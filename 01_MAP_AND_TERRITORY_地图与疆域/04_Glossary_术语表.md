## 术语表

**a priori（先验）** 在考虑证据之前。类似地，“a posteriori”意为“在考虑证据之后”；可与先验概率和后验概率对比。在哲学中，“a priori”通常指无需任何经验性证据（除了理解命题所需的证据）就能知道某事的更强含义。

**anchoring（锚定效应）** 在获得相关新信息后，仍然过度依赖最初信息的认知偏差。

**anthropics（人择问题）** 涉及如何合理推理像你这样的观察者有多少的问题。

**artificial general intelligence（通用人工智能）** 指“通用型”的人工智能，其通用性类似于人类推理的通用性。很难准确描述这种推理的本质——如果我们知道如何完全形式化它，我们就已经知道如何构建通用人工智能了。不过，我们可以用人类在许多不同科学领域都能出类拔萃来举例，尽管我们的祖先环境中并没有粒子加速器。

**availability heuristic（可得性启发）** 倾向于根据相关例子在脑海中浮现的容易程度来做判断。

**Bayes’s Theorem（贝叶斯定理）** 用于在获得新证据 E 后更新假设 H 的概率的公式。最简单形式下，贝叶斯定理表明，给定证据下假设的概率（记作 P(H|E)），等于在假设成立时观察到证据的概率，乘以你对假设为真的先验概率 P(H)，再除以无论如何都会看到该证据的先验概率 P(E)。即：

> P(H|E) = P(E|H)P(H)/P(E)

也称为贝叶斯法则。参见“odds ratio（赔率比）”以了解更简单的贝叶斯更新计算方法。

**Bayesian（贝叶斯/贝叶斯主义者）**  
(a) 最优推理的；符合概率论法则的推理。  
(b) 最优推理者，或在推理上非常接近最优推理的人。  
(c) 将信念视为概率性的，并将概率论视为评估推理者的相关理想的人。  
(d) 与概率信念相关的。  
(e) 与贝叶斯统计方法相关的。

**Bayesian updating（贝叶斯更新）** 以完全符合你所掌握信息的方式修正你的信念。完美的贝叶斯更新在现实环境中极难实现，因此现实中的智能体必须依赖不完美的启发式方法。但作为一种最优性标准，贝叶斯更新有助于理解某些改变想法的方式比其他方式更有助于了解世界。

**bias（偏见/偏差）**  
(a) 认知偏差。在《理性：从AI到僵尸》中，这将是默认含义。  
(b) 统计偏差。  
(c) 归纳偏差。  
(d) 口语：偏见或不公。

**bit（比特）**  
(a) 二进制数字，取值为0或1。  
(b) 概率的对数（以1/2为底）——用二进制数字平均能传递的最大信息量。《理性：从AI到僵尸》通常采用后一种含义。

**Blue and Green（蓝队与绿队）** 古罗马的对立体育队和政治派别。

**calibration（校准）** 以概率分配信念，并使这些信念被证实的频率与分配概率相匹配。例如，如果你对某些断言赋予“70%置信度”，而这些断言有70%的概率被证实，那么你的校准就是好的。

**causal decision theory（因果决策理论）** 认为做决策的正确方式是选择因果后果最好的行动的理论。

**cognitive bias（认知偏差）** 由于人类推理方式导致的系统性错误。可与普通的无知、错误信息、脑损伤等导致的错误区分开来。

**conditional probability（条件概率）** 在假设某个陈述为真的前提下，另一个陈述为真的概率。例如，条件概率 P(A|B) 表示“在 B 为真的情况下 A 为真的概率”。

**confirmation bias（确认偏误）** 更加重视与自己当前信念一致的证据的认知偏差。

**conjunction（合取/合取句）** 断言多件事的句子。“正在下雨并且我在吃三明治”就是一个合取句；它的合取项分别是“正在下雨”和“我在吃三明治”。

**conjunction fallacy（合取谬误）** 把一个合取句当作比它的任一合取项更可能为真的谬误。

**deontology（义务论）** 一种道德理论，认为道德行为就是选择满足特定规则（如“不要说谎”“不要偷窃”）的行为。

**directed acyclic graph（有向无环图）** 一种图结构，边有方向（有向），且不存在沿着边的方向从某个节点出发又回到自身的路径（无环）。

**élan vital（生命力）** “生命的力量”。1907年由哲学家亨利·柏格森提出，用来指代一种被认为赋予生命“活力”和目标导向行为的神秘力量。

**entanglement（纠缠）**  
(a) 两个事物之间的因果相关。  
(b) 在量子物理中，两个粒子的状态相互依赖。当一个量子幅度分布无法因式分解时，就发生了（b）意义上的纠缠。

**entropy（熵）**  
(a) 热力学中，某一物理状态可能出现的不同方式的数量（玻尔兹曼熵）。例如，略微洗乱的牌堆比完全洗乱的牌堆熵低，因为完全洗乱的牌堆可能出现的排列更多。  
(b) 信息论中，一条消息所包含信息的期望值（香农熵）。即，如果你不知道某个随机变量的取值，平均来说你会缺少多少比特的信息。玻尔兹曼熵和香农熵实际上是等价的：一个系统的热力学无序度对应于完全描述它所需的比特数。

**epistemic（认知/知识相关）** 与知识有关的。

**Everett branch（埃弗雷特分支）** 量子力学多世界解释中的一个“世界”。

**expected utility（期望效用）** 在采取某个行动时，效用函数的期望值。大致意思是：在对行动结果不确定的情况下，某个行动实现智能体目标的平均程度。确定获得1美元通常比10%概率获得100万美元带来更多效用，但如果你对100万美元的效用超过10倍于1美元，那么10%概率获得100万美元的期望效用更高。期望效用是一个理想化的数学框架，用来理解“好赌注未必是必然的赌注”。

**expected value（期望值）** 某个变量所有可能取值与其为真概率的乘积之和。

**费米悖论（Fermi Paradox）** 这样一个难题：一方面，“按先验概率，我们应该预期夜空中会有许多大型星际文明可见”；另一方面，“我们却没有看到任何此类文明的明确迹象”。许多人觉得没有可见外星文明令人困惑的原因包括：“地球上生命所需的元素似乎很常见”；“在我们进化之前，生命在其他地方有数十亿年的发展时间”；“高等智能似乎相对容易进化（例如，许多认知能力在人类、章鱼、乌鸦等物种中独立进化出来）”；以及“虽然有些目标偏好隐藏，但许多不同的目标都偏好大规模资源提取，而我们只需要存在一种这样的古老物种即可”。

**foozality** 参见“理性（rationality）”。

**图（graph）** 在图论中，是由简单的原子对象（“顶点”或“节点”）通过线（“边”）连接而成的数学对象。当边有方向时，也称为“箭头”。

**hedonic（享乐的）** 与愉悦有关。

**事后偏差（hindsight bias）** 夸大自己在事后能预测当前已知事件的倾向。

**归纳偏差（inductive bias）** 学习者用来根据数据集做出预测的一组假设。这里的“偏差”指的是学习者在某些方向上更容易更新，而不是其他方向，但与其他“偏差”概念不同，“归纳偏差”并不意味着一定有错误。

**工具性（instrumental）** 与有用性或有效性有关。

**工具性价值（instrumental value）** 仅为实现其他目标而追求的目标。

**意向性（intentionality）** 事物代表或指代其他事物的能力。不要与“意图（intent）”混淆。

**同构（isomorphism）** 一个范畴中对象之间的双向映射。非正式地说，如果两个事物在所有相关方面都相同，常被称为“同构”。

**Kolmogorov复杂度（Kolmogorov complexity）** 复杂性的形式化定义。给定一种编程语言，一个可计算字符串的Kolmogorov复杂度是该语言中输出该字符串的最短程序的长度。

**似然（likelihood）** 在贝叶斯概率论中，某个假设对某个证据赋予的概率。例如，假设我们观察到证据E=“Boddy先生被刀捅了”，我们的假设是HP=“Plum教授杀了Boddy”和HW=“White夫人杀了Boddy”。如果我们认为在Plum教授杀人时用刀的概率是25%，那么HP对E的似然就是25%。如果White夫人杀人时用刀的概率只有5%，那么HP和HW的似然比就是25/5=5。这意味着该证据支持“Plum干的”的力度是“White干的”的5倍，这告诉我们在观察到E后如何更新信念。（参见“赔率比（odds ratio）”获取更简单的例子。）

**magisterium（权威领域）** 斯蒂芬·古尔德提出的术语，指某个群体或领域拥有权威的范围。古尔德认为科学和宗教是各自独立、互不重叠的权威领域。在他看来，宗教有权回答“终极意义和道德价值”的问题（但不能回答经验事实），科学有权回答经验事实的问题（但不能回答意义或价值）。

**最大熵概率分布（maximum-entropy probability distribution）** 给每个事件分配相等概率的概率分布。

**最小消息长度原理（Minimum Message Length Principle）** 奥卡姆剃刀的形式化表达，根据传达假设及可用数据所需的总信息长度来判断假设的概率。更简单的假设和能简洁编码数据的假设更受青睐。

**动机性认知（motivated cognition）** 由某种目标或情感驱动、与准确性相悖的推理。例如：无证据地倾向于拒绝某主张（动机性怀疑）、倾向于相信某主张（动机性轻信）、倾向于持续评估某问题（动机性持续）、或倾向于停止评估某问题（动机性停止）。

**墨菲定律（Murphy’s Law）** “凡是可能出错的事都会出错。”

**互信息（mutual information）** 对于两个变量，了解其中一个变量的信息能告诉你多少关于另一个变量的取值。如果两个变量的互信息为零，则它们是独立的；知道其中一个的取值对另一个的不确定性没有任何减少。

**纳米技术（nanotechnology）**  
(a) 按埃里克·德雷克斯勒（Eric Drexler）等人的定义，对单个原子尺度的物质进行精细操控。这是《理性：从AI到僵尸》中的默认含义。  
(b) 在纳米米级别操控物质。

**纽科姆问题（Newcomb’s Problem）** 决策理论中的一个核心问题。想象有一个能提前预测你决策的智能体，根据预测结果决定是否在两个盒子里放钱。无论如何，透明盒里都有1000美元；如果预测你只拿不透明盒，就在不透明盒里放100万美元，否则不放。预测者告诉你规则后离开。你会怎么选？如果你两个盒子都拿（“双盒”），预测者早已预见到你的选择，所以不透明盒是空的，你只得1000美元。如果你只拿不透明盒，你会得到100万美元。所以看起来应该只拿不透明盒。然而，因果决策理论者反对这种策略，理由是你无法因果地控制预测者过去的行为；预测者在你做决定前就已经决定好了，无论不透明盒里有没有钱，如果你不拿透明盒就等于白白丢掉1000美元。因此，因果决策理论也主张在一次性的囚徒困境中背叛，即使对手是你的完美复制体。

**规范性（normative）** 良好，或作为理想行为标准的。

**奥卡姆剃刀（Occam’s Razor）** 原则是：在其他条件相同的情况下，较简单的主张比复杂的主张更可能为真。奥卡姆剃刀的形式化包括所罗门诺夫归纳法和最小消息长度原理。

**赔率比（odds ratio）** 表示两个事件相对可能性的方式。例如，如果我对今天是星期几一无所知，那么今天是星期天的赔率是1:6。这等价于“今天是星期天”的先验概率为1/7。如果x:y是赔率比，则x的概率为x/(x+y)。同理，要把概率p转为赔率比，只需写作p:(1-p)。如果是百分比p%，则为p:(100-p)。例如，我赢得比赛的概率是40%，赔率就是40:60，也可以写作2:3。赔率比常用于贝叶斯更新的计算。如果我注意到商场提前关门，这种情况在星期天发生的概率是非星期天的两倍（似然比2:1），我只需把先验“今天是星期天”的赔率（1:6）与证据的似然比（2:1）相乘，得到后验概率2:6，即1:3。

**优化过程（optimization process）** Yudkowsky 的术语，指在巨大搜索空间中进行搜索，并能命中极其罕见目标的过程。例如，树木的存在更容易理解为进化这一搜索过程不断提出更优解的结果。同理，一个设计良好的水坝也更容易理解为某种优化过程在寻找满足某些标准的设计或策略。进化、人类和海狸都具备这种特性，因此都可以被视为优化过程。相比之下，山脉和恒星的形成则更适合用其他方式描述。

**正交性（orthogonality）** 两个（或多个）变量的独立性。如果两个变量正交，知道其中一个的取值对了解另一个没有帮助。

**燃素（phlogiston）** 17世纪提出的一种假想物质，用来解释火和生锈等现象。晚期炼金术士和早期化学家认为可燃物中含有燃素，燃烧时燃素会逸出。

**正偏见（positive bias）** 更容易注意到理论预测你会看到的内容，而不是注意到理论预测你不会看到的内容的偏差。

**后验概率（posterior probability）** 智能体在获得证据后的信念。与获得证据前的先验信念（prior）相对。

**先验概率（prior probability）** 智能体在获得某些证据前的信念。

**囚徒困境（Prisoner’s Dilemma）** 一种博弈，每个参与者可以选择“合作”或“背叛”。对每个玩家来说，最佳结果是自己背叛而对方合作；最差结果是自己合作而对方背叛。双方都合作是次优，双方都背叛是次差。传统博弈论认为，在一次性囚徒困境中，背叛总是最优选择；无论对方独立选择合作还是背叛，背叛都能让你获得更高收益或减少损失。Yudkowsky 是少数认为在一次性囚徒困境中理性合作是可能的决策理论家之一，前提是双方的决策过程足够相似。“我和对手都遵循同样的决策程序，所以如果我合作，对方也会合作；如果我背叛，对方也会背叛。前者更好，所以我的决策程序输出‘合作’。”

**概率分布（probability distribution）** 一个函数，为每种可能性分配一个概率（即某事为真的可能性大小）。离散和连续概率分布通常分别用概率质量函数和概率密度函数编码。把概率想象成必须在各种可能性之间分配的“质量”，有助于理解减少一个假设的概率必然意味着增加其他假设的概率，反之亦然。概率就像（经典）质量一样，是守恒的。

**夸克（quark）** 一种基本粒子，构成物质的基本单元。

**理性主义者（rationalist）**  
(a) 与理性相关的。  
(b) 尝试将理性概念应用于现实决策的人。

**理性（rationality）** 做出系统性良好决策（工具理性）并获得系统性准确信念（认知理性）。

**代表性启发（representativeness heuristic）** 一种认知捷径，人们根据某事件与心理原型的相似程度来判断其概率。

**范围不敏感（scope insensitivity）** 一种认知偏差，人们往往忽视某些现象的规模大小。

**自我锚定（self-anchoring）** 以自身特质为默认标准，即使有证据显示他人不同，也只会做出微弱调整。

**香农互信息（Shannon mutual information）** 参见“互信息（mutual information）”。

**所罗门诺夫归纳（Solomonoff induction）** 一种对最优（但计算上不可行）推理的尝试性定义。即贝叶斯更新加上简约性先验：生成感知的程序越长，分配到的概率越低。

**奇点（Singularity）** 指人工智能系统在某些情境下以极大幅度超越人类智能的情景。

**统计偏差（statistical bias）** 某项测量的期望值与被测事物真实值之间的系统性偏差。

**系统1（System 1）** 大脑中负责快速、自动、情感化和直觉性判断的过程。

**系统2（System 2）** 大脑中负责缓慢、深思熟虑、反思和理性判断的过程。

**泰格马克世界（Tegmark world）** 存在于庞大多元宇宙中的一个宇宙，由数学对象组成。该观点来自马克斯·泰格马克的“数学宇宙假说”，认为我们的宇宙本身就是一个数学对象，存在于所有可计算结构都存在的集合中。

**传统理性主义（Traditional Rationality）** Yudkowsky 的术语，指理查德·费曼、卡尔·萨根、查尔斯·皮尔斯等思想家所倡导的科学规范和传统。Yudkowsky 将其与当代数学和认知科学中的理性观念进行对比。

**真值（truth-value）** 一个命题的真假属性。

**图灵机（Turing machine）** 一种抽象机器，按照规则在无限长的纸带上操作符号。

**双盒选择（two-boxing）** 在纽科姆问题中选择两个盒子的策略。

**更新（updating）** 修正自己的信念。参见“贝叶斯更新（Bayesian updating）”。

**效用函数（utility function）** 按“效用”对结果进行排序的函数，即根据结果满足某组目标或约束的程度来排序。人类是有限且不完美的推理者，通常无法持续优化任何认可的效用函数；但效用函数的概念有助于我们形式化“如何更好地追求目标”，正如贝叶斯更新有助于形式化“如何更好地学习”一样。

---

## Glossary

**a priori** Before considering the evidence. Similarly, “a posteriori” means “after considering the evidence”; compare prior and posterior probabilities. In philosophy, “a priori” often refers to the stronger idea of something knowable in the absence of any experiential evidence (outside of the evidence needed to understand the claim).

**anchoring** The cognitive bias of relying excessively on initial information after receiving relevant new information.

**anthropics** Problems related to reasoning well about how many observers like you there are.

**artificial general intelligence** Artificial intelligence that is “general-purpose” in the same sense that human reasoning is general-purpose. It’s hard to crisply state what this kind of reasoning consists in—if we knew how to fully formalize it, we would already know how to build artificial general intelligence. However, we can gesture at (e.g.) humans’ ability to excel in many different scientific fields, even though we did not evolve in an ancestral environment containing particle accelerators.

**availability heuristic** The tendency to base judgments on how easily relevant examples come to mind.

**Bayes’s Theorem** The equation stating how to update a hypothesis H in light of new evidence E. In its simplest form, Bayes’s Theorem says that a hypothesis’ probability given the evidence, written “P(H|E),” equals the likelihood of the evidence given that hypothesis, multiplied by your prior probability P(H) that the hypothesis was true, divided by the prior probability P(E) that you would see that evidence regardless. I.e.:

> P(H|E)=P(E|H)P(H)/P(E).

Also known as Bayes’s Rule. See “odds ratio” for a simpler way to calculate a Bayesian update.

**Bayesian** (a) Optimally reasoned; reasoned in accordance with the laws of probability. (b) An optimal reasoner, or a reasoner that approximates optimal inference unusually well. (c) Someone who treats beliefs as probabilistic and treats probability theory as a relevant ideal for evaluating reasoners. (d) Related to probabilistic belief. (e) Related to Bayesian statistical methods.

**Bayesian updating** Revising your beliefs in a way that’s fully consistent with the information available to you. Perfect Bayesian updating is wildly intractable in realistic environments, so real-world agents have to rely on imperfect heuristics to get by. As an optimality condition, however, Bayesian updating helps make sense of the idea that some ways of changing one’s mind work better than others for learning about the world.

**bias** (a) A cognitive bias. In Rationality: From AI to Zombies, this will be the default meaning. (b) A statistical bias. (c) An inductive bias. (d) Colloquially: prejudice or unfairness.

**bit** (a) A binary digit, taking the value 0 or 1. (b) The logarithm (base 1/2) of a probability—the maximum information that can be communicated using a binary digit, averaged over the digit’s states. Rationality: From AI to Zombies usually uses “bit” in the latter sense.

**Blue and Green** Rival sports teams and political factions in ancient Rome.

**calibration** Assigning probabilities to beliefs in a way that matches how often those beliefs turn out to be right. E.g., if your assignment of “70% confidence” to claims is well-calibrated, then you will get such claims right about 70% of the time.

**causal decision theory** The theory that the right way to make decisions is by picking the action with the best causal consequences.

**cognitive bias** A systematic error stemming from the way human reasoning works. This can be contrasted with errors due to ordinary ignorance, misinformation, brain damage, etc.

**conditional probability** The probability that a statement is true on the assumption that some other statement is true. E.g., the conditional probability P(A|B) means “the probability of A given that B.”

**confirmation bias** The cognitive bias of giving more weight to evidence that agrees with one’s current beliefs.

**conjunction** A sentence that asserts multiple things. “It’s raining and I’m eating a sandwich” is a conjunction; its conjuncts are “It’s raining” and “I’m eating a sandwich.”

**conjunction fallacy** The fallacy of treating a conjunction as though it were more likely than its conjuncts.

**deontology** The theory that moral conduct is about choosing actions that satisfy specific rules like “don’t lie” or “don’t steal.”

**directed acyclic graph** A graph that is directed (its edges have a direction associated with them) and acyclic (there’s no way to follow a sequence of edges in a given direction to loop around from a node back to itself).

**élan vital** “Vital force.” A term coined in 1907 by the philosopher Henri Bergson to refer to a mysterious force that was held to be responsible for life’s “aliveness” and goal-oriented behavior.

**entanglement** (a) Causal correlation between two things. (b) In quantum physics, the mutual dependence of two particles’ states upon one another. Entanglement in sense (b) occurs when a quantum amplitude distribution cannot be factorized.

**entropy** (a) In thermodynamics, the number of different ways a physical state may be produced (its Boltzmann entropy). E.g., a slightly shuffled deck has lower entropy than a fully shuffled one, because there are many more configurations a fully shuffled deck is likely to end up in. (b) In information theory, the expected value of the information contained in a message (its Shannon entropy). That is, a random variable’s Shannon entropy is how many bits of information one would be missing (on average) if one did not know the variable’s value. Boltzmann entropy and Shannon entropy have turned out to be equivalent; that is, a system’s thermodynamic disorder corresponds to the number of bits needed to fully characterize it.

**epistemic** Concerning knowledge.

**Everett branch** A “world” in the many-worlds interpretation of quantum mechanics.

**expected utility** The expected value of a utility function given some action. Roughly: how much an agent’s goals will tend to be satisfied by some action, given uncertainty about the action’s outcome. A sure \$1 will usually lead to more utility than a 10% chance of \$1 million. Yet in all cases, the 10% shot at \$1 million has more expected utility, assuming you assign more than ten times as much utility to winning \$1 million. Expected utility is an idealized mathematical framework for making sense of the idea “good bets don’t have to be sure bets.”

**expected value** The sum of all possible values of a variable, each multiplied by its probability of being the true value.

**Fermi Paradox** The puzzle of reconciling “on priors, we should expect there to be many large interstellar civilizations visible in the night sky” and “we see no clear signs of such civilizations.” Some reasons many people find it puzzling that there are no visible alien civilizations include: “the elements required for life on Earth seem commonplace”; “life had billions of years to develop elsewhere before we evolved”; “high intelligence seems relatively easy to evolve (e.g., many of the same cognitive abilities evolved independently in humans, octopuses, crows)”; and “although some goals favor hiddenness, many different possible goals favor large-scale extraction of resources, and we only require there to exist one old species of the latter type.”

**foozality** See “rationality.”

**graph** In graph theory, a mathematical object consisting of simple atomic objects (“vertices,” or “nodes”) connected by lines (or “edges”). When edges have an associated direction, they are also called “arrows.” hedonic Concerning pleasure.

**hindsight bias** The tendency to exaggerate how well one could have predicted things that one currently believes.

**inductive bias** The set of assumptions a leaner uses to derive predictions from a data set. The learner is “biased” in the sense that it’s more likely to update in some directions than in others, but unlike with other conceptions of “bias”, the idea of “inductive bias” doesn’t imply any sort of error.

**instrumental** Concerning usefulness or effectiveness.

**instrumental value** A goal that is only pursued in order to further some other goal.

**intentionality** The ability of things to represent, or refer to, other things. Not to be confused with “intent.”

**isomorphism** A two-way mapping between objects in a category. Informally, two things are often called “isomorphic” if they’re identical in every relevant respect.

**Kolmogorov complexity** A formalization of the idea of complexity. Given a programming language, a computable string’s Kolmogorov complexity is the length of the shortest computer program in that language that outputs the string.

**likelihood** In Bayesian probability theory, how much probability a hypothesis assigns to a piece of evidence. Suppose we observe the evidence E = “Mr. Boddy was knifed,” and our hypotheses are HP = “Professor Plum killed Boddy” and HW = “Mrs. White killed Boddy.” If we think there’s a 25% chance that Plum would use a knife in the worlds where he chose to kill Boddy, then we can say HP assigns a likelihood of 25% to E. Suppose that there’s only a 5% chance Mrs. White would use a knife if she killed Boddy. Then we can say that the likelihood ratio between HP and HW is 25/5= 5. This means that the evidence supports “Plum did it” five times as strongly as it supports “White did it,” which tells us how to update upon observing E. (See “odds ratio” for a simple example.)

**magisterium** Stephen Gould’s term for a domain where some community or field has authority. Gould claimed that science and religion were separate and non-overlapping magisteria. On his view, religion has authority to answer questions of “ultimate meaning and moral value” (but not empirical fact) and science has authority to answer questions of empirical fact (but not meaning or value).

**maximum-entropy probability distribution** A probability distribution which assigns equal probability to every event.

**Minimum Message Length Principle** A formalization of Occam’s Razor that judges the probability of a hypothesis based on how long it would take to communicate the hypothesis plus the available data. Simpler hypotheses are favored, as are hypotheses that can be used to concisely encode the data.

**motivated cognition** Reasoning that is driven by some goal or emotion that’s at odds with accuracy. Examples include non-evidence-based inclinations to reject a claim (motivated skepticism), to believe a claim (motivated credulity), to continue evaluating an issue (motivated continuation), or to stop evaluating an issue (motivated stopping).

**Murphy’s Law** The saying “Anything that can go wrong will go wrong.”

**mutual information** For two variables, the amount that knowing about one variable tells you about the other’s value. If two variables have zero mutual information, then they are independent; knowing the value of one does nothing to reduce uncertainty about the other.

**nanotechnology** (a) Fine-grained control of matter on the scale of individual atoms, as in Eric Drexler’s writing. This is the default meaning in Rationality: From AI to Zombies. (b) Manipulation of matter on a scale of nanometers.

**Newcomb’s Problem** A central problem in decision theory. Imagine an agent that understands psychology well enough to predict your decisions in advance, and decides to either fill two boxes with money, or fill one box, based on their prediction. They put \$1,000 in a transparent box no matter what, and they then put \$1 million in an opaque box if (and only if) they predicted that you’d only take the opaque box. The predictor tells you about this, and then leaves. Which do you pick? If you take both boxes (“two-boxing”), you get only the \$1000, because the predictor foresaw your choice and didn’t fill the opaque box. On the other hand, if you only take the opaque box, you come away with \$1 million. So it seems like you should take only the opaque box. However, causal decision theorists object to this strategy on the grounds that you can’t causally control what the predictor did in the past; the predictor has already made their decision by the time you make yours, and regardless of whether or not they placed the \$1 million in the opaque box, you’ll be throwing away a free \$1000 if you choose not to take it. For the same reason, causal decision theory prescribes defecting in one-shot Prisoner’s Dilemmas, even if you’re playing against a perfect atom-by-atom copy of yourself.

**ormative** Good, or serving as a standard for desirable behavior.

**Occam’s Razor** The principle that, all else being equal, a simpler claim is more probable than a relatively complicated one. Formalizations of Occam’s Razor include Solomonoff induction and the Minimum Message Length Principle.

**odds ratio** A way of representing how likely two events are relative to each other. E.g., if I have no information about which day of the week it is, the odds are 1 : 6 that it’s Sunday. This is the same as saying that “it’s Sunday” has a prior probability of 1/7. If x : y is the odds ratio, the probability of x is x/(x + y). Likewise, to convert a probability p into an odds ratio, I can just write p : (1− p). For a percent probability p%, this becomes p : (100− p). E.g., if my probability of winning a race is 40%, my odds are 40 : 60, which can also be written 2 : 3. Odds ratios are useful because they’re usually the easiest way to calculate a Bayesian update. If I notice the mall is closing early, and that’s twice as likely to happen on a Sunday as it is on a non-Sunday (a likelihood ratio of 2 : 1), I can simply multiply the left and right sides of my prior it’s Sunday (1 : 6) by the evidence’s likelihood ratio (2 : 1) to arrive at a correct posterior probability of 2 : 6, or 1 : 3.

**optimization process** Yudkowsky’s term for a process that performs searches through a large search space, and manages to hit very specific targets that would be astronomically unlikely to occur by chance. E.g., the existence of trees is much easier to understand if we posit a search process, evolution, that iteratively comes up with better and better solutions to cognitively difficult problems. A well-designed dam, similarly, is easier to understand if we posit an optimization process searching for designs or policies that meet some criterion. Evolution, humans, and beavers all share this property, and can therefore be usefully thought of as optimization processes. In contrast, the processes that produce mountains and stars are easiest to describe in other terms.

**orthogonality** The independence of two (or more) variables. If two variables are orthogonal, then knowing the value of one doesn’t help you learn the value of the other.

**phlogiston** A substance hypothesized in the 17th entity to explain phenomena such as fire and rust. Combustible objects were thought by late alchemists and early chemists to contain phlogiston, which evaporated during combustion.

**positive bias** Bias toward noticing what a theory predicts you’ll see, instead of noticing what a theory predicts you won’t see.

**posterior probability** An agent’s beliefs after acquiring evidence. Contrasted with its prior beliefs, or priors.

**prior probability** An agent’s beliefs prior to acquiring some evidence.

**Prisoner’s Dilemma** A game in which each player can choose to either “cooperate” or “defect” with the other. The best outcome for each player is to defect while the other cooperates; and the worst outcome is to cooperate while the other defects. Each player views mutual cooperation as the second-best option, and mutual defection as the second-worst. Traditionally, game theorists have argued that defection is always the correct move in one-shot dilemmas; it improves your reward if the other player independently cooperates, and it lessens your loss if the other player independently defects. Yudkowsky is one of a minority of decision theorists who argue that rational cooperation is possible in the one-shot Prisoner’s Dilemma, provided the two players’ decision-making is known to be sufficiently similar. “My opponent and I are both following the same decision procedure, so if I cooperate, my opponent will cooperate too; and if I defect, my opponent will defect. The former seems preferable, so this decision procedure hereby outputs ‘cooperate.”

**probability distribution** A function which assigns a probability (i.e., a number representing how likely something is to be true) to every possibility under consideration. Discrete and continuous probability distributions are generally encoded by, respectively, probability mass functions and probability density functions. Thinking of probability as a “mass” that must be divided up between possibilities can be a useful way to keep in view that reducing the probability of one hypothesis always requires increasing the probability of others, and vice versa. Probability, like (classical) mass, is conserved.

**quark** An elementary particle of matter.

**rationalist** (a) Related to rationality. (b) A person who tries to apply rationality concepts to their real-world decisions.

**rationality** Making systematically good decisions (instrumental rationality) and achieving systematically accurate beliefs (epistemic rationality).

**representativeness heuristic** A cognitive heuristic where one judges the probability of an event based on how well it matches some mental prototype.

**scope insensitivity** A cognitive bias where people tend to disregard the size of certain phenomena.

**self-anchoring** Anchoring to oneself. Treating one’s own qualities as the default, and only weakly updating toward viewing others as different when given evidence of differences.

**Shannon mutual information** See “mutual information.”

**Solomonoff induction** An attempted definition of optimal (albeit computationally unfeasible) inference. Bayesian updating plus a simplicity prior that assigns less probability to percept-generating programs the longer they are.

**Singularity** One of several scenarios in which artificial intelligence systems surpass human intelligence in a large and dramatic way.

**statistical bias** A systematic discrepancy between the expected value of some measure, and the true value of the thing you’re measuring.

**System 1** The processes behind the brain’s fast, automatic, emotional, and intuitive judgments.

**System 2** The processes behind the brain’s slow, deliberative, reflective, and intellectual judgments.

**Tegmark world** A universe contained in a vast multiverse of mathematical objects. The idea comes from Max Tegmark’s Mathematical Universe Hypothesis, which holds that our own universe is a mathematical object contained in an ensemble in which all possible computable structures exist.

**Traditional Rationality** Yudkowsky’s term for the scientific norms and conventions espoused by thinkers like Richard Feynman, Carl Sagan, and Charles Peirce. Yudkowsky contrasts this with the ideas of rationality in contemporary mathematics and cognitive science.

**truth-value** A proposition’s truth or falsity.

**Turing machine** An abstract machine that follows rules for manipulating symbols on an arbitrarily long tape.

**two-boxing** Taking both boxes in Newcomb’s Problem.

**updating** Revising one’s beliefs. See also “Bayesian updating.”

**utility function** A function that ranks outcomes by “utility,” i.e., by how well they satisfy some set of goals or constraints. Humans are limited and imperfect reasoners, and don’t consistently optimize any endorsed utility function; but the idea of optimizing a utility function helps us give formal content to “what it means to pursue a goal well,” just as Bayesian updating helps formalize “what it means to learn well.”
