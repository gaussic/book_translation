## 积极偏见：探寻黑暗

作者：Eliezer Yudkowsky

我正在教一门课，并在黑板上写下三个数字：2-4-6。“我在想一个规则，”我说，“它支配着由三个数字组成的序列。2-4-6这个序列恰好符合这个规则。每位同学在桌子上会找到一堆索引卡片。请在卡片上写下一个由三个数字组成的序列，我会标记它为‘是’（符合规则）或‘否’（不符合规则）。然后你可以继续写下另一个三个数字的序列并问它是否符合规则，依此类推。当你确信自己知道这个规则时，就在卡片上写下这个规则。你可以测试尽可能多的三元组。”

以下是其中一位学生的猜测记录：

> 4-6-2 否
> 4-6-8 是
> 10-12-14 是

此时，学生写下了他们对规则的猜测。你认为规则是什么？你会想测试另一个三元组吗？如果是，你会测试哪个？在继续之前，花点时间思考一下。

上面的挑战基于彼得·沃森（Peter Wason）的一项经典实验，称为2-4-6任务。尽管参与者通常对他们的猜测充满信心，只有21%的参与者成功猜出了实验者的真实规则，而此后的一些重复实验也持续显示成功率约为20%。

这项研究被称为《在概念任务中未能消除假设》。尝试2-4-6任务的参与者通常会试图生成积极的示例，而非消极示例——他们会根据假设的规则生成一个代表性的实例，并看看它是否被标记为“是”。

因此，假设“数字每次增加2”的人会测试三元组8-10-12，得知它符合规则，并自信地宣布规则。而假设“X-2X-3X”的人会测试三元组3-6-9，发现它符合规则，并宣布这一规则。

实际上，所有的规则都是相同的：三个数字必须按升序排列。

但要发现这一点，你必须生成一些不符合规则的三元组，比如20-23-26，看看它们是否被标记为“否”。然而，参与者在这项实验中往往不会这样做。在某些情况下，参与者会设计、测试并宣布比实际答案复杂得多的规则。

这种认知现象通常被归类为“确认偏见”。然而，在我看来，试图测试积极示例而非消极示例的现象，应该与试图保持你最初信念的现象区分开来。“积极偏见”有时被用作“确认偏见”的同义词，它更贴切地描述了这个特定的缺陷。

曾经有一种观点认为，火焰熄灭的原因可以通过火焰素理论来解释（空气被火焰素饱和，无法再释放火焰素）。但是，火焰素理论同样也能解释火焰为什么不熄灭。要注意到这一点，你必须寻找负面的示例，而不是积极的示例——你必须看看零，而不是一；这与实验所表明的人类本能相悖。

因为本能上，我们人类只能生活在世界的一半。

即便你被讲解了好几天关于积极偏见的内容，依然可能在实际情况中忽视它。积极偏见并不是我们出于逻辑考虑，或者情感依附做出的行为。2-4-6任务是“冷”的，理性的，不带有感情的“热”因素。然而，这个错误发生在语言之下，发生在意象层面，发生在本能反应上。因为问题并不是出自遵循“只思考积极示例”的明确规则，它不能仅仅通过知道“我们应该思考积极和消极的示例”来解决。哪个示例首先跳入你的脑海？你必须学会无言地，选择“曲折”的方式，而不是“直行”。你必须学会朝零的方向弯曲，而不是远离它。

我已经写了很长时间，提出了这样的观点：一个假设的力量在于它不能解释的部分，而不是它能解释的部分——如果你能同样好地解释任何结果，那么你就没有知识。因此，要发现一个不有用的解释，单单考虑它解释得很好的部分是不够的——你还必须去寻找它无法解释的结果，这才是理论的真正强度。

所以，我说了这些话，接着我挑战了“涌现”作为概念的有用性。一位评论者提到了超导性和铁磁性作为涌现的例子。我回答说，非超导性和非铁磁性也是涌现的例子，这就是问题所在。但请不要误解，我不是要批评那位评论者！尽管我曾大量阅读关于“确认偏见”的内容，但第一次读到2-4-6任务时，我没有发现其中的“陷阱”。这是一个亚语言的反应，必须通过再训练来克服。我自己也在不断努力。

理性主义者的很多技能都在语言之下。这使得通过语言来传达这门艺术变得非常具有挑战性。人们可能会同意你，但在接下来的句子中，他们会做出一些不加思考的举动，完全与前面的观点相反。并不是说我在抱怨！我写这篇文章的一个重要原因，是想观察我的话语没有传达的部分。

你现在是在寻找积极偏见的积极示例，还是将一小部分精力集中在积极偏见应该让你忽视的部分？你是朝向光明看，还是向黑暗看？

---

## Positive Bias: Look into the Dark

by Eliezer Yudkowsky

I am teaching a class, and I write upon the blackboard three numbers: 2-4-6. “I am thinking of a rule,” I say, “which governs sequences of three numbers. The sequence 2-4-6, as it so happens, obeys this rule. Each of you will find, on your desk, a pile of index cards. Write down a sequence of three numbers on a card, and I’ll mark it ‘Yes’ for fits the rule, or ‘No’ for not fitting the rule. Then you can write down another set of three numbers and ask whether it fits again, and so on. When you’re confident that you know the rule, write down the rule on a card. You can test as many triplets as you like.”

Here’s the record of one student’s guesses:

> 4-6-2 No
> 4-6-8 Yes
> 10-12-14 Yes .

At this point the student wrote down their guess at the rule. What do you think the rule is? Would you have wanted to test another triplet, and if so, what would it be? Take a moment to think before continuing.

The challenge above is based on a classic experiment due to Peter Wason, the 2-4-6 task. Although subjects given this task typically expressed high confidence in their guesses, only 21% of the subjects successfully guessed the experimenter’s real rule, and replications since then have continued to show success rates of around 20%.

The study was called “On the failure to eliminate hypotheses in a conceptual task.” Subjects who attempt the 2-4-6 task usually try to generate positive examples, rather than negative examples—they apply the hypothetical rule to generate a representative instance, and see if it is labeled “Yes.”

Thus, someone who forms the hypothesis “numbers increasing by two” will test the triplet 8-10-12, hear that it fits, and confidently announce the rule. Someone who forms the hypothesis X-2X-3X will test the triplet 3-6-9, discover that it fits, and then announce that rule.

In every case the actual rule is the same: the three numbers must be in ascending order.

But to discover this, you would have to generate triplets that shouldn’t fit, such as 20-23-26, and see if they are labeled “No.” Which people tend not to do, in this experiment. In some cases, subjects devise, “test,” and announce rules far more complicated than the actual answer.

This cognitive phenomenon is usually lumped in with “confirmation bias.” However, it seems to me that the phenomenon of trying to test positive rather than negative examples, ought to be distinguished from the phenomenon of trying to preserve the belief you started with. “Positive bias” is sometimes used as a synonym for “confirmation bias,” and fits this particular flaw much better.

It once seemed that phlogiston theory could explain a flame going out in an enclosed box (the air became saturated with phlogiston and no more could be released). But phlogiston theory could just as well have explained the flame not going out. To notice this, you have to search for negative examples instead of positive examples, look into zero instead of one; which goes against the grain of what experiment has shown to be human instinct.

For by instinct, we human beings only live in half the world.

One may be lectured on positive bias for days, and yet overlook it in-the-moment. Positive bias is not something we do as a matter of logic, or even as a matter of emotional attachment. The 2-4-6 task is “cold,” logical, not affectively “hot.” And yet the mistake is sub-verbal, on the level of imagery, of instinctive reactions. Because the problem doesn’t arise from following a deliberate rule that says “Only think about positive examples,” it can’t be solved just by knowing verbally that “We ought to think about both positive and negative examples.” Which example automatically pops into your head? You have to learn, wordlessly, to zag instead of zig. You have to learn to flinch toward the zero, instead of away from it.

I have been writing for quite some time now on the notion that the strength of a hypothesis is what it can’t explain, not what it can—if you are equally good at explaining any outcome, you have zero knowledge. So to spot an explanation that isn’t helpful, it’s not enough to think of what it does explain very well—you also have to search for results it couldn’t explain, and this is the true strength of the theory.

So I said all this, and then I challenged the usefulness of “emergence” as a concept. One commenter cited superconductivity and ferromagnetism as examples of emergence. I replied that non-superconductivity and non-ferromagnetism were also examples of emergence, which was the problem. But be it far from me to criticize the commenter! Despite having read extensively on “confirmation bias,” I didn’t spot the “gotcha” in the 2-4-6 task the first time I read about it. It’s a subverbal blink-reaction that has to be retrained. I’m still working on it myself.

So much of a rationalist’s skill is below the level of words. It makes for challenging work in trying to convey the Art through words. People will agree with you, but then, in the next sentence, do something subdeliberative that goes in the opposite direction. Not that I’m complaining! A major reason I’m writing this is to observe what my words haven’t conveyed.

Are you searching for positive examples of positive bias right now, or sparing a fraction of your search on what positive bias should lead you to not see? Did you look toward light or darkness?