## 合法的不确定性

作者：Eliezer Yudkowsky

在《不确定世界中的理性选择》（*Rational Choice in an Uncertain World*）一书中，罗宾·道斯（Robyn Dawes）描述了一项由特维尔斯基（Tversky）进行的实验：<sup>1</sup>

> 许多心理学实验是在1950年代末到1960年代初进行的，实验中要求受试者预测某个具有随机成分但又具有基本概率可预测性的事件的结果。例如，受试者被要求预测实验者翻开的下一张卡片是红色还是蓝色，实验中70%的卡片是蓝色，且红蓝卡片的顺序完全随机。
>
> 在这种情况下，获得最高成功率的策略是预测更常见的事件。例如，如果70%的卡片是蓝色，那么每次都预测蓝色，成功率就是70%。
>
> 然而，受试者通常会采取匹配概率的策略——即用事件发生的相对频率来预测更可能发生的事件。例如，受试者倾向于预测70%的时间蓝色卡片会出现，30%的时间红色卡片会出现。这样的策略的成功率是58%，因为当蓝色卡片出现时（它发生的概率是0.70），受试者70%的时间猜对；当红色卡片出现时（它发生的概率是0.30），受试者30%的时间猜对；因此，(0.70×0.70) + (0.30×0.30) = 0.58。
>
> 事实上，受试者预测更频繁的事件时，会以比其实际发生概率稍高的概率进行预测，但他们并没有接近100%地预测事件的发生，即使他们因预测准确性而获得报酬...例如，在一千次试验中，受试者每预测对一次就能得到五分之一的奖励...他们预测\[更常见的事件]的准确率为76%。

不要以为这个实验仅仅是关于赌博策略中的一个小错误。它简明扼要地展示了理性思考中最重要的一个观点。

受试者不断猜测红色卡片，好像他们认为有某种方式能够预测这个随机的序列。道斯在谈到这个实验时接着说：“尽管有一千次的反馈，受试者还是无法让自己相信这个情境是无法预测的。”

但错误一定更深。即使受试者认为他们提出了一个假设，他们并不需要在实际的赌注中依赖这个假设来验证它。他们可以说：“如果这个假设是对的，下一张卡片将是红色”——然后就选择赌蓝色。他们每次都选择蓝色，积累尽可能多的五分钱，同时在心里注意到任何他们认为可能发现的模式。如果他们的预测是正确的，那么他们就可以切换到新的发现的序列。

我不会责怪受试者继续发明假设——他们怎么能知道这个序列确实超出了他们的预测能力呢？但我会责怪受试者在没有必要测试假设的情况下，仍然为猜测下注，而事实上，数百次早期的猜测都被证伪了。

人类真的能如此过于自信吗？

我怀疑其实有更简单的事情在发生——即受试者根本没想到全蓝策略。

人们看到一个以蓝卡为主，夹杂一些红卡的序列，便认为最优的下注策略必须是既有大量蓝卡，又有一些红卡。

这是一个违反直觉的观点——在信息不完全的情况下，最优的下注策略并不类似典型的卡片序列。

这是一个违反直觉的观点——即使在存在随机因素的环境中，最优策略也应该是“遵守规律”。

看起来你的行为应该像环境一样不可预测——但不！随机的钥匙并不会打开随机的锁，仅仅因为它们“都是随机的”。

你不能以火攻火；你应该用水灭火。但这个想法需要额外的一步，需要一个没有直接由问题陈述激活的新概念，因此它并不是第一个跳入你脑海的想法。

在蓝色和红色卡片的困境中，我们的部分知识告诉我们——在每一轮中——最好的赌注是蓝色。我们的部分知识在每一轮中的建议是一样的。如果我们在30%的时间里违背我们的部分知识，选择下注红色，那么我们就会因此做得更糟——因为现在我们正处于愚蠢的状态，下注我们知道是更不可能发生的结果。

如果你每一轮都下注红色，你会尽可能地糟糕，甚至会100%愚蠢。如果你在30%的时间下注红色，面对30%的红色卡片，那么你让自己变得30%愚蠢。

当你的知识不完全时——意味着你觉得世界似乎有一部分是随机的——随机化你的行为并不能解决问题。随机化你的行为会让你离目标更远，而不是更近。在一个已经模糊的世界中，丢掉你的智慧只会让事情变得更糟。

这是一个违反直觉的观点——即使在不确定的条件下，最优策略也可能是遵循规律的。

因此，理性主义者并不多，因为大多数认为世界是混乱的，最终会试图用混乱对抗混乱。你必须采取额外的一步，去想出一些没有立刻进入你脑海的东西，才能想象如何用不是“火”的东西来对抗火。

你听过那些没有启蒙的人说：“理性在人与理性人打交道时很好用，但这个世界不理性。”然而，面对一个不理性的对手，抛弃自己的理性并不会帮助你。即使面对一个违反决策理论的对手，决策理论也不会崩溃死亡。

这并不比在面临一串蓝色和红色卡片时选择全蓝更明显。然而，你每一次在红色上的下注都是一次预期的失败，就像你在思考中的每一次偏离规律。

有多少《星际迷航》的剧集因此被推翻？有多少人工智能的理论被推翻？

---

<sup>1</sup>阿莫斯·特维尔斯基和沃德·爱德华兹，“信息与奖励在二元选择中的作用，”《实验心理学杂志》71卷，第5期（1966年）：680–683。另见雅各布·舒尔和鲁思·梅奥，“在不确定的世界中寻找确定性：放弃经验性思维转向理性思维的困难，”《行为决策杂志》16卷，第2期（2003年）：93–106。

---

## Lawful Uncertainty

by Eliezer Yudkowsky

In Rational Choice in an Uncertain World, Robyn Dawes describes an experiment by Tversky:<sup>1</sup>

> Many psychological experiments were conducted in the late 1950s and early 1960s in which subjects were asked to predict the outcome of an event that had a random component but yet had base-rate predictability—for example, subjects were asked to predict whether the next card the experimenter turned over would be red or blue in a context in which 70% of the cards were blue, but in which the sequence of red and blue cards was totally random.
> 
> In such a situation, the strategy that will yield the highest proportion of success is to predict the more common event. For example, if 70% of the cards are blue, then predicting blue on every trial yields a 70% success rate.
> 
> What subjects tended to do instead, however, was match probabilities—that is, predict the more probable event with the relative frequency with which it occurred. For example, subjects tended to predict 70% of the time that the blue card would occur and 30% of the time that the red card would occur. Such a strategy yields a 58% success rate, because the subjects are correct 70% of the time when the blue card occurs (which happens with probability .70) and 30% of the time when the red card occurs (which happens with probability .30); (.70×.70) + (.30×.30) = .58.
> 
> In fact, subjects predict the more frequent event with a slightly higher probability than that with which it occurs, but do not come close to predicting its occurrence 100% of the time, even when they are paid for the accuracy of their predictions . . . For example, subjects who were paid a nickel for each correct prediction over a thousand trials . . . predicted [the more common event] 76% of the time.

Do not think that this experiment is about a minor flaw in gambling strategies. It compactly illustrates the most important idea in all of rationality.

Subjects just keep guessing red, as if they think they have some way of predicting the random sequence. Of this experiment Dawes goes on to say, “Despite feedback through a thousand trials, subjects cannot bring themselves to believe that the situation is one in which they cannot predict.”

But the error must go deeper than that. Even if subjects think they’ve come up with a hypothesis, they don’t have to actually bet on that prediction in order to test their hypothesis. They can say, “Now if this hypothesis is correct, the next card will be red”—and then just bet on blue. They can pick blue each time, accumulating as many nickels as they can, while mentally noting their private guesses for any patterns they thought they spotted. If their predictions come out right, then they can switch to the newly discovered sequence.

I wouldn’t fault a subject for continuing to invent hypotheses—how could they know the sequence is truly beyond their ability to predict? But I would fault a subject for betting on the guesses, when this wasn’t necessary to gather information, and literally hundreds of earlier guesses had been disconfirmed.

Can even a human be that overconfident?

I would suspect that something simpler is going on—that the all-blue strategy just didn’t occur to the subjects.

People see a mix of mostly blue cards with some red, and suppose that the optimal betting strategy must be a mix of mostly blue cards with some red.

It is a counterintuitive idea that, given incomplete information, the optimal betting strategy does not resemble a typical sequence of cards.

It is a counterintuitive idea that the optimal strategy is to behave lawfully, even in an environment that has random elements.

It seems like your behavior ought to be unpredictable, just like the environment—but no! A random key does not open a random lock just because they are “both random.”

You don’t fight fire with fire; you fight fire with water. But this thought involves an extra step, a new concept not directly activated by the problem statement, and so it’s not the first idea that comes to mind.

In the dilemma of the blue and red cards, our partial knowledge tells us—on each and every round—that the best bet is blue. This advice of our partial knowledge is the same on every single round. If 30% of the time we go against our partial knowledge and bet on red instead, then we will do worse thereby—because now we’re being outright stupid, betting on what we know is the less probable outcome.

If you bet on red every round, you would do as badly as you could possibly do; you would be 100% stupid. If you bet on red 30% of the time, faced with 30% red cards, then you’re making yourself 30% stupid.

When your knowledge is incomplete—meaning that the world will seem to you to have an element of randomness—randomizing your actions doesn’t solve the problem. Randomizing your actions takes you further from the target, not closer. In a world already foggy, throwing away your intelligence just makes things worse.

It is a counterintuitive idea that the optimal strategy can be to think lawfully, even under conditions of uncertainty.

And so there are not many rationalists, for most who perceive a chaotic world will try to fight chaos with chaos. You have to take an extra step, and think of something that doesn’t pop right into your mind, in order to imagine fighting fire with something that is not itself fire.

You have heard the unenlightened ones say, “Rationality works fine for dealing with rational people, but the world isn’t rational.” But faced with an irrational opponent, throwing away your own reason is not going to help you. There are lawful forms of thought that still generate the best response, even when faced with an opponent who breaks those laws. Decision theory does not burst into flames and die when faced with an opponent who disobeys decision theory.

This is no more obvious than the idea of betting all blue, faced with a sequence of both blue and red cards. But each bet that you make on red is an expected loss, and so too with every departure from the Way in your own thinking.

How many Star Trek episodes are thus refuted? How many theories of AI?

---

<sup>1</sup>Amos Tversky and Ward Edwards, “Information versus Reward in Binary Choices,” Journal of Experimental Psychology 71, no. 5 (1966): 680–683. See also Yaacov Schul and Ruth Mayo, “Searching for Certainty in an Uncertain World: The Difficulty of Giving Up the Experiential for the Rational Mode of Thinking,” Journal of Behavioral Decision Making 16, no. 2 (2003): 93–106.