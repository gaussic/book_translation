## 事后诸葛让科学贬值

作者：Eliezer Yudkowsky

本文紧密基于 Meyers《探索社会心理学》中的一段[摘录](https://web.archive.org/web/20170801042830/http://csml.som.ohio-state.edu:80/Music829C/hindsight.bias.html)；强烈建议阅读全文。

《大西洋月刊》编辑 Cullen Murphy 说，社会科学“没有提出任何在[任何]名人语录词典里找不到的观点或结论……社会科学家们日复一日地走向世界，日复一日地发现人们的行为正如你所预期的那样。”

当然，这种“预期”全都是[事后诸葛](https://www.lesswrong.com/lw/il/hindsight_bias/)。（事后诸葛偏差：知道问题答案的被试，会大大高估自己“本来会”猜中这个答案的概率，而不知道答案的被试则不会。）

历史学家 Arthur Schlesinger, Jr. 认为对二战士兵经历的科学研究只是“常识的沉重演示”。例如：

1. 受教育程度更高的士兵比受教育程度低的士兵更难适应。（知识分子比街头聪明人更难应对战场压力。）
2. 南方士兵比北方士兵更能适应南海群岛的炎热气候。（南方人更习惯炎热天气。）
3. 白人士兵比黑人士兵更渴望晋升为士官。（多年的压迫削弱了成就动机。）
4. 南方黑人更喜欢南方白人军官而不是北方白人军官。（南方军官与黑人打交道更有经验、更有技巧。）
5. 只要战斗还在继续，士兵们比战争结束后更渴望回家。（战斗期间，士兵们知道自己身处险境。）

你觉得这些发现中，有多少是你事先能预测到的？五个里能猜中三个？四个？有没有哪一项你会预测相反——你的模型会“受挫”？在继续往下读之前，先想一想……

……

在这个演示（来自 Paul Lazarsfeld，经由 Meyers）中，上述所有发现其实都与实际结果相反。<sup>1</sup> 你觉得你的模型“受挫”了几次？你承认自己会错几次？这才是你模型的真实水平。你作为理性主义者的力量，体现在你能对虚构比对现实更感到困惑。

当然，除非我又把结果反转了。你觉得呢？

此刻你真的不知道答案时的思考过程，和你刚才为“已知”答案合理化时的思考过程，有什么不同吗？

Daphna Baratz 让大学生面对一对对所谓的研究发现，一真一假（比如“经济繁荣时人们花掉的收入比例比经济衰退时高”），<sup>2</sup> 无论哪一边，学生们都觉得“自己本来也会预测到”。这就是典型的事后诸葛偏差。

这让人们觉得自己不需要科学，因为“我本来也能预测到”。

（正如你所预期的，对吧？）

事后诸葛会让我们系统性地低估科学发现的“令人惊讶”程度，尤其是那些我们能理解的发现——那些对我们来说“真实”的、我们能事后塞进自己世界模型的发现。如果你懂神经科学或物理学，读相关领域新闻时，你也很可能低估那些发现的惊奇性。这不仅不公正地贬低了研究者的贡献，更糟糕的是，会让你无法察觉到那些与你真正预期不符的证据。

我们需要有意识地努力，让自己足够震惊。

---

<sup>1</sup>Paul F. Lazarsfeld, “The American Solidier—An Expository Review,” Public Opinion Quarterly 13, no. 3 (1949): 377–404.

<sup>2</sup>Daphna Baratz, How Justified Is the “Obvious” Reaction? (Stanford University, 1983).

---

## Hindsight Devalues Science

by Eliezer Yudkowsky

This essay is closely based on an [excerpt](https://web.archive.org/web/20170801042830/http://csml.som.ohio-state.edu:80/Music829C/hindsight.bias.html) from Meyers’s Exploring Social Psychology; the excerpt is worth reading in its entirety.

Cullen Murphy, editor of The Atlantic, said that the social sciences turn up “no ideas or conclusions that can’t be found in [any] encyclopedia of quotations . . . Day after day social scientists go out into the world. Day after day they discover that people’s behavior is pretty much what you’d expect.”

Of course, the “expectation” is all [hindsight](https://www.lesswrong.com/lw/il/hindsight_bias/). (Hindsight bias: Subjects who know the actual answer to a question assign much higher probabilities they “would have” guessed for that answer, compared to subjects who must guess without knowing the answer.)

The historian Arthur Schlesinger, Jr. dismissed scientific studies of World War II soldiers’ experiences as “ponderous demonstrations” of common sense. For example:

1. Better educated soldiers suffered more adjustment problems than less educated soldiers. (Intellectuals were less prepared for battle stresses than street-smart people.) 
2. Southern soldiers coped better with the hot South Sea Island climate than Northern soldiers. (Southerners are more accustomed to hot weather.) 
3. White privates were more eager to be promoted to noncommissioned officers than Black privates. (Years of oppression take a toll on achievement motivation.) 
4. Southern Blacks preferred Southern to Northern White officers. (Southern officers were more experienced and skilled in interacting with Blacks.) 
5. As long as the fighting continued, soldiers were more eager to return home than after the war ended. (During the fighting, soldiers knew they were in mortal danger.)

How many of these findings do you think you could have predicted in advance? Three out of five? Four out of five? Are there any cases where you would have predicted the opposite—where your model takes a hit? Take a moment to think before continuing . . .


. . .


In this demonstration (from Paul Lazarsfeld by way of Meyers), all of the findings above are the opposite of what was actually found.<sup>1</sup> How many times did you think your model took a hit? How many times did you admit you would have been wrong? That’s how good your model really was. The measure of your strength as a rationalist is your ability to be more confused by fiction than by reality.

Unless, of course, I reversed the results again. What do you think?

Do your thought processes at this point, where you really don’t know the answer, feel different from the thought processes you used to rationalize either side of the “known” answer?

Daphna Baratz exposed college students to pairs of supposed findings, one true (“In prosperous times people spend a larger portion of their income than during a recession”) and one the truth’s opposite.<sup>2</sup> In both sides of the pair, students rated the supposed finding as what they “would have predicted.” Perfectly standard hindsight bias.

Which leads people to think they have no need for science, because they “could have predicted” that.

(Just as you would expect, right?)

Hindsight will lead us to systematically undervalue the surprisingness of scientific findings, especially the discoveries we understand—the ones that seem real to us, the ones we can retrofit into our models of the world. If you understand neurology or physics and read news in that topic, then you probably underestimate the surprisingness of findings in those fields too. This unfairly devalues the contribution of the researchers; and worse, will prevent you from noticing when you are seeing evidence that doesn’t fit what you really would have expected.

We need to make a conscious effort to be shocked enough.

---

<sup>1</sup>Paul F. Lazarsfeld, “The American Solidier—An Expository Review,” Public Opinion Quarterly 13, no. 3 (1949): 377–404.

<sup>2</sup>Daphna Baratz, How Justified Is the “Obvious” Reaction? (Stanford University, 1983).

