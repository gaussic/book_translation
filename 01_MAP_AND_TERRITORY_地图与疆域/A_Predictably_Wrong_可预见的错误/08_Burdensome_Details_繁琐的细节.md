## 繁琐的细节

作者：Eliezer Yudkowsky

> 只是为了让本来光秃秃、毫无说服力的叙述增添一点艺术上的逼真感而加的佐证细节……
>
> ——普巴，《米卡多》（吉尔伯特与沙利文）

合取谬误是指：人们会把“A且B”这种命题的概率评估得比单独“A”或“B”还高，尽管逻辑上合取命题的概率绝不可能高于其任一部分。例如，在一项实验中，68% 的受试者认为“里根将为未婚母亲提供联邦支持并削减对地方政府的联邦支持”比“里根将为未婚母亲提供联邦支持”更有可能。<sup>1</sup>

[一系列巧妙设计的实验](https://www.lesswrong.com/lw/jj/conjunction_controversy_or_how_they_nail_it_down/)，排除了其他假设，证实了标准解释：合取谬误之所以发生，是因为我们“用代表性判断代替了概率判断”。<sup>2</sup> 通过添加额外细节，你可以让某个结果看起来更符合生成它的过程。比如，加上“里根还会削减对地方政府的支持”，就让“里根会支持未婚母亲”听起来更合理。一个主张的不可信被另一个主张的可信所抵消；它们被“平均”了。

也就是说：添加细节可以让情景听起来更合理，尽管事件本身的概率必然变小。

如果真是这样，那么，假设来说，我们可能会看到未来学家编造出极其详细且貌似合理的未来历史，或者看到人们把一大堆未经证实的主张和几个听起来很有力的断言捆绑在一起全盘接受。

如果你在一个赤裸裸的直接对比中遇到合取谬误，你也许能通过有意识地纠正自己，在那道题上答对。但这只是头痛医头脚痛医脚，并不能解决根本问题。

在[1982 年的实验](https://www.lesswrong.com/lw/ji/conjunction_fallacy/)中，专业预测者给“俄罗斯入侵波兰，随后美苏断交”的概率打分高于“美苏断交”，而每组实验对象只看到其中一个命题。<sup>3</sup> 这些预测者作为一个群体，能采取什么策略来避免合取谬误？当没有人直接知道对比内容，甚至没人知道实验是关于合取谬误时，他们如何能做出更好的概率判断？

只修补一个特殊陷阱，并不能解决普遍问题。陷阱只是症状，不是病因。

预测者们要如何在没有直接对比、甚至不知道会被考察合取谬误的情况下避免这个错误？在我看来，他们需要注意到“和（and）”这个词。他们不仅要警惕，甚至要本能地避开它。即使不知道研究者会专门考察合取谬误，也要对两个完整细节的合取保持警觉，对有人让你认同如此复杂的预测感到震惊。并且要大幅降低概率——根据实验细节，至少要降到四分之一。

预测者们如果能思考一下美苏断交可能的各种原因也会有帮助。情景不是“美苏无缘无故突然断交”，而是“美苏因任何原因断交”。

对于那些给“里根将为未婚母亲提供联邦支持并削减对地方政府的联邦支持”打分的受试者，同样需要对“和”这个词感到震惊。此外，他们需要把荒谬性相加（荒谬性就是对数概率，可以相加），而不是平均。他们应该想：“里根可能会不会削减对地方政府的支持（1 比特），但他支持未婚母亲的可能性极低（4 比特）。总荒谬性：5 比特。”或者，“里根不会支持未婚母亲。只要有一个不成立就全盘否定，另一个主张只会让情况更糟。”

再比如，Tversky 和 Kahneman（1983）做过一个关于六面骰子的实验，骰子有四面是绿的，两面是红的。<sup>4</sup> 受试者要押注在 20 次掷骰中出现（1）RGRRR，（2）GRGRRR，或（3）GRRRRR 这三种序列中的哪一个。65% 的受试者选择了 GRGRRR，但实际上只要出现 GRGRRR，RGRRR 也必然出现，所以 RGRRR 严格优于 GRGRRR。受试者怎样才能做得更好？注意到包含关系？也许，但这只是权宜之计，不能解决根本问题。明确计算概率当然可以，但你并不总能算出精确概率。

受试者用启发式思维时会想：“啊哈！序列2绿红比例最高！我该押2！”要想用启发式赢，他们应该想：“啊哈！序列1最短！我该选1！”

他们需要对奥卡姆剃刀有更强烈的情感反应——每加一个细节都要觉得是负担，哪怕只是多掷一次骰子。

有一次，我和一个被某位不谨慎的未来学家（喜欢加很多听起来很酷的细节）迷住的人聊天。我试图解释为什么我不会被这些惊人理论迷住。我讲了合取谬误，特别是“断交±入侵波兰”实验。他说：“好吧，但这和——有什么关系？”我说：“宇宙因任何原因复制的概率，总是大于‘宇宙通过黑洞复制，因为高级文明制造黑洞，因为宇宙进化出让他们这么做的机制’的概率。”他才恍然大悟。

在那之前，他并没有把这些额外细节当作负担。相反，他觉得这些细节是佐证，让故事更真实。有人给你一堆奇怪的观点，其中之一是宇宙会自我复制。然后他们为“宇宙会自我复制”这个主张提供支持。但这并不是对整个[捆绑包](http://en.wikipedia.org/wiki/Package-deal_fallacy)的支持，尽管它们被讲成了一个故事。

你必须把细节拆开。你要把每个细节单独拎出来，问一句：“我们怎么知道这一点？”有人描绘人类陷入纳米技术战争的图景，说中国拒绝遵守国际协议，接着爆发军备竞赛……等一下——你怎么知道一定是中国？你兜里有水晶球，还是只是喜欢当未来学家？这些细节都从哪来的？那个具体细节又是怎么来的？

正如所言：

> 如果你能减轻负担，就必须这么做。
>
> 没有哪根稻草不能压垮骆驼的背。

---

<sup>1</sup> Amos Tversky 和 Daniel Kahneman, “Judgments of and by Representativeness: Heuristics and Biases,” 收录于 Judgment Under Uncertainty, Daniel Kahneman, Paul Slovic, Amos Tversky 编（纽约：剑桥大学出版社，1982），84–98页。

<sup>2</sup> 参见 Amos Tversky 和 Daniel Kahneman, “Extensional Versus Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment,” Psychological Review 90, no. 4 (1983): 293–315；以及 Daniel Kahneman 和 Shane Frederick, “Representativeness Revisited: Attribute Substitution in Intuitive Judgment,” 收录于 Heuristics and Biases: The Psychology of Intuitive Judgment, Thomas Gilovich, Dale Griffin, Daniel Kahneman 编（剑桥大学出版社，2002）。

<sup>3</sup> Tversky 和 Kahneman, [“Extensional Versus Intuitive Reasoning.”](https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/Yq6aA4M3JKWaQepPJ#cite.0.Tversky.1983)

<sup>4</sup> [同上。](https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/Yq6aA4M3JKWaQepPJ#cite.0.Tversky.1983)

---

## Burdensome Details

by Eliezer Yudkowsky

> Merely corroborative detail, intended to give artistic verisimilitude to an otherwise bald and unconvincing narrative . . .
> 
> —Pooh-Bah, in Gilbert and Sullivan’s The Mikado

The conjunction fallacy is when humans assign a higher probability to a proposition of the form “A and B” than to one of the propositions “A” or “B” in isolation, even though it is a theorem that conjunctions are never likelier than their conjuncts. For example, in one experiment, 68% of the subjects ranked it more likely that “Reagan will provide federal support for unwed mothers and cut federal support to local governments” than that “Reagan will provide federal support for unwed mothers.”<sup>1</sup>

[A long series of cleverly designed experiments](https://www.lesswrong.com/lw/jj/conjunction_controversy_or_how_they_nail_it_down/), which weeded out alternative hypotheses and nailed down the standard interpretation, confirmed that conjunction fallacy occurs because we “substitute judgment of representativeness for judgment of probability.”<sup>2</sup> By adding extra details, you can make an outcome seem more characteristic of the process that generates it. You can make it sound more plausible that Reagan will support unwed mothers, by adding the claim that Reagan will also cut support to local governments. The implausibility of one claim is compensated by the plausibility of the other; they “average out.”

Which is to say: Adding detail can make a scenario sound more plausible, even though the event necessarily becomes less probable.

If so, then, hypothetically speaking, we might find futurists spinning unconscionably plausible and detailed future histories, or find people swallowing huge packages of unsupported claims bundled with a few strong-sounding assertions at the center.

If you are presented with the conjunction fallacy in a naked, direct comparison, then you may succeed on that particular problem by consciously correcting yourself. But this is only slapping a band-aid on the problem, not fixing it in general.

In the [1982 experiment](https://www.lesswrong.com/lw/ji/conjunction_fallacy/) where professional forecasters assigned systematically higher probabilities to “Russia invades Poland, followed by suspension of diplomatic relations between the USA and the USSR” than to “Suspension of diplomatic relations between the USA and the USSR,” each experimental group was only presented with one proposition.<sup>3</sup> What strategy could these forecasters have followed, as a group, that would have eliminated the conjunction fallacy, when no individual knew directly about the comparison? When no individual even knew that the experiment was about the conjunction fallacy? How could they have done better on their probability judgments?

Patching one gotcha as a special case doesn’t fix the general problem. The gotcha is the symptom, not the disease.

What could the forecasters have done to avoid the conjunction fallacy, without seeing the direct comparison, or even knowing that anyone was going to test them on the conjunction fallacy? It seems to me, that they would need to notice the word “and.” They would need to be wary of it—not just wary, but leap back from it. Even without knowing that researchers were afterward going to test them on the conjunction fallacy particularly. They would need to notice the conjunction of two entire details, and be shocked by the audacity of anyone asking them to endorse such an insanely complicated prediction. And they would need to penalize the probability substantially—a factor of four, at least, according to the experimental details.

It might also have helped the forecasters to think about possible reasons why the US and Soviet Union would suspend diplomatic relations. The scenario is not “The US and Soviet Union suddenly suspend diplomatic relations for no reason,” but “The US and Soviet Union suspend diplomatic relations for any reason.”

And the subjects who rated “Reagan will provide federal support for unwed mothers and cut federal support to local governments”? Again, they would need to be shocked by the word “and.” Moreover, they would need to add absurdities—where the absurdity is the log probability, so you can add it—rather than averaging them. They would need to think, “Reagan might or might not cut support to local governments (1 bit), but it seems very unlikely that he will support unwed mothers (4 bits). Total absurdity: 5 bits.” Or maybe, “Reagan won’t support unwed mothers. One strike and it’s out. The other proposition just makes it even worse.”

Similarly, consider Tversky and Kahnemans (1983) experiment based around a six-sided die with four green faces and two red faces.<sup>4</sup> The subjects had to bet on the sequence (1) RGRRR, (2) GRGRRR, or (3) GRRRRR appearing anywhere in twenty rolls of the dice. Sixty-five percent of the subjects chose GRGRRR, which is strictly dominated by RGRRR, since any sequence containing GRGRRR also pays off for RGRRR. How could the subjects have done better? By noticing the inclusion? Perhaps; but that is only a band-aid, it does not fix the fundamental problem. By explicitly calculating the probabilities? That would certainly fix the fundamental problem, but you can’t always calculate an exact probability.

The subjects lost heuristically by thinking: “Aha! Sequence 2 has the highest proportion of green to red! I should bet on Sequence 2!” To win heuristically, the subjects would need to think: “Aha! Sequence 1 is short! I should go with Sequence 1!”

They would need to feel a stronger emotional impact from Occam’s Razor—feel every added detail as a burden, even a single extra roll of the dice.

Once upon a time, I was speaking to someone who had been mesmerized by an incautious futurist (one who adds on lots of details that sound neat). I was trying to explain why I was not likewise mesmerized by these amazing, incredible theories. So I explained about the conjunction fallacy, specifically the “suspending relations ± invading Poland” experiment. And he said, “Okay, but what does this have to do with—” And I said, “It is more probable that universes replicate for any reason, than that they replicate via _black holes because advanced civilizations manufacture black holes because universes evolve to make them do it_.” And he said, “Oh.”

Until then, he had not felt these extra details as extra burdens. Instead they were corroborative detail, lending verisimilitude to the narrative. Someone presents you with a package of strange ideas, one of which is that universes replicate. Then they present support for the assertion that universes replicate. But this is not support for the [package](http://en.wikipedia.org/wiki/Package-deal_fallacy), though it is all told as one story.

You have to disentangle the details. You have to hold up every one independently, and ask, “How do we know this detail?” Someone sketches out a picture of humanity’s descent into nanotechnological warfare, where China refuses to abide by an international control agreement, followed by an arms race . . . Wait a minute—how do you know it will be China? Is that a crystal ball in your pocket or are you just happy to be a futurist? Where are all these details coming from? Where did that specific detail come from?

For it is written:

> If you can lighten your burden you must do so.
> 
> There is no straw that lacks the power to break your back.

---

<sup>1</sup> Amos Tversky and Daniel Kahneman, “Judgments of and by Representativeness: Heuristics and Biases,” in Judgment Under Uncertainty, ed. Daniel Kahneman, Paul Slovic, and Amos Tversky (New York: Cambridge University Press, 1982), 84–98.

<sup>2</sup> See Amos Tversky and Daniel Kahneman, “Extensional Versus Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment,” Psychological Review 90, no. 4 (1983): 293–315 and Daniel Kahneman and Shane Frederick, “Representativeness Revisited: Attribute Substitution in Intuitive Judgment,” in Heuristics and Biases: The Psychology of Intuitive Judgment, ed. Thomas Gilovich, Dale Griffin, and Daniel Kahneman (Cambridge University Press, 2002) for more information.

<sup>3</sup> Tversky and Kahneman, [“Extensional Versus Intuitive Reasoning.”](https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/Yq6aA4M3JKWaQepPJ#cite.0.Tversky.1983)

<sup>4</sup> [Ibid.](https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/Yq6aA4M3JKWaQepPJ#cite.0.Tversky.1983)

