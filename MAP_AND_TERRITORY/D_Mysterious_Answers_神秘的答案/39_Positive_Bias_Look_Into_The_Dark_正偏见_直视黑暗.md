## 正偏见：直视黑暗

我在教一门课，在黑板上写下了三个数字：2-4-6。“我心里有一个规则，”我说，“它决定了三元数列的规律。2-4-6 这个数列，恰好符合这个规则。你们每个人桌上都有一叠索引卡。请在卡片上写下一个三元数列，我会标记‘是’，表示符合规则，或‘否’，表示不符合。然后你可以再写下另一个三元数列，继续问是否符合，以此类推。当你确信自己知道规则时，把规则写在卡片上。你可以测试任意多组三元数。”

下面是一位学生的猜测记录：

> 4-6-2 否  
> 4-6-8 是  
> 10-12-14 是

此时，这位学生写下了自己对规则的猜测。你觉得规则是什么？你会想再测试一个三元组吗？如果会，你会测试什么？请在继续往下读前，先思考一下。

上面的挑战基于 Peter Wason 的经典实验“2-4-6 任务”。虽然被试通常对自己的猜测信心满满，但只有21%的人最终猜对了实验者的真实规则，后续重复实验的成功率也一直在20%左右。

这项研究名为《在概念任务中未能排除假设》。尝试2-4-6任务的被试通常倾向于生成正例，而不是反例——他们用假设的规则生成一个代表性实例，看看会不会被标记为“是”。

比如，有人假设“数字每次加二”，就会测试8-10-12，听到符合规则后自信地宣布自己的规则。有人假设是“X-2X-3X”，就会测试3-6-9，发现也符合规则，然后就写下这个规则。

但实际上，真正的规则始终只有一个：三个数字必须是递增的。

但要发现这一点，你就得生成一些不该符合规则的三元组，比如20-23-26，看看会不会被标记为“否”。而实验中人们往往不会这么做。有时，被试会想出、测试并宣布比实际答案复杂得多的规则。

这种认知现象通常被归为“确认偏误”（confirmation bias）。但在我看来，倾向于测试正例而不是反例的现象，应该和试图维护原有信念的现象区分开来。“正偏见”（positive bias）有时被当作“确认偏误”的同义词，但用来描述这种具体错误更为贴切。

曾经，燃素理论似乎可以解释火焰在密闭容器中熄灭（空气被燃素饱和，无法再释放燃素）。但燃素理论同样可以解释火焰不熄灭。要注意到这一点，你必须主动去寻找反例，而不是正例，要直视“零”而不是“壹”；而实验表明，这违背了人类的本能。

因为本能上，我们人类只活在世界的一半里。

你可以被讲解正偏见好几天，但在实际情境中还是会忽略它。正偏见不是我们出于逻辑，甚至不是出于情感依恋而做的事。2-4-6任务是“冷”的、逻辑性的，并不“热”。但这种错误发生在语言之下，在意象和本能反应的层面。因为问题不是出在我们有个“只考虑正例”的明确规则，所以光靠口头知道“我们应该同时考虑正例和反例”并不能解决。你脑中自动浮现的例子是哪种？你必须无言地学会“左转”而不是“右转”。你得学会本能地朝“零”而不是远离它。

我一直在写，强调一个假说的力量在于它不能解释什么，而不是它能解释什么——如果你能同样好地解释任何结果，你就一无所知。所以，要识别一个无用的解释，仅仅想它能很好地解释什么还不够——你还要主动寻找它无法解释的结果，这才是理论的真正力量。

所以我说了这些，然后质疑了“涌现”作为概念的用处。有评论者举超导和铁磁性为“涌现”的例子。我回应说，非超导和非铁磁性同样是“涌现”的例子，这正是问题所在。但我绝无意批评那位评论者！尽管我读过很多关于“确认偏误”的内容，第一次看到2-4-6任务时我也没发现其中的“陷阱”。这是需要重新训练的下意识反应。我自己现在还在努力。

理性主义者的许多技能都在语言之下。这让用文字传授理性之艺变得极具挑战。人们会同意你的观点，但下一句话就会下意识地做出完全相反的事。我并不是在抱怨！我写这些的一个重要原因，就是观察我的文字没有传达出去的地方。

你现在是在寻找正偏见的正例，还是分出一部分注意力去寻找正偏见本应让你看不到的东西？你是在看向光明，

---

## Positive Bias: Look into the Dark

I am teaching a class, and I write upon the blackboard three numbers: 2-4-6. “I am thinking of a rule,” I say, “which governs sequences of three numbers. The sequence 2-4-6, as it so happens, obeys this rule. Each of you will find, on your desk, a pile of index cards. Write down a sequence of three numbers on a card, and I’ll mark it ‘Yes’ for fits the rule, or ‘No’ for not fitting the rule. Then you can write down another set of three numbers and ask whether it fits again, and so on. When you’re confident that you know the rule, write down the rule on a card. You can test as many triplets as you like.”

Here’s the record of one student’s guesses:

> 4-6-2 No
> 4-6-8 Yes
> 10-12-14 Yes .

At this point the student wrote down their guess at the rule. What do you think the rule is? Would you have wanted to test another triplet, and if so, what would it be? Take a moment to think before continuing.

The challenge above is based on a classic experiment due to Peter Wason, the 2-4-6 task. Although subjects given this task typically expressed high confidence in their guesses, only 21% of the subjects successfully guessed the experimenter’s real rule, and replications since then have continued to show success rates of around 20%.

The study was called “On the failure to eliminate hypotheses in a conceptual task.” Subjects who attempt the 2-4-6 task usually try to generate positive examples, rather than negative examples—they apply the hypothetical rule to generate a representative instance, and see if it is labeled “Yes.”

Thus, someone who forms the hypothesis “numbers increasing by two” will test the triplet 8-10-12, hear that it fits, and confidently announce the rule. Someone who forms the hypothesis X -2X -3X will test the triplet 3-6-9, discover that it fits, and then announce that rule.

In every case the actual rule is the same: the three numbers must be in ascending order.

But to discover this, you would have to generate triplets that shouldn’t fit, such as 20-23-26, and see if they are labeled “No.” Which people tend not to do, in this experiment. In some cases, subjects devise, “test,” and announce rules far more complicated than the actual answer.

This cognitive phenomenon is usually lumped in with “confirmation bias.” However, it seems to me that the phenomenon of trying to test positive rather than negative examples, ought to be distinguished from the phenomenon of trying to preserve the belief you started with. “Positive bias” is sometimes used as a synonym for “confirmation bias,” and fits this particular flaw much better.

It once seemed that phlogiston theory could explain a flame going out in an enclosed box (the air became saturated with phlogiston and no more could be released). But phlogiston theory could just as well have explained the flame not going out. To notice this, you have to search for negative examples instead of positive examples, look into zero instead of one; which goes against the grain of what experiment has shown to be human instinct.

For by instinct, we human beings only live in half the world.

One may be lectured on positive bias for days, and yet overlook it in-themoment. Positive bias is not something we do as a matter of logic, or even as a matter of emotional attachment. The 2-4-6 task is “cold,” logical, not affectively “hot.” And yet the mistake is sub-verbal, on the level of imagery, of instinctive reactions. Because the problem doesn’t arise from following a deliberate rule that says “Only think about positive examples,” it can’t be solved just by knowing verbally that “We ought to think about both positive and negative examples.” Which example automatically pops into your head? You have to learn, wordlessly, to zag instead of zig. You have to learn to flinch toward the zero, instead of away from it.

I have been writing for quite some time now on the notion that the strength of a hypothesis is what it can’t explain, not what it can—if you are equally good at explaining any outcome, you have zero knowledge. So to spot an explanation that isn’t helpful, it’s not enough to think of what it does explain very well—you also have to search for results it couldn’t explain, and this is the true strength of the theory.

So I said all this, and then I challenged the usefulness of “emergence” as a concept. One commenter cited superconductivity and ferromagnetism as examples of emergence. I replied that non-superconductivity and nonferromagnetism were also examples of emergence, which was the problem. But be it far from me to criticize the commenter! Despite having read extensively on “confirmation bias,” I didn’t spot the “gotcha” in the 2-4-6 task the first time I read about it. It’s a subverbal blink-reaction that has to be retrained. I’m still working on it myself.

So much of a rationalist’s skill is below the level of words. It makes for challenging work in trying to convey the Art through words. People will agree with you, but then, in the next sentence, do something subdeliberative that goes in the opposite direction. Not that I’m complaining! A major reason I’m writing this is to observe what my words haven’t conveyed.

Are you searching for positive examples of positive bias right now, or sparing a fraction of your search on what positive bias should lead you to not see? Did you look toward light or darkness?