## 计划谬误

丹佛国际机场比原计划晚了16个月才开业，超支20亿美元。<sup>1</sup>

欧洲战斗机台风项目是多个欧洲国家联合的国防项目，交付时间比原计划晚了54个月，花费190亿美元，而原预算仅为70亿美元。

悉尼歌剧院或许是史上最传奇的建设超支案例，最初预计1963年完工，预算为700万美元，最终于1973年完工，总花费达1.02亿美元。<sup>2</sup>

这些是被选择性关注带到我们面前的孤立灾难吗？它们是官僚主义或政府激励失灵的症状吗？是的，很可能如此。但还有一种相应的认知偏差，在个体规划者的实验中也被反复验证。

Buehler 等人让他们的学生估算自己完成学术项目的时间。<sup>3</sup> 具体来说，研究者让学生分别估算他们有50%、75%和99%把握完成项目的时间。你能猜到有多少学生在自己设定的50%、75%和99%概率时间点前完成了吗？

- 只有13%的学生在自己设定的50%概率时间前完成；
- 19%在75%概率时间前完成；
- 而只有45%（不到一半！）在99%概率时间前完成。

正如 Buehler 等人所写：“99%概率水平的结果尤其引人注目：即使要求做出极为保守的预测——一种他们几乎确信能实现的预测——学生们对自己时间估算的信心远远超过了实际完成情况。”<sup>4</sup>

更普遍地说，这种现象被称为“计划谬误”。计划谬误就是人们以为自己能做好计划，哈哈。

Newby-Clark 等人揭示了计划算法背后的根本问题：

- 让受试者基于现实的“最佳猜测”情景做预测；
- 让受试者基于他们期望的“最佳情况”情景做预测……

……结果几乎没有区别。<sup>5</sup>

当人们被要求给出“现实”情景时，他们想象一切都按计划进行，没有任何意外延误或突发灾难——和他们的“最佳情况”设想完全一样。

而现实往往比“最坏情况”还要糟糕。

与大多数认知偏差不同，我们知道一个不错的去偏差方法来应对计划谬误。它对丹佛国际机场那种大项目没用，但对很多个人计划，甚至一些小型组织事务都有效。只需用“外部视角”替代“内部视角”。

人们倾向于通过思考手头任务的特殊、独特特征，并构建完成任务的情景来做预测——这正是我们通常所说的“计划”。

当你想完成某件事时，你会计划在哪里、何时、如何做；估算需要多少时间和资源；想象从开始到成功结束的每一步。这些都是“内部视角”，但它没有考虑到意外延误和突发灾难。正如我们之前看到的，让人们想象“最坏情况”也不足以抵消他们的乐观——他们想象的“墨菲定律”还不够多。

“外部视角”则是你有意避免考虑这个项目的特殊性，只问过去类似项目一般花了多长时间。这种做法违反直觉，因为“内部视角”有更多细节——人们容易以为，越详细、越充分利用所有数据的预测会更准确。

但实验表明，受试者想象得越详细，反而越乐观（也越不准确）。Buehler 等人让一组受试者详细描述圣诞购物的具体计划——在哪里、何时、如何购物。<sup>6</sup> 这组人平均预计会在圣诞节前一周多完成购物。另一组只被问预计何时完成圣诞购物，平均回答是提前四天。两组实际上都在圣诞节前三天完成了购物。

同样，Buehler 等人报告的一项跨文化研究发现，日本学生预计会在截止日期前十天完成论文，实际上他们只提前一天完成。当被问及以往完成类似任务的时间时，他们回答“截止日前一天”。这就是外部视角胜过内部视角的力量。

类似的发现还有：有经验的外部观察者，虽然了解细节较少，但有相关记忆可供参考，往往比实际的计划者和执行者更不乐观，也更准确。

因此，如果你做的事情大致类似于以往某类项目，有一种相当可靠的方法可以修正计划谬误。只需问：过去类似项目一般花了多长时间，不要考虑这个项目的特殊性。更好的是，问一位有经验的外部人士，类似项目一般花了多久。

你会得到一个听起来吓人地长的答案，显然没有考虑到这个任务为什么会更快的特殊理由。这个答案才是真实的。接受它吧。

---

<sup>1</sup>我也看到有人声称（金额）高达 31 亿美元。
<sup>2</sup>Buehler, Griffin, and Ross, “Exploring the ‘Planning Fallacy,”’ 1994.
<sup>3</sup>Buehler, Griffin, and Ross, “It’s About Time,” 1995.
<sup>4</sup>Buehler, Griffin, and Ross, “Inside the Planning Fallacy,” 2002.
<sup>5</sup>Newby-Clark et al., “People Focus on Optimistic Scenarios and Disregard Pessimistic Scenarios While Predicting Task Completion Times,” 2000.
<sup>6</sup>Buehler, Griffin, and Ross, “Inside the Planning Fallacy,” 2002.

---

## Planning Fallacy

The Denver International Airport opened 16 months late, at a cost overrun of \$2 billion.<sup>1</sup>

The Eurofighter Typhoon, a joint defense project of several European countries, was delivered 54 months late at a cost of \$19 billion instead of \$7 billion.

The Sydney Opera House may be the most legendary construction overrun of all time, originally estimated to be completed in 1963 for \$7 million, and finally completed in 1973 for \$102 million.<sup>2</sup>

Are these isolated disasters brought to our attention by selective availability? Are they symptoms of bureaucracy or government incentive failures? Yes, very probably. But there’s also a corresponding cognitive bias, replicated in experiments with individual planners.

Buehler et al. asked their students for estimates of when they (the students) thought they would complete their personal academic projects.<sup>3</sup> Specifically, the researchers asked for estimated times by which the students thought it was 50%, 75%, and 99% probable their personal projects would be done. Would you care to guess how many students finished on or before their estimated 50%, 75%, and 99% probability levels?

- 13% of subjects finished their project by the time they had assigned a 50% probability level; 
- 19% finished by the time assigned a 75% probability level;
- and only 45% (less than half!) finished by the time of their 99% probability level.

As Buehler et al. wrote, “The results for the 99% probability level are especially striking: Even when asked to make a highly conservative forecast, a prediction that they felt virtually certain that they would fulfill, students’ confidence in their time estimates far exceeded their accomplishments.”<sup>4</sup>

More generally, this phenomenon is known as the “planning fallacy.” The planning fallacy is that people think they can plan, ha ha.

A clue to the underlying problem with the planning algorithm was uncovered by Newby-Clark et al., who found that

- Asking subjects for their predictions based on realistic “best guess”scenarios; and
- Asking subjects for their hoped-for “best case” scenarios . . .

. . . produced indistinguishable results.<sup>5</sup>

When people are asked for a “realistic” scenario, they envision everything going exactly as planned, with no unexpected delays or unforeseen catastrophes—the same vision as their “best case.”

Reality, it turns out, usually delivers results somewhat worse than the “worst case.”

Unlike most cognitive biases, we know a good debiasing heuristic for the planning fallacy. It won’t work for messes on the scale of the Denver International Airport, but it’ll work for a lot of personal planning, and even some small-scale organizational stuff. Just use an “outside view” instead of an “inside view.”

People tend to generate their predictions by thinking about the particular, unique features of the task at hand, and constructing a scenario for how they intend to complete the task—which is just what we usually think of as planning.

When you want to get something done, you have to plan out where, when, how; figure out how much time and how much resource is required; visualize the steps from beginning to successful conclusion. All this is the “inside view,” and it doesn’t take into account unexpected delays and unforeseen catastrophes. As we saw before, asking people to visualize the “worst case” still isn’t enough to counteract their optimism—they don’t visualize enough Murphyness.

The outside view is when you deliberately avoid thinking about the special, unique features of this project, and just ask how long it took to finish broadly similar projects in the past. This is counterintuitive, since the inside view has so much more detail—there’s a temptation to think that a carefully tailored prediction, taking into account all available data, will give better results.

But experiment has shown that the more detailed subjects’ visualization, the more optimistic (and less accurate) they become. Buehler et al. asked an experimental group of subjects to describe highly specific plans for their Christmas shopping—where, when, and how.<sup>6</sup> On average, this group expected to finish shopping more than a week before Christmas. Another group was simply asked when they expected to finish their Christmas shopping, with an average response of four days. Both groups finished an average of three days before Christmas.

Likewise, Buehler et al., reporting on a cross-cultural study, found that Japanese students expected to finish their essays ten days before deadline. They actually finished one day before deadline. Asked when they had previously completed similar tasks, they responded, “one day before deadline.” This is the power of the outside view over the inside view.

A similar finding is that experienced outsiders, who know less of the details, but who have relevant memory to draw upon, are often much less optimistic and much more accurate than the actual planners and implementers.

So there is a fairly reliable way to fix the planning fallacy, if you’re doing something broadly similar to a reference class of previous projects. Just ask how long similar projects have taken in the past, without considering any of the special properties of this project. Better yet, ask an experienced outsider how long similar projects have taken.

You’ll get back an answer that sounds hideously long, and clearly reflects no understanding of the special reasons why this particular task will take less time. This answer is true. Deal with it.

---

<sup>1</sup>I’ve also seen $3.1 billion asserted.
<sup>2</sup>Buehler, Griffin, and Ross, “Exploring the ‘Planning Fallacy,”’ 1994.
<sup>3</sup>Buehler, Griffin, and Ross, “It’s About Time,” 1995.
<sup>4</sup>Buehler, Griffin, and Ross, “Inside the Planning Fallacy,” 2002.
<sup>5</sup>Newby-Clark et al., “People Focus on Optimistic Scenarios and Disregard Pessimistic Scenarios While Predicting Task Completion Times,” 2000.
<sup>6</sup>Buehler, Griffin, and Ross, “Inside the Planning Fallacy,” 2002.