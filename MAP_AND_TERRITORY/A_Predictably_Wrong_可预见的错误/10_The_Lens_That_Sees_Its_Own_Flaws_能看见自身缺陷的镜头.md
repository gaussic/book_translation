## 能看见自身缺陷的镜头

阳光发出光线，照射到你的鞋带上并反射回来；一些光子进入你的瞳孔，击中你的视网膜；光子的能量触发神经冲动；神经冲动被传递到大脑的视觉处理区域；在那里，光学信息被处理并重建为一个三维模型，被识别为一根松开的鞋带；于是你相信你的鞋带松了。

这就是有意理性的秘密——整个过程并不是魔法，你是可以理解它的。你可以理解自己是如何看到鞋带的。你可以思考，哪些思维过程会产生与现实相符的信念，哪些则不会。

老鼠能看见，但它们无法理解“看见”这件事。而你能理解“看见”，正因如此，你能做到老鼠做不到的事。请花点时间惊叹一下吧，这确实很神奇。

老鼠能看见，但它们不知道自己有视觉皮层，因此无法纠正视觉错觉。老鼠的心理世界里有猫、洞、奶酪和捕鼠器——但没有“老鼠大脑”这个概念。它们的相机不会给自己的镜头拍照。但我们人类可以看到一幅看似奇怪的图像，并意识到我们看到的部分其实是镜头本身。你不必总是相信自己的眼睛，但你必须意识到自己有眼睛——你必须在心里区分“地图与领地”、“感官与现实”。别以为这是一项微不足道的能力，要知道在动物界这是极其罕见的。

科学的全部思想，其实就是对让你头脑内容更好映射世界内容的过程进行反思性推理。这是老鼠永远不会发明的东西。思考“做可重复实验以证伪理论”这件事，我们就能明白它为何有效。科学不是某种远离现实生活、普通人无法理解的独立权威。科学不仅仅适用于实验室内部。科学本身，是一种可以理解的、存在于世界中的过程，它让大脑与现实产生关联。

当你思考科学时，它是有道理的。但老鼠无法思考“思考”本身，这也是它们没有科学的原因。我们不应忽视这一点的奇妙——也不要忽视它赋予我们个人的潜在力量，而不仅仅是科学共同体的力量。

当然，理解思维引擎可能比理解蒸汽机复杂一些——但本质上并没有什么不同。

曾经有一次，我去 EFNet 的 #philosophy 聊天室问：“你认为未来20年内会发生核战争吗？如果不会，为什么？”有个人回答说他觉得未来100年都不会有核战争，因为“目前所有参与核战争决策的人都没有兴趣”。我问：“那你为什么要把这个判断延长到100年？”他答：“纯粹是希望。”

反思整个思考过程，我们可以理解为什么“核战争”这个想法让那个人感到不快，也能理解他的大脑因此拒绝相信它。但如果你想象有十亿个世界——比如 Everett 分支，或 Tegmark 的平行宇宙<sup>1</sup>——这种思考过程并不会系统性地把乐观主义者分配到没有核战争发生的分支上。<sup>2</sup>

去问“哪些信念会让你快乐”，其实是向内而不是向外——它告诉你一些关于自己的信息，但并不是与环境纠缠的证据。我并不反对幸福，但幸福应该来自你对世界的认知，而不是去篡改你心中的画笔。

如果你能看到这一点——如果你能看到希望让你的第一层思考偏离得太多——如果你能理解你的大脑是一台有缺陷的制图引擎——那么你就可以进行反思性的修正。大脑是一块有缺陷的镜头，用来观察现实。这对老鼠和人类的大脑都成立。但人类大脑是一块能理解自身缺陷的镜头——能理解自己的系统性错误和偏见，并对它们进行二阶修正。实际上，这让这块镜头变得更强大。不是完美，但强大得多。

---

<sup>1</sup> Tegmark, “Parallel Universes,” 2004, http://arxiv.org/abs/astro-ph/0302131.
<sup>2</sup> 总会有聪明人说：“啊，但因为我有希望，我会更努力工作，推动全球经济，从而帮助防止国家陷入愤怒和绝望的状态，避免核战争的可能性。所以这两件事其实是有关联的。”这时，我们就得用贝叶斯定理来定量衡量这种关系。你的乐观性格不可能对世界产生那么大的影响；它本身无法让核战争的概率降低20%，或者说无法像你的乐观性格改变信念那样大幅降低概率。仅仅因为某个事件只略微增加了你判断正确的概率，却让你大幅调整信念，最终只会让你的“地图”变得更糟。

---

## The Lens That Sees Its Own Flaws

Light leaves the Sun and strikes your shoelaces and bounces off; some photons enter the pupils of your eyes and strike your retina; the energy of the photons triggers neural impulses; the neural impulses are transmitted to the visual-processing areas of the brain; and there the optical information is processed and reconstructed into a 3D model that is recognized as an untied shoelace; and so you believe that your shoelaces are untied.

Here is the secret of deliberate rationality—this whole process is not magic, and you can understand it. You can understand how you see your shoelaces. You can think about which sort of thinking processes will create beliefs which mirror reality, and which thinking processes will not. 

Mice can see, but they can’t understand seeing. You can understand seeing, and because of that, you can do things that mice cannot do. Take a moment to marvel at this, for it is indeed marvelous.

Mice see, but they don’t know they have visual cortexes, so they can’t correct for optical illusions. A mouse lives in a mental world that includes cats, holes, cheese and mousetraps—but not mouse brains. Their camera does not take pictures of its own lens. But we, as humans, can look at a seemingly bizarre image, and realize that part of what we’re seeing is the lens itself. You don’t always have to believe your own eyes, but you have to realize that you have eyes—you must have distinct mental buckets for the map and the territory, for the senses and reality. Lest you think this a trivial ability, remember how rare it is in the animal kingdom.

The whole idea of Science is, simply, reflective reasoning about a more reliable process for making the contents of your mind mirror the contents of the world. It is the sort of thing mice would never invent. Pondering this business of “performing replicable experiments to falsify theories,” we can see why it works. Science is not a separate magisterium, far away from real life and the understanding of ordinary mortals. Science is not something that only applies to the inside of laboratories. Science, itself, is an understandable process-in-the-world that correlates brains with reality.

Science makes sense, when you think about it. But mice can’t think about thinking, which is why they don’t have Science. One should not overlook the wonder of this—or the potential power it bestows on us as individuals, not just scientific societies.

Admittedly, understanding the engine of thought may be a little more complicated than understanding a steam engine—but it is not a fundamentally different task.

Once upon a time, I went to EFNet’s #philosophy chatroom to ask, “Do you believe a nuclear war will occur in the next 20 years? If no, why not?” One person who answered the question said he didn’t expect a nuclear war for 100 years, because “All of the players involved in decisions regarding nuclear war are not interested right now.” “But why extend that out for 100 years?” I asked. “Pure hope,” was his reply.

Reflecting on this whole thought process, we can see why the thought of nuclear war makes the person unhappy, and we can see how his brain therefore rejects the belief. But if you imagine a billion worlds—Everett branches, or Tegmark duplicates<sup>1</sup>—this thought process will not systematically correlate optimists to branches in which no nuclear war occurs.<sup>2</sup>

To ask which beliefs make you happy is to turn inward, not outward—it tells you something about yourself, but it is not evidence entangled with the environment. I have nothing against happiness, but it should follow from your picture of the world, rather than tampering with the mental paintbrushes.

If you can see this—if you can see that hope is shifting your first-order thoughts by too large a degree—if you can understand your mind as a mapping engine that has flaws—then you can apply a reflective correction. The brain is a flawed lens through which to see reality. This is true of both mouse brains and human brains. But a human brain is a flawed lens that can understand its own flaws—its systematic errors, its biases—and apply second-order corrections to them. This, in practice, makes the lens far more powerful. Not perfect, but far more powerful.

---

<sup>1</sup>Tegmark, “Parallel Universes,” 2004, http://arxiv.org/abs/astro-ph/0302131.
<sup>2</sup>Some clever fellow is bound to say, “Ah, but since I have hope, I’ll work a little harder at my job, pump up the global economy, and thus help to prevent countries from sliding into the angry and hopeless state where nuclear war is a possibility. So the two events are related after all.” At this point, we have to drag in Bayes’s Theorem and measure the relationship quantitatively. Your optimistic nature cannot have that large an effect on the world; it cannot, of itself, decrease the probability of nuclear war by 20%, or however much your optimistic nature shifted your beliefs. Shifting your beliefs by a large amount, due to an event that only slightly increases your chance of being right, will still mess up your mapping.