## 群体信念的“蒸发冷却”效应

早期研究邪教的人发现了一个令人惊讶的现象：当邪教遭遇重大打击——比如预言没有实现，或者创始人被揭露有道德污点——他们往往会变得比以前更强大，信仰和狂热程度反而提升。耶和华见证人曾根据圣经推算世界末日将在1975年到来，1975年过去了，什么也没发生。Unarian 邪教至今依然活跃，尽管1975年9月27日那天并没有出现银河舰队。

为什么一个群体的信念在遭遇毁灭性反证后反而会变得更强？

对此现象的传统解释是“认知失调”。当人们为信仰做出“不可逆转”的行动——比如把所有财产都捐出去，等待飞碟降临——他们就无法承认自己错了。信仰受到挑战会带来巨大的认知失调，他们必须找到强化信念的理由来对抗打击，于是变得更加狂热。在这种解释下，群体狂热的增强是个体狂热增强的结果。

有一次我在看一个用蒸发冷却形成玻色-爱因斯坦凝聚态的 Java 小程序时，突然想到，可能还有另一种完全不同的机制会导致狂热增强。蒸发冷却会在一群高能原子周围形成一个势能屏障。热能本质上是统计性的——不是所有原子的速度都一样。每个原子的动能会因碰撞而变化。如果你设置的势能屏障略高于平均热能，偶尔就会有原子获得足够高的动能逃出陷阱。当一个异常高速的原子逃离时，它带走了大量动能，剩下的原子平均能量就降低了。这样，群体的“温度”会比势能屏障还低。

在 Festinger、Riecken 和 Schachter 的经典著作《预言落空时》中，有个邪教成员在飞碟没有降临后立刻离开了。谁会第一个受不了而离开？是普通成员，还是原本就更怀疑、曾经在群体中起到缓和作用的成员？

当动能最高的成员离开后，剩下的讨论就只剩下极端狂热者和稍微没那么极端的狂热者，群体的共识会落在这两者之间的“中间”。

如果要把这个类比延伸到玻色-爱因斯坦凝聚态的坍缩，其实没必要非要这么做。但你可能还记得，我曾用裂变链式反应来类比情感死亡螺旋；当一个群体把所有温和的声音都排除出去，剩下的人互相鼓励、压制异见，群体内部的平均狂热程度就会上升。<sup>1</sup>

当安·兰德与 Nathaniel Branden 的长期婚外情被客观主义圈子揭露后，相当一部分成员脱离了原组织，跟随 Branden 支持一种不那么紧密依附于兰德本人的“开放体系”客观主义。丑闻爆发后，谁还留在兰德身边？是那些真正、极度相信她的人——也许还有一些原本犹豫不决的人，在温和派离开后，只能听到一方的声音。这也许解释了为什么据说分裂后的安·兰德研究所比原先兰德和 Branden 领导下的核心圈子更加狂热。

几年前，我在一个超人类主义邮件列表上，看到一小群“社会民主超人类主义者”恶毒攻击列表上的每一个自由意志主义者。大多数自由意志主义者离开了邮件列表，剩下的人也不再发言。结果，剩下的群体整体大幅左倾。这是有意为之吗？大概不是，因为我觉得那些人并不懂多少心理学。<sup>2</sup> 他们最多只是想让自己在更小的池塘里当“大鱼”。

这也是为什么我们要有意识地偏向于容忍异见。在你觉得有充分理由把某人踢出群体后，最好再等一段时间再真正动手。如果你把原来的“异类”都清理掉，群体立场就会转移，接下来又会有新的“异类”出现。如果你也把他们踢掉，你就离“玻色-爱因斯坦凝聚态”不远了，甚至可能“爆炸”。

反过来说：Thomas Kuhn 认为，一门科学只有成为“范式”，拥有排除外人的技术语言后，才能真正取得进展。在科学的形成阶段，成员会极力让自己的工作对外部学者易于理解。但（据 Kuhn 说）只有当科学放弃对外部可理解性的要求，范式内的科学家默认彼此熟悉大量技术内容时，科学才能作为技术学科取得真正进步。相较于通常关于科学公众理解的说法，这听起来有些犬儒，但我确实能看到其中的道理。<sup>3</sup>

---

<sup>1</sup>这里没有热力学类比，除非有人发明出遇冷就爆炸的核武器。

<sup>1</sup>顺便说一句，我没见过别处用“蒸发冷却”这个类比，但这不代表没人提过。

<sup>1</sup>我自己的互联网社区管理理论是：你必须愿意踢掉喷子和垃圾信息，才能让讨论顺利进行。如果你想让技术邮件列表有产出，甚至要愿意把善意但技术不懂的人请出去。真正开放的网络讨论会迅速退化。按这个理论，最该谨慎踢掉的是能言善辩的“喷子”——他们实际上起到了让温和异见合法化的作用。但你也不能让能言善辩的喷子太多，否则他们会互相争吵，主导讨论。如果你有一个“著名的反对一切的人”，那么其他更温和的异见者就不会显得那么突出。这个理论在实践中未必总是有效，所以请谨慎参考。

---

## Evaporative Cooling of Group Beliefs

Early studiers of cults were surprised to discover than when cults receive a major shock—a prophecy fails to come true, a moral flaw of the founder is revealed—they often come back stronger than before, with increased belief and fanaticism. The Jehovah’s Witnesses placed Armageddon in 1975, based on Biblical calculations; 1975 has come and passed. The Unarian cult, still going strong today, survived the nonappearance of an intergalactic spacefleet on September 27, 1975.

Why would a group belief become stronger after encountering crushing counterevidence?

The conventional interpretation of this phenomenon is based on cognitive dissonance. When people have taken “irrevocable” actions in the service of a belief—given away all their property in anticipation of the saucers landing—they cannot possibly admit they were mistaken. The challenge to their belief presents an immense cognitive dissonance; they must find reinforcing thoughts to counter the shock, and so become more fanatical. In this interpretation, the increased group fanaticism is the result of increased individual fanaticism.

I was looking at a Java applet which demonstrates the use of evaporative cooling to form a Bose-Einstein condensate, when it occurred to me that another force entirely might operate to increase fanaticism. Evaporative cooling sets up a potential energy barrier around a collection of hot atoms. Thermal energy is essentially statistical in nature—not all atoms are moving at the exact same speed. The kinetic energy of any given atom varies as the atoms collide with each other. If you set up a potential energy barrier that’s just a little higher than the average thermal energy, the workings of chance will give an occasional atom a kinetic energy high enough to escape the trap. When an unusually fast atom escapes, it takes with it an unusually large amount of kinetic energy, and the average energy decreases. The group becomes substantially cooler than the potential energy barrier around it.

In Festinger, Riecken, and Schachter’s classic When Prophecy Fails, one of the cult members walked out the door immediately after the flying saucer failed to land. Who gets fed up and leaves first? An average cult member? Or a relatively skeptical member, who previously might have been acting as a voice of moderation, a brake on the more fanatic members?

After the members with the highest kinetic energy escape, the remaining discussions will be between the extreme fanatics on one end and the slightly less extreme fanatics on the other end, with the group consensus somewhere in the “middle.”

And what would be the analogy to collapsing to form a Bose-Einstein condensate? Well, there’s no real need to stretch the analogy that far. But you may recall that I used a fission chain reaction analogy for the affective death spiral; when a group ejects all its voices of moderation, then all the people encouraging each other, and suppressing dissents, may internally increase in average fanaticism.<sup>1</sup>

When Ayn Rand’s long-running affair with Nathaniel Branden was revealed to the Objectivist membership, a substantial fraction of the Objectivist membership broke off and followed Branden into espousing an “open system” of Objectivism not bound so tightly to Ayn Rand. Who stayed with Ayn Rand even after the scandal broke? The ones who really, really believed in her—and perhaps some of the undecideds, who, after the voices of moderation left, heard arguments from only one side. This may account for how the Ayn Rand Institute is (reportedly) more fanatical after the breakup than the original core group of Objectivists under Branden and Rand.

A few years back, I was on a transhumanist mailing list where a small group espousing “social democratic transhumanism” vitriolically insulted every libertarian on the list. Most libertarians left the mailing list; most of the others gave up on posting. As a result, the remaining group shifted substantially to the left. Was this deliberate? Probably not, because I don’t think the perpetrators knew that much psychology.<sup>2</sup> At most, they might have thought to make themselves “bigger fish in a smaller pond.”

This is one reason why it’s important to be prejudiced in favor of tolerating dissent. Wait until substantially after it seems to you justified in ejecting a member from the group, before actually ejecting. If you get rid of the old outliers, the group position will shift, and someone else will become the oddball. If you eject them too, you’re well on the way to becoming a Bose-Einstein condensate and, er, exploding.

The flip side: Thomas Kuhn believed that a science has to become a “paradigm,” with a shared technical language that excludes outsiders, before it can get any real work done. In the formative stages of a science, according to Kuhn, the adherents go to great pains to make their work comprehensible to outside academics. But (according to Kuhn) a science can only make real progress as a technical discipline once it abandons the requirement of outside accessibility, and scientists working in the paradigm assume familiarity with large cores of technical material in their communications. This sounds cynical, relative to what is usually said about public understanding of science, but I can definitely see a core of truth here.<sup>3</sup>

---

<sup>1</sup>No thermodynamic analogy here, unless someone develops a nuclear weapon that explodes when it gets cold.

<sup>1</sup>For that matter, I can’t recall seeing the evaporative cooling analogy elsewhere, though that doesn’t mean it hasn’t been noted before.

<sup>1</sup>My own theory of Internet moderation is that you have to be willing to exclude trolls and spam to get a conversation going. You must even be willing to exclude kindly but technically uninformed folks from technical mailing lists if you want to get any work done. A genuinely open conversation on the Internet degenerates fast. It’s the articulate trolls that you should be wary of ejecting, on this theory—they serve the hidden function of legitimizing less extreme disagreements. But you should not have so many articulate trolls that they begin arguing with each other, or begin to dominate conversations. If you have one person around who is the famous Guy Who Disagrees With Everything, anyone with a more reasonable, more moderate disagreement won’t look like the sole nail sticking out. This theory of Internet moderation may not have served me too well in practice, so take it with a grain of salt.