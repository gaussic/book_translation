## 抵抗情感死亡螺旋

从前，有个人坚信自己拥有一个伟大的想法。随着他越想越多，他意识到这不仅仅是个好主意，而是有史以来最美妙的主意。这个伟大的想法能揭开宇宙的奥秘，取代腐败且错误百出的权威体制，赋予持有者近乎魔法般的力量，能让饥饿者吃饱，让病人痊愈，让整个世界变得更美好，等等等等。

这个人就是弗朗西斯·培根，他的伟大想法就是科学方法，而他也是历史上唯一一个声称能为人类带来如此巨大福祉并且完全说对了的“怪人”。<sup>1</sup>

这就是你决定“永远不要如此崇拜任何事物”时的问题：有些想法确实值得如此崇拜。虽然还没有人实现比培根更大胆的承诺；至少目前还没有。

但我们又该如何抵抗对科学本身的情感死亡螺旋呢？情感死亡螺旋始于你认为某事物极其美好，光环效应让你不断发现更多优点，于是你觉得它更加美好，如此循环，最终陷入无底深渊。如果科学真的如此有益，以至于我们无法承认它的真正荣耀而还能保持理智，那该怎么办？这听起来很美好，不是吗？哦不，螺旋要开始了，快跑啊……

如果你调用标准的“不要过度崇拜科学”的深刻智慧，你会想到诸如“科学给了我们空调，但也造出了氢弹”或者“科学能告诉我们星星和生物，但永远无法证明或证伪我车库里的龙”之类的话。但最早说出这些话的人，并不是为了抵抗情感死亡螺旋。他们并不担心自己对科学的崇拜会失控。很可能是他们不喜欢科学对自己心爱信念的挑战，于是想办法削弱科学的权威。

这些关于科学的负面说法，对那些真正感受到科学带来振奋的人并没有吸引力——这本来也不是说给他们听的。所以我们得另找别的负面说法。

但如果你刻意去找科学的缺点——即使是为了抵抗情感死亡螺旋——你不就等于是在合理化吗？如果你知道自己是在操纵自己，为什么还要相信自己的想法？

我通常对那些声称可以用一种偏见抵消另一种偏见的人持怀疑态度。这听起来就像修车工说你右边雨刷的马达坏了，但他不修，而是把左边雨刷也弄坏来“平衡”。这种聪明反被聪明误的做法只会让你自食其果。无论解决方案是什么，都应该是相信真实的东西，而不是让自己相信明知是假的东西。

你能不能通过把对科学的崇拜限制在某个狭窄领域来防止情感死亡螺旋？情感死亡螺旋的一部分，就是把伟大想法投射到各个领域——比如认为只要给共产主义机会，它就能治愈癌症。最可靠的邪教大师特征之一，就是他不仅在某一领域，甚至不是一组相关领域，而是对一切都自称专家。他知道信徒该吃什么、穿什么、做什么工作、和谁上床、该看什么艺术、听什么音乐……

可惜的是，大多数人试图给科学划定“安全小圈子”时都会失败。常见的伎俩，比如“科学治不了癌症”，根本站不住脚。“科学对父母对孩子的爱无话可说”——很抱歉，这也是错的。如果你试图把科学和比如父母之爱割裂开来，你不仅是否定了认知科学和进化心理学，还是否定了 Martine Rothblatt 为了给女儿治病而创办 United Therapeutics 的事实。科学以某种方式，确实和人类生活的几乎每个重要方面都有关系。

那么，有没有什么关于科学的“虚假美好说法”呢？

在我看来，有一种虚假说法是：科学如此伟大，以至于科学家根本不需要为自己的工作承担伦理责任——反正最后都会变好。这其实误解了科学造福人类的过程。科学家是人，他们和大多数人一样有亲社会关怀，这至少是科学最终利大于弊的部分原因。

但这一点显然也有争议。那么再举个更简单的虚假美好说法：“只要发表足够多的论文，癌症患者就能痊愈。”或者：“只要反社会者承诺永远不相信未经p<0.05重复实验的数据，他们就能变成正常人。”

避免相信这些说法的方法，不是给科学设定情感上限，觉得科学只是“还不错”；也不是刻意去找理由相信“发表论文会导致癌症”；更不是相信科学对癌症无话可说。

而是，如果你足够具体地了解科学的运作方式，你就会知道，“科学可以治愈癌症”也许没错，但一个癌症患者自己写论文并不会奇迹般痊愈。这个具体的因果链根本行不通。

情感死亡螺旋之所以是情感问题，是因为感知问题——光环效应——让我们在接受了一个正面说法后，更容易接受下一个正面说法。我们无法仅凭意愿消除这种效应，它大概永远都会影响我们。但我们可以学会慢下来、停下来，把每一个额外的美好说法都当作额外的负担，专注于说法的具体细节，而不是它的正面情感。

如果某个具体的美好说法“无法证伪”，但“有正反两方面的论据”，那你就要小心了，因为这往往意味着人们在反复演练证据，或者回避真正的薄弱点。考虑到情感死亡螺旋的危险，最好不要对尚未定论的说法感到高兴——不要让它们成为你喜欢的事物的又一个正面情感来源。

情感死亡螺旋之所以是大问题，是因为正反馈太强，过程可能失控。你也许无法彻底消除光环效应，但你可以用足够的批判性思维让光环效应保持在“亚临界”——确保共振最终会消散，而不是爆炸。

你甚至可以说，整个问题的根源在于人们一旦接受了某个核心前提，就不再批判性地审视每一个额外的细节——不再要求足够的证据来抵消复杂性，不再同时寻找漏洞和支持，不再激发好奇心。如果没有合取谬误，也许还会有光环效应，但不会有情感死亡螺旋。<sup>3</sup>

即使是宇宙中最美好的事物，一个完美的理性主义者如果对每一个额外（正面）说法都要求恰当的证据，就不会产生情感共振。你做不到完全如此，但你可以足够接近理性，避免幸福感失控。<sup>4</sup>

Stuart Armstrong 给出了类似的建议：<sup>5</sup>

把你的伟大想法拆分成更小、更独立的观点，并分别对待。

比如，一个马克思主义者可以把马克思的伟大理论拆分为劳动价值论、阶级政治关系理论、工资理论、人类最终政治状态理论。然后每一项都要独立评估，某一项的真假不应影响其他项。如果我们能做到这一点，就能避免陷入螺旋，因为每个理论都太狭窄，不足以单独引发螺旋。

这在比喻上，就像防止亚临界的钚块聚在一起。三个伟大想法远比一个伟大想法更难让你疯狂。Armstrong 的建议还有助于促进具体化：一旦有人说“发表足够多论文能治愈你的癌症”，你就可以问：“这是实验方法的好处吗？如果是，癌症在哪个实验阶段被治愈？还是说这是科学作为社会过程的好处？如果是，那它依赖于科学家想治愈癌症，还是他们可以只为自己？”希望这能让你远离情感，而关注混乱和证据不足。

总结一下，避免情感死亡螺旋的方法包括：

- 把伟大想法拆分成部分；
- 把每一个额外细节都当作负担；
- 关注因果链的具体细节，而不是好坏感受；
- 不要反复演练证据；
- 不要因为“你无法证明它错”就增加幸福感；
但不要通过：
- 拒绝过度欣赏任何事物；
- 有偏见地搜寻负面点直到自己又不开心为止；
- 强行把一个想法塞进安全的小盒子。

---

<sup>1</sup>当然，培根不是科学的唯一发明者，但他确实做出了贡献，也许是第一个意识到其力量的人。

<sup>2</sup>而且她真的成功了。

<sup>3</sup>更多背景可参见《负担性细节》《需要多少证据？》和《奥卡姆剃刀》（见前一卷《地图与领地》）。

<sup>4</sup>真正危险的情况是，任何对伟大事物正面说法的批评都会让人感觉糟糕，或者在社会上不可接受。论据就是士兵；任何正面说法都是“我方士兵”；刺伤自己士兵就是叛国。这时链式反应就会失控。后文还会详细讨论。

<sup>5</sup>来源：http://lesswrong.com/lw/lm/affective_death_spirals/gp5.

---

## Resist the Happy Death Spiral

Once upon a time, there was a man who was convinced that he possessed a Great Idea. Indeed, as the man thought upon the Great Idea more and more, he realized that it was not just a great idea, but the most wonderful idea ever. The Great Idea would unravel the mysteries of the universe, supersede the authority of the corrupt and error-ridden Establishment, confer nighmagical powers upon its wielders, feed the hungry, heal the sick, make the whole world a better place, etc., etc., etc.

The man was Francis Bacon, his Great Idea was the scientific method, and he was the only crackpot in all history to claim that level of benefit to humanity and turn out to be completely right.<sup>1</sup>

That’s the problem with deciding that you’ll never admire anything that much: Some ideas really are that good. Though no one has fulfilled claims more audacious than Bacon’s; at least, not yet.

But then how can we resist the happy death spiral with respect to Science itself? The happy death spiral starts when you believe something is so wonderful that the halo effect leads you to find more and more nice things to say about it, making you see it as even more wonderful, and so on, spiraling up into the abyss. What if Science is in fact so beneficial that we cannot acknowledge its true glory and retain our sanity? Sounds like a nice thing to say, doesn’t it? Oh no it’s starting ruuunnnnn . . .

If you retrieve the standard cached deep wisdom for don’t go overboard on admiring science, you will find thoughts like “Science gave us air conditioning, but it also made the hydrogen bomb” or “Science can tell us about stars and biology, but it can never prove or disprove the dragon in my garage.” But the people who originated such thoughts were not trying to resist a happy death spiral. They weren’t worrying about their own admiration of science spinning out of control. Probably they didn’t like something science had to say about their pet beliefs, and sought ways to undermine its authority.

The standard negative things to say about science aren’t likely to appeal to someone who genuinely feels the exultation of science—that’s not the intended audience. So we’ll have to search for other negative things to say instead.

But if you look selectively for something negative to say about science— even in an attempt to resist a happy death spiral—do you not automatically convict yourself of rationalization? Why would you pay attention to your own thoughts, if you knew you were trying to manipulate yourself?

I am generally skeptical of people who claim that one bias can be used to counteract another. It sounds to me like an automobile mechanic who says that the motor is broken on your right windshield wiper, but instead of fixing it, they’ll just break your left windshield wiper to balance things out. This is the sort of cleverness that leads to shooting yourself in the foot. Whatever the solution, it ought to involve believing true things, rather than believing you believe things that you believe are false.

Can you prevent the happy death spiral by restricting your admiration of Science to a narrow domain? Part of the happy death spiral is seeing the Great Idea everywhere—thinking about how Communism could cure cancer if it were only given a chance. Probably the single most reliable sign of a cult guru is that the guru claims expertise, not in one area, not even in a cluster of related areas, but in everything. The guru knows what cult members should eat, wear, do for a living; who they should have sex with; which art they should look at; which music they should listen to . . .

Unfortunately for this plan, most people fail miserably when they try to describe the neat little box that science has to stay inside. The usual trick, “Hey, science won’t cure cancer,” isn’t going to fly. “Science has nothing to say about a parent’s love for their child”—sorry, that’s simply false. If you try to sever science from e.g. parental love, you aren’t just denying cognitive science and evolutionary psychology. You’re also denying Martine Rothblatt’s founding of United Therapeutics to seek a cure for her daughter’s pulmonary hypertension.<sup>2</sup> Science is legitimately related, one way or another, to just about every important facet of human existence.

All right, so what’s an example of a false nice claim you could make about science?

One false claim, in my humble opinion, is that science is so wonderful that scientists shouldn’t even try to take ethical responsibility for their work—it will turn out well in the end regardless. It appears to me that this misunderstands the process whereby science benefits humanity. Scientists are human; they have prosocial concerns just like most other other people, and this is at least part of why science ends up doing more good than evil.

But that point is, evidently, not beyond dispute. So here’s a simpler false nice claim: “A cancer patient can be cured just through the publishing of enough journal papers.” Or: “Sociopaths could become fully normal, if they just committed themselves to never believing anything without replicated experimental evidence with p < 0.05.”

The way to avoid believing such statements isn’t an affective cap, deciding that science is only slightly nice. Nor searching for reasons to believe that publishing journal articles causes cancer. Nor believing that science has nothing to say about cancer one way or the other.

Rather, if you know with enough specificity how science works, then you know that while it may be possible for “science to cure cancer,” a cancer patient writing journal papers isn’t going to experience a miraculous remission. That specific proposed chain of cause and effect is not going to work out.

The happy death spiral is only an emotional problem because of a perceptual problem, the halo effect, that makes us more likely to accept future positive claims once we’ve accepted an initial positive claim. We can’t get rid of this effect just by wishing; it will probably always influence us a little. But we can manage to slow down, stop, consider each additional nice claim as an additional burdensome detail, and focus on the specific points of the claim apart from its positiveness.

What if a specific nice claim “can’t be disproven” but there are arguments “both for and against” it? Actually these are words to be wary of in general, because often this is what people say when they’re rehearsing the evidence or avoiding the real weak points. Given the danger of the happy death spiral, it makes sense to try to avoid being happy about unsettled claims—to avoid making them into a source of yet more positive affect about something you liked already.

The happy death spiral is only a big emotional problem because of the overly positive feedback, the ability for the process to go critical. You may not be able to eliminate the halo effect entirely, but you can apply enough critical reasoning to keep the halos subcritical—make sure that the resonance dies out rather than exploding.

You might even say that the whole problem starts with people not bothering to critically examine every additional burdensome detail—demanding sufficient evidence to compensate for complexity, searching for flaws as well as support, invoking curiosity—once they’ve accepted some core premise. Without the conjunction fallacy, there might still be a halo effect, but there wouldn’t be a happy death spiral.<sup>3</sup>

Even on the nicest Nice Thingies in the known universe, a perfect rationalist who demanded exactly the necessary evidence for every additional (positive) claim would experience no affective resonance. You can’t do this, but you can stay close enough to rational to keep your happiness from spiraling out of control.<sup>4</sup>

Stuart Armstrong gives closely related advice:<sup>5</sup>

Cut up your Great Thingy into smaller independent ideas, and treat them as independent.

For instance a marxist would cut up Marx’s Great Thingy into a theory of value of labour, a theory of the political relations between classes, a theory of wages, a theory on the ultimate political state of mankind. Then each of them should be assessed independently, and the truth or falsity of one should not halo on the others. If we can do that, we should be safe from the spiral, as each theory is too narrow to start a spiral on its own.

This, metaphorically, is like keeping subcritical masses of plutonium from coming together. Three Great Ideas are far less likely to drive you mad than one Great Idea. Armstrong’s advice also helps promote specificity: As soon as someone says, “Publishing enough papers can cure your cancer,” you ask, “Is that a benefit of the experimental method, and if so, at which stage of the experimental process is the cancer cured? Or is it a benefit of science as a social process, and if so, does it rely on individual scientists wanting to cure cancer, or can they be self-interested?” Hopefully this leads you away from the good or bad feeling, and toward noticing the confusion and lack of support.

To summarize, you do avoid a Happy Death Spiral by:

- Splitting the Great Idea into parts;
- Treating every additional detail as burdensome;
- Thinking about the specifics of the causal chain instead of the good or bad feelings;
- Not rehearsing evidence; and
- Not adding happiness from claims that “you can’t prove are wrong”; but not by:
- Refusing to admire anything too much;
- Conducting a biased search for negative points until you feel unhappy again; or
- Forcibly shoving an idea into a safe box.

---

<sup>1</sup>Bacon didn’t singlehandedly invent science, of course, but he did contribute, and may have been the first to realize the power.

<sup>2</sup>Successfully, I might add.

<sup>3</sup>For more background, see “Burdensome Details,” “How Much Evidence Does it Take?”, and “Occam’s Razor” in the previous volume, Map and Territory.

<sup>4</sup>The really dangerous cases are the ones where any criticism of any positive claim about the Great Thingy feels bad or is socially unacceptable. Arguments are soldiers; any positive claim is a soldier on our side; stabbing your soldiers in the back is treason. Then the chain reaction goes supercritical. More on this later.

<sup>5</sup>Source: http://lesswrong.com/lw/lm/affective_death_spirals/gp5.