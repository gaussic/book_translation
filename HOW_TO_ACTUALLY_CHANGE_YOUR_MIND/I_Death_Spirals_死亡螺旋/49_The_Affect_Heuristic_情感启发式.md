## 情感启发式

情感启发式指的是，我们对好坏的主观印象会作为一种启发式——即快速、感知式判断的来源。愉快和不愉快的感受在人类推理中居于核心地位，而情感启发式带来了许多有趣的偏见——其中一些是我最喜欢的。

让我们从一个相对没那么疯狂的偏见说起。假设你即将搬到一个新城市，需要托运一只古董落地钟。第一种情况，这只钟是你五岁生日时祖父母送的礼物。第二种情况，这只钟是远房亲戚送的，你对它没有特殊感情。如果钟在运输途中丢失，保险公司会赔付100美元。你愿意为这份保险支付多少钱？Hsee 和 Kunreuther 的研究发现，第一种情况下，受试者愿意支付的金额是第二种的两倍多。<sup>1</sup> 这听起来似乎很合理——为什么不为更有价值的物品多付点钱呢？——直到你意识到保险并不能保护钟本身，只是在钟丢失时赔付，而且无论哪只钟，赔付金额都一样。（而且保险公司是外部公司，不会影响搬运工的动机。）

好吧，这听起来还不算太疯狂。也许你可以说，受试者买的是情感安慰，而不是经济补偿。

那再看这个例子：Yamagishi 发现，当一种疾病被描述为“每一万人中有1286人死亡”时，受试者认为它比“致死率为24.14%”的疾病更危险。<sup>2</sup> 显然，脑海中浮现出成千上万具尸体的画面，比起“一个人更可能活下来”要更令人恐惧。

但还没完，情况会更糟。

假设某机场要决定是否花钱购买新设备，而批评者认为这笔钱应该花在机场安全的其他方面。Slovic 等人让两组受试者分别看到支持和反对购买设备的论据，评分从0（完全不支持）到20（非常支持）。<sup>3</sup> 一组看到的描述是“该措施能拯救150条生命”，另一组看到的是“该措施能拯救150条生命中的98%”。实验假设，拯救150条生命听起来模糊——到底多还是少？——而“98%”则很接近百分比的上限，听起来非常好。结果显示，“拯救150条生命”组的平均支持度为10.4，而“拯救98%”组为13.6。

再看 Denes-Raj 和 Epstein 的实验：受试者有机会从一碗糖豆中随机抽取红色糖豆，每抽到一次就能赢1美元。很多人更愿意从红豆数量多但比例更低的碗中抽取，比如100颗中有7颗红豆，而不是10颗中有1颗红豆。<sup>4</sup>

Denes-Raj 和 Epstein 发现，这些受试者事后表示，虽然知道概率对自己不利，但看到更多红豆时感觉中奖机会更大。也许你觉得这很荒谬，亲爱的统计高手，但如果你仔细想想，这其实很有道理。7%和10%的概率虽然差距不小，但红豆数量多带来的“感觉”弥补了概率的劣势。概率更低没错，但你还是觉得更容易赢。你应该好好体会一下，这就是地球上大多数人看待概率的方式。

正如我在《正义的天平，理性的笔记本》中讨论过的，Finucane 等人发现，对于核电站、天然气和食品防腐剂，告知高收益信息会让人们感知到的风险降低；告知高风险信息会让人们感知到的收益降低；其他领域也有类似现象。<sup>5</sup> 人们会把对某件事好/坏某一方面的判断，混合成对整体的好/坏感受。

Finucane 等人还发现，时间压力会极大增强风险与收益感知之间的负相关，这与普遍发现一致：时间压力、信息不足或分心都会让感知性启发式压倒分析性思考。

Ganzach 在金融领域也发现了同样的效应。<sup>6</sup> 按照传统经济理论，回报和风险应该正相关——也就是说，人们愿意为安全投资支付溢价，导致回报降低；股票回报高于债券，但风险也更大。当分析师评估熟悉的股票时，风险和回报的判断呈正相关，符合常规预测。但在评估不熟悉的股票时，分析师往往把股票简单地归为“好”或“坏”——低风险高回报，或高风险低回报。

想进一步了解，推荐阅读 Slovic 的综述文章《理性行为者还是理性傻瓜：情感启发式对行为经济学的启示》。

---

<sup>1</sup>Hsee 和 Kunreuther, “The Affection Effect in Insurance Decisions,” 2000.

<sup>2</sup>Yamagishi, “When a 12.86% Mortality Is More Dangerous than 24.14%,” 1997.

<sup>3</sup>Slovic 等, “Rational Actors or Rational Fools,” 2002.

<sup>4</sup>Denes-Raj 和 Epstein, “Conflict between Intuitive and Rational Processing,” 1994.

<sup>5</sup>Finucane 等, “The Affect Heuristic in Judgments of Risks and Benefits,” 2000.

<sup>6</sup>Ganzach, “Judging Risk and Return of Financial Assets,” 2000.

---

## The Affect Heuristic

The affect heuristic is when subjective impressions of goodness/badness act as a heuristic—a source of fast, perceptual judgments. Pleasant and unpleasant feelings are central to human reasoning, and the affect heuristic comes with lovely biases—some of my favorites.

Let’s start with one of the relatively less crazy biases. You’re about to move to a new city, and you have to ship an antique grandfather clock. In the first case, the grandfather clock was a gift from your grandparents on your fifth birthday. In the second case, the clock was a gift from a remote relative and you have no special feelings for it. How much would you pay for an insurance policy that paid out $100 if the clock were lost in shipping? According to Hsee and Kunreuther, subjects stated willingness to pay more than twice as much in the first condition.<sup>1</sup> This may sound rational—why not pay more to protect the more valuable object?—until you realize that the insurance doesn’t protect the clock, it just pays if the clock is lost, and pays exactly the same amount for either clock. (And yes, it was stated that the insurance was with an outside company, so it gives no special motive to the movers.)

All right, but that doesn’t sound too insane. Maybe you could get away with claiming the subjects were insuring affective outcomes, not financial outcomes—purchase of consolation.

Then how about this? Yamagishi showed that subjects judged a disease as more dangerous when it was described as killing 1,286 people out of every 10,000, versus a disease that was 24.14% likely to be fatal.<sup>2</sup> Apparently the mental image of a thousand dead bodies is much more alarming, compared to a single person who’s more likely to survive than not.

But wait, it gets worse.

Suppose an airport must decide whether to spend money to purchase some new equipment, while critics argue that the money should be spent on other aspects of airport safety. Slovic et al. presented two groups of subjects with the arguments for and against purchasing the equipment, with a response scale ranging from 0 (would not support at all) to 20 (very strong support).<sup>3</sup> One group saw the measure described as saving 150 lives. The other group saw the measure described as saving 98% of 150 lives. The hypothesis motivating the experiment was that saving 150 lives sounds vaguely good—is that a lot? a little?—while saving 98% of something is clearly very good because 98% is so close to the upper bound of the percentage scale. Lo and behold, saving 150 lives had mean support of 10.4, while saving 98% of 150 lives had mean support of 13.6.

Or consider the report of Denes-Raj and Epstein: subjects who were offered an opportunity to win $1 each time they randomly drew a red jelly bean from a bowl often preferred to draw from a bowl with more red beans and a smaller proportion of red beans.<sup>4</sup> E.g., 7 in 100 was preferred to 1 in 10.

According to Denes-Raj and Epstein, these subjects reported afterward that even though they knew the probabilities were against them, they felt they had a better chance when there were more red beans. This may sound crazy to you, oh Statistically Sophisticated Reader, but if you think more carefully you’ll realize that it makes perfect sense. A 7% probability versus 10% probability may be bad news, but it’s more than made up for by the increased number of red beans. It’s a worse probability, yes, but you’re still more likely to win, you see. You should meditate upon this thought until you attain enlightenment as to how the rest of the planet thinks about probability.

As I discussed in “The Scales of Justice, the Notebook of Rationality,” Finucane et al. found that for nuclear reactors, natural gas, and food preservatives, presenting information about high benefits made people perceive lower risks; presenting information about higher risks made people perceive lower benefits; and so on across the quadrants.<sup>5</sup> People conflate their judgments about particular good/bad aspects of something into an overall good or bad feeling about that thing.

Finucane et al. also found that time pressure greatly increased the inverse relationship between perceived risk and perceived benefit, consistent with the general finding that time pressure, poor information, or distraction all increase the dominance of perceptual heuristics over analytic deliberation.

Ganzach found the same effect in the realm of finance.<sup>6</sup> According to ordinary economic theory, return and risk should correlate positively—or to put it another way, people pay a premium price for safe investments, which lowers the return; stocks deliver higher returns than bonds, but have correspondingly greater risk. When judging familiar stocks, analysts’ judgments of risks and returns were positively correlated, as conventionally predicted. But when judging unfamiliar stocks, analysts tended to judge the stocks as if they were generally good or generally bad—low risk and high returns, or high risk and low returns.

For further reading I recommend Slovic’s fine summary article, “Rational Actors or Rational Fools: Implications of the Affect Heuristic for Behavioral Economics.”

---

<sup>1</sup>Hsee and Kunreuther, “The Affection Effect in Insurance Decisions,” 2000.

<sup>2</sup>Yamagishi, “When a 12.86% Mortality Is More Dangerous than 24.14%,” 1997.

<sup>3</sup>Slovic et al., “Rational Actors or Rational Fools,” 2002.

<sup>4</sup>Denes-Raj and Epstein, “Conflict between Intuitive and Rational Processing,” 1994.

<sup>5</sup>Finucane et al., “The Affect Heuristic in Judgments of Risks and Benefits,” 2000.

<sup>6</sup>Ganzach, “Judging Risk and Return of Financial Assets,” 2000.