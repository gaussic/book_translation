## 逐步修正自我

政治是心灵的杀手。辩论就是战争，论据就是士兵。人们总是想方设法把每一个可能的实验结果都解释成支持自己的理论，就像要把城堡的每一条防线都守住一样。但你做不到这一点。这在数学上是不可能的。每一个你预期会出现的证据，都有同等概率出现反证。<sup>1</sup>

但没关系，你珍视的信念不需要做到完美无缺。如果你的假设是硬币正面朝上的概率是95%，那么你就应该预期每二十次里会有一次出现看似反对的证据。这没什么，这很正常，甚至是预期之中的——只要你有十九次支持的观察来对抗一次反对的观察。概率模型可以承受一两次打击，只要打击不会持续不断地出现。<sup>2</sup>

然而，尤其是在舆论场上，人们普遍认为，真正的理论不能有任何失败，错误的理论不能有任何成功。

你会看到有人拿出一条他们认为的证据，声称他们的理论可以“解释”它，好像这就是理论所需要的全部支持。显然，错误的理论不可能有任何支持证据；错误的理论连一个事件都不可能解释。因此，一条支持证据就足够了。

而把一条概率上的反证当作反驳，仿佛正确的理论不可能有哪怕一点点反对意见，这也只稍微好一点。但人类几千年来就是这样争论的——试图击败所有敌方论据，同时否认敌方有哪怕一丝支持。人们希望自己的辩论是一边倒的，习惯于一个他们偏爱的理论没有任何反对证据的世界。因此，哪怕只允许一条概率上的反证，似乎都像世界末日一样。

我敢肯定，观众里一定有人会说：“可你在现实世界里想赢得辩论，哪怕一点都不能让步！只要你承认有反对论据，敌人就会反复纠缠——你不能让敌人有机会！你会输的！还有什么比这更可怕的呢？”

随便吧。理性不是用来赢辩论的，而是用来决定你该站在哪一边。如果你已经决定了要为哪一方辩护，那么理性的工作已经在你心里完成了，无论做得好坏。但你自己该如何决定要为哪一方辩护？如果选错一方让你感到哪怕一丝恐惧，那你最好整合所有证据。

理性不是散步，而是一支舞蹈。每一步都要踩在恰到好处的位置，不偏左也不偏右。每获得一丝支持证据，就把信念提高一点；每获得一丝反对证据，就把信念降低一点。没错，是降低。即使模型是正确的，只要不是完全精确的模型，有时你也需要下调自己的信念。

如果有一两条证据恰好反对你的信念，也没关系。这在概率证据和非精确理论中很常见。（如果精确理论失败了，那你就麻烦了！）只需把信念下调一点——无论是概率、赔率，还是你心里那种非语言的确信权重。只需稍微下调，然后等待更多证据。如果理论是真的，支持证据很快就会到来，概率又会升上去。如果理论是错的，你其实也不想要它。

用非黑即白、二元、定性推理的最大问题在于，任何一次观察都可能摧毁理论，或者完全无关。如果连一条反对观察都不能容忍，就会产生认知失调，只能靠辩解来消解。这就排除了渐进式进步，也排除了对所有证据的正确整合。用概率推理，我们会意识到，平均而言，正确的理论会带来更多支持证据而不是反证。所以你可以毫无畏惧地对自己说：“这是轻微的反对证据，我要下调一点信念。”没错，是下调。这不会摧毁你珍视的理论。那是定性推理；你要学会定量思考。

每一次观察，你都必须平均预期信念下调和上调的幅度是一样的。如果你觉得自己已经知道会得到什么证据，那你对理论的信心已经很高了——概率接近1——这时概率就没多少上升空间了。而无论你觉得遇到反证的可能性有多小，实际下调的幅度也必须足够大，才能和另一边的预期增益精确平衡。你预期的后验概率加权平均，必须等于你的先验概率。

那么，如果你都愿意调查某个问题了，却还害怕下调概率，这有多可笑？平均而言，每次观察你都要预期信念下调和上调一样多。

也许会出现这样的情况：反对证据一条接一条地出现，而新的支持证据却迟迟不来。你会发现自己的信念不断下滑，越来越低。直到有一天，你终于意识到证据的风向正对着你。在那一刻，没必要再找借口了。在那一刻，你已经放下了自己珍视的信念。太棒了！该庆祝一下了！开瓶香槟或者叫个披萨吧！毕竟，只有放下原有信念，你才能变得更强。

---

<sup>1</sup>见《地图与领地》中的“期望证据守恒”。

<sup>2</sup>见 “I Defy the Data!” http://lesswrong.com/lw/ig/i_defy_the_data.

---

## Update Yourself Incrementally

Politics is the mind-killer. Debate is war, arguments are soldiers. There is the temptation to search for ways to interpret every possible experimental result to confirm your theory, like securing a citadel against every possible line of attack. This you cannot do. It is mathematically impossible. For every expectation of evidence, there is an equal and opposite expectation of counterevidence.<sup>1</sup>

But it’s okay if your cherished belief isn’t perfectly defended. If the hypothesis is that the coin comes up heads 95% of the time, then one time in twenty you will expect to see what looks like contrary evidence. This is okay. It’s normal. It’s even expected, so long as you’ve got nineteen supporting observations for every contrary one. A probabilistic model can take a hit or two, and still survive, so long as the hits don’t keep on coming in.<sup>2</sup>

Yet it is widely believed, especially in the court of public opinion, that a true theory can have no failures and a false theory no successes.

You find people holding up a single piece of what they conceive to be evidence, and claiming that their theory can “explain” it, as though this were all the support that any theory needed. Apparently a false theory can have no supporting evidence; it is impossible for a false theory to fit even a single event. Thus, a single piece of confirming evidence is all that any theory needs.

It is only slightly less foolish to hold up a single piece of probabilistic counterevidence as disproof, as though it were impossible for a correct theory to have even a slight argument against it. But this is how humans have argued for ages and ages, trying to defeat all enemy arguments, while denying the enemy even a single shred of support. People want their debates to be one-sided; they are accustomed to a world in which their preferred theories have not one iota of antisupport. Thus, allowing a single item of probabilistic counterevidence would be the end of the world.

I just know someone in the audience out there is going to say, “But you can’t concede even a single point if you want to win debates in the real world! If you concede that any counterarguments exist, the Enemy will harp on them over and over—you can’t let the Enemy do that! You’ll lose! What could be more viscerally terrifying than that?”

Whatever. Rationality is not for winning debates, it is for deciding which side to join. If you’ve already decided which side to argue for, the work of rationality is done within you, whether well or poorly. But how can you, yourself, decide which side to argue? If choosing the wrong side is viscerally terrifying, even just a little viscerally terrifying, you’d best integrate all the evidence.

Rationality is not a walk, but a dance. On each step in that dance your foot should come down in exactly the correct spot, neither to the left nor to the right. Shifting belief upward with each iota of confirming evidence. Shifting belief downward with each iota of contrary evidence. Yes, down. Even with a correct model, if it is not an exact model, you will sometimes need to revise your belief down.

If an iota or two of evidence happens to countersupport your belief, that’s okay. It happens, sometimes, with probabilistic evidence for nonexact theories. (If an exact theory fails, you are in trouble!) Just shift your belief downward a little—the probability, the odds ratio, or even a nonverbal weight of credence in your mind. Just shift downward a little, and wait for more evidence. If the theory is true, supporting evidence will come in shortly, and the probability will climb again. If the theory is false, you don’t really want it anyway.

The problem with using black-and-white, binary, qualitative reasoning is that any single observation either destroys the theory or it does not. When not even a single contrary observation is allowed, it creates cognitive dissonance and has to be argued away. And this rules out incremental progress; it rules out correct integration of all the evidence. Reasoning probabilistically, we realize that on average, a correct theory will generate a greater weight of support than countersupport. And so you can, without fear, say to yourself: “This is gently contrary evidence, I will shift my belief downward.” Yes, down. It does not destroy your cherished theory. That is qualitative reasoning; think quantitatively.

pectation of counterevidence. On every occasion, you must, on average, anticipate revising your beliefs downward as much as you anticipate revising them upward. If you think you already know what evidence will come in, then you must already be fairly sure of your theory—probability close to 1—which doesn’t leave much room for the probability to go further upward. And however unlikely it seems that you will encounter disconfirming evidence, the resulting downward shift must be large enough to precisely balance the anticipated gain on the other side. The weighted mean of your expected posterior probability must equal your prior probability.

How silly is it, then, to be terrified of revising your probability downward, if you’re bothering to investigate a matter at all? On average, you must anticipate as much downward shift as upward shift from every individual observation.

It may perhaps happen that an iota of antisupport comes in again, and again and again, while new support is slow to trickle in. You may find your belief drifting downward and further downward. Until, finally, you realize from which quarter the winds of evidence are blowing against you. In that moment of realization, there is no point in constructing excuses. In that moment of realization, you have already relinquished your cherished belief. Yay! Time to celebrate! Pop a champagne bottle or send out for pizza! You can’t become stronger by keeping the beliefs you started with, after all.

---

<sup>1</sup>See “Conservation of Expected Evidence” in Map and Territory.

<sup>2</sup>See “I Defy the Data!” http://lesswrong.com/lw/ig/i_defy_the_data.