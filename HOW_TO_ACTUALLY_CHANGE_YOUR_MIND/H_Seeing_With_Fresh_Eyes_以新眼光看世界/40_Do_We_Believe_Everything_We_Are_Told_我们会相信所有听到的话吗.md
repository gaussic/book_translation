## 我们会相信所有听到的话吗？

关于锚定与调整的一些早期实验，测试了让受试者分心（比如让他们在一串数字中留意“5”出现等任务，使其认知上“忙碌”）是否会减少调整，从而加剧锚定效应。大多数实验结果都支持这个观点：认知负荷越大，锚定效应和更广泛的污染效应就越强。

随着越来越多关于污染效应、认知负荷加剧污染的实验结果积累，Daniel Gilbert 发现了一个极其疯狂的模式：我们会相信所有听到的话吗？

人们可能会自然地认为，当我们听到一个命题时，首先会理解它的含义，然后加以思考，最后才决定接受还是拒绝。这种看似显而易见的认知流程模型可以追溯到笛卡尔。但笛卡尔的对手斯宾诺莎却不同意；斯宾诺莎认为，在理解命题的过程中，我们首先会被动地接受它，只有在进一步思考后，才会主动拒绝那些被否定的命题。

过去几百年里，哲学家们大多支持笛卡尔的观点，因为他的看法似乎更“合乎逻辑”也更直观。<sup>1</sup> 但 Gilbert 想到了一个实验方法，可以检验笛卡尔和斯宾诺莎的假说。

如果笛卡尔是对的，那么让受试者分心，应该会同时影响他们接受真实陈述和拒绝虚假陈述的能力。如果斯宾诺莎是对的，那么让受试者分心，会导致他们把虚假陈述记成真实，但不会让他们把真实陈述记成虚假。

Gilbert、Krull 和 Malone 的实验结果支持了后者：受试者被呈现标记为“真”或“假”的新陈述时，分心对识别真实命题没有影响（未分心时正确率55%，分心时58%）；但对识别虚假命题有影响（未分心时正确率55%，分心时只有35%）。<sup>2</sup>

Gilbert、Tafarodi 和 Malone 后续实验给出了更戏剧性的例证。<sup>3</sup> 受试者大声朗读屏幕上滚动的犯罪报告，报告中文字颜色标明该陈述是真还是假。有些报告包含夸大罪行严重性的虚假陈述，有些则包含为罪行开脱的虚假陈述。部分受试者还要在阅读报告时留意数字串中的“5”——这就是让他们认知分心的任务。最后，受试者要为每个罪犯建议刑期，范围是0到20年。

在认知负荷组中，面对“夸大”型虚假陈述的罪犯，受试者建议的平均刑期为11.15年；面对“开脱”型虚假陈述的罪犯，建议的平均刑期为5.83年。这几乎相差一倍，且统计学上显著。

未分心组的受试者读到的报告、标签和数字串完全一样，只是不用找“5”，因此能更专注于“否定”那些被标为假的陈述。这组受试者对“夸大”型和“开脱”型虚假陈述罪犯的建议刑期分别为7.03年和6.03年。

Gilbert、Tafarodi 和 Malone 的论文标题是《你无法不相信你读到的一切》。

这至少说明，我们在接触不可靠信息时，尤其是当我们还在做别的事情时，应该更加小心。比如在超市随手翻报纸时要格外警惕。

附言：根据我刚刚编造的一个未经证实的谣言，人们会因为这篇文章字体变化太多而变得不那么怀疑它。

---

<sup>1</sup>见 Hanson, “Policy Tug-O-War,” 2007, http://www.overcomingbias.com/2007/05/policy_tugowar.html。

<sup>2</sup>Gilbert, Krull, and Malone, “Unbelieving the Unbelievable,” 1990.

<sup>3</sup>Gilbert, Tafarodi, and Malone, “You Can’t Not Believe Everything You Read,” 1993.

---

## Do We Believe Everything We’re Told?

Some early experiments on anchoring and adjustment tested whether distracting the subjects—rendering subjects cognitively “busy” by asking them to keep a lookout for “5” in strings of numbers, or some such—would decrease adjustment, and hence increase the influence of anchors. Most of the experiments seemed to bear out the idea that being cognitive busy increased anchoring, and more generally contamination.

Looking over the accumulating experimental results—more and more findings of contamination, exacerbated by cognitive busyness—Daniel Gilbert saw a truly crazy pattern emerging: Do we believe everything we’re told?

One might naturally think that on being told a proposition, we would first comprehend what the proposition meant, then consider the proposition, and finally accept or reject it. This obvious-seeming model of cognitive process flow dates back to Descartes. But Descartes’s rival, Spinoza, disagreed; Spinoza suggested that we first passively accept a proposition in the course of comprehending it, and only afterward actively disbelieve propositions which are rejected by consideration.

Over the last few centuries, philosophers pretty much went along with Descartes, since his view seemed more, y’know, logical and intuitive.<sup>1</sup> But Gilbert saw a way of testing Descartes’s and Spinoza’s hypotheses experimentally.

If Descartes is right, then distracting subjects should interfere with both accepting true statements and rejecting false statements. If Spinoza is right, then distracting subjects should cause them to remember false statements as being true, but should not cause them to remember true statements as being false.

Gilbert, Krull, and Malone bear out this result, showing that, among subjects presented with novel statements labeled TRUE or FALSE, distraction had no effect on identifying true propositions (55% success for uninterrupted presentations, vs. 58% when interrupted); but did affect identifying false propositions (55% success when uninterrupted, vs. 35% when interrupted).<sup>2</sup>

A much more dramatic illustration was produced in followup experiments by Gilbert, Tafarodi, and Malone.<sup>3</sup> Subjects read aloud crime reports crawling across a video monitor, in which the color of the text indicated whether a particular statement was true or false. Some reports contained false statements that exacerbated the severity of the crime; other reports contained false statements that extenuated (excused) the crime. Some subjects also had to pay attention to strings of digits, looking for a “5,” while reading the crime reports—this being the distraction task to create cognitive busyness. Finally, subjects had to recommend the length of prison terms for each criminal, from 0 to 20 years.

Subjects in the cognitively busy condition recommended an average of 11.15 years in prison for criminals in the “exacerbating” condition, that is, criminals whose reports contained labeled false statements exacerbating the severity of the crime. Busy subjects recommended an average of 5.83 years in prison for criminals whose reports contained labeled false statements excusing the crime. This nearly twofold difference was, as you might suspect, statistically significant.

Non-busy participants read exactly the same reports, with the same labels, and the same strings of numbers occasionally crawling past, except that they did not have to search for the number “5.” Thus, they could devote more attention to “unbelieving” statements labeled false. These non-busy participants recommended 7.03 years versus 6.03 years for criminals whose reports falsely exacerbated or falsely excused.

Gilbert, Tafarodi, and Malone’s paper was entitled “You Can’t Not Believe Everything You Read.”

This suggests—to say the very least—that we should be more careful when we expose ourselves to unreliable information, especially if we’re doing something else at the time. Be careful when you glance at that newspaper in the supermarket.

PS: According to an unverified RUMOR I just made up, people will be less skeptical of this essay BECAUSE OF THE DISTRACTING FONT CHANGES.

---

<sup>1</sup>See Hanson, “Policy Tug-O-War,” 2007, http://www.overcomingbias.com/2007/05/policy_tugowar.html.

<sup>2</sup>Gilbert, Krull, and Malone, “Unbelieving the Unbelievable,” 1990.

<sup>3</sup>Gilbert, Tafarodi, and Malone, “You Can’t Not Believe Everything You Read,” 1993.