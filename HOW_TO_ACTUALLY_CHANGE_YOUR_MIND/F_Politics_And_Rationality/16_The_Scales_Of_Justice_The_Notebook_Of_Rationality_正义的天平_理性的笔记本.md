## 正义的天平，理性的笔记本

正义女神常被描绘为手持天平。天平的特点是：无论哪一边被拉低，另一边就会上升。这让事情变得非常方便，也容易追踪。但这通常是对现实的严重扭曲。

在人类的讨论中，有一种天然的倾向，把讨论当作一种战斗、战争的延伸，或者一种竞技运动；而在运动中，你只需要记录每支队伍得了多少分。只有两方，每得一分就是对方失一分。观众们会在脑海中不断统计每位发言者对对方“得分”多少。辩论结束时，得分多的那位显然就是赢家；所以他说的每句话都一定是对的，输家说的每句话都一定是错的。

《风险与收益判断中的情感启发式》研究了受试者是否会把对某项技术（如核能）的潜在好处和潜在风险混为一种整体的好坏感受。<sup>1</sup> 假设我先告诉你，某种核反应堆比其他设计产生的核废料更少。但接着我又告诉你，这种反应堆比其他设计更不稳定，如果有足够多的问题同时发生，熔毁的风险更大。

如果反应堆更容易熔毁，这似乎是“反对”反应堆的一个“扣分项”，或者说是反对建造该反应堆的人的一个“扣分项”。而如果反应堆产生的废料更少，这就是“支持”反应堆的一个“加分项”，或者说是支持建造它的人的一个“加分项”。那么，这两个事实是彼此对立的吗？不是。在现实世界中，完全不是。这两个事实可能会被辩论双方分别引用，但它们在逻辑上是独立的；事实本身并不知道自己“站在哪一边”。

如果某种反应堆设计在物理上是被动安全的（即使冷却系统等都失效也不会超临界），这并不意味着它一定会产生更少的废料，或者发电成本更低。这些都是好事，但它们不是同一件好事。反应堆产生的废料量取决于它的某些物理属性，而其他物理属性则决定了核反应是否更不稳定。即使有些设计属性是重叠的，你也必须分别考虑熔毁概率和每年预期废料量。这是两个不同的物理问题，有两个不同的事实答案。

但如上所述的研究表明，人们倾向于用整体的好坏感受来判断技术——以及许多其他问题。如果你告诉人们某种反应堆设计产生的废料更少，他们就会认为它的熔毁概率也更低。这意味着他们在面对有明确事实答案的物理问题时，会得出错误答案，因为他们把逻辑上独立的问题混为一谈——把事实当作战争中不同阵营的士兵，认为一方的士兵可以用来对抗另一方的士兵。

如果正义女神调查的是关于有罪或无罪的纯粹事实问题，天平并非完全不合适。要么约翰·史密斯杀了约翰·多伊，要么没有。我们从 E. T. Jaynes 那里学到，所有贝叶斯证据都表现为假设之间的概率流动；不存在只“支持”或“反驳”单一假设的证据，除非是相对于其他假设表现更好或更差。所以，只要正义女神调查的是一个有二元答案空间的单一事实问题，天平就是合适的工具。如果正义女神必须考虑更复杂的问题，她就应该放下天平，或者放下手中的剑。

并非所有论证都能简化为“加分”或“减分”。理性女神手持笔记本，把所有不属于任何一方的事实都记下来。

---

<sup>1</sup>Finucane 等, “The Affect Heuristic in Judgments of Risks and Benefits,”

---

## The Scales of Justice, the Notebook of Rationality

Lady Justice is widely depicted as carrying scales. A set of scales has the property that whatever pulls one side down pushes the other side up. This makes things very convenient and easy to track. It’s also usually a gross distortion.

In human discourse there is a natural tendency to treat discussion as a form of combat, an extension of war, a sport; and in sports you only need to keep track of how many points have been scored by each team. There are only two sides, and every point scored against one side is a point in favor of the other. Everyone in the audience keeps a mental running count of how many points each speaker scores against the other. At the end of the debate, the speaker who has scored more points is, obviously, the winner; so everything that speaker says must be true, and everything the loser says must be wrong.

“The Affect Heuristic in Judgments of Risks and Benefits” studied whether subjects mixed up their judgments of the possible benefits of a technology (e.g., nuclear power), and the possible risks of that technology, into a single overall good or bad feeling about the technology.1 Suppose that I first tell you that a particular kind of nuclear reactor generates less nuclear waste than competing reactor designs. But then I tell you that the reactor is more unstable than competing designs, with a greater danger of melting down if a sufficient number of things go wrong simultaneously.

If the reactor is more likely to melt down, this seems like a “point against” the reactor, or a “point against” someone who argues for building the reactor. And if the reactor produces less waste, this is a “point for” the reactor, or a “point for” building it. So are these two facts opposed to each other? No. In the real world, no. These two facts may be cited by different sides of the same debate, but they are logically distinct; the facts don’t know whose side they’re on.

If it’s a physical fact about a reactor design that it’s passively safe (won’t go supercritical even if the surrounding coolant systems and so on break down), this doesn’t imply that the reactor will necessarily generate less waste, or produce electricity at a lower cost. All these things would be good, but they are not the same good thing. The amount of waste produced by the reactor arises from the properties of that reactor. Other physical properties of the reactor make the nuclear reaction more unstable. Even if some of the same design properties are involved, you have to separately consider the probability of meltdown, and the expected annual waste generated. These are two different physical questions with two different factual answers.

But studies such as the above show that people tend to judge technologies—and many other problems—by an overall good or bad feeling. If you tell people a reactor design produces less waste, they rate its probability of meltdown as lower. This means getting the wrong answer to physical questions with definite factual answers, because you have mixed up logically distinct questions—treated facts like human soldiers on different sides of a war, thinking that any soldier on one side can be used to fight any soldier on the other side.

A set of scales is not wholly inappropriate for Lady Justice if she is investigating a strictly factual question of guilt or innocence. Either John Smith killed John Doe, or not. We are taught (by E. T. Jaynes) that all Bayesian evidence consists of probability flows between hypotheses; there is no such thing as evidence that “supports” or “contradicts” a single hypothesis, except insofar as other hypotheses do worse or better. So long as Lady Justice is investigating a single, strictly factual question with a binary answer space, a set of scales would be an appropriate tool. If Justitia must consider any more complex issue, she should relinquish her scales or relinquish her sword.

Not all arguments reduce to mere up or down. Lady Rationality carries a notebook, wherein she writes down all the facts that aren’t on anyone’s side.

---

<sup>1</sup>Finucane et al., “The Affect Heuristic in Judgments of Risks and Benefits,” 2000.