## 遗传谬误

作者：Eliezer Yudkowsky

在逻辑谬误的列表中，你会看到包括“遗传谬误”——即基于某人相信某个观点的原因来攻击该观点的谬误。

乍一看，这个想法似乎很奇怪——如果信念的起因并不决定其系统可靠性，那到底是什么决定的呢？如果深蓝（Deep Blue）建议我们下一步该怎么走，我们会基于对其代码的理解来信任它，尽管我们自己无法评估实际的棋局。除了通过某种系统可靠的过程得出的概率赋值之外，还有什么能够被认为是“理性的”呢？

关于遗传谬误的文章会告诉你，遗传推理并不总是谬误——证据的来源在评估中有时是相关的，比如在信任的专家的情况下。但是有时候，这种推理就是谬误；比如化学家凯库勒（Kekulé）首次在梦中看到了苯的环状结构，但这并不意味着我们不能信任这一信念。

所以，遗传谬误有时候是谬误，有时候又不是？

遗传谬误从形式上来说是谬误，因为一个信念的原始原因并不等于它当前的辩护状态，即目前已知的所有支持和反对的证据之和。

然而，我们改变想法的频率比我们认为的要低。当面对新的怀疑，认为自己的一些观点可能来自于有缺陷的来源时，遗传指控在人类之间的影响力是理想的贝叶斯人（Bayesians）所无法比拟的。

清除心中的偏见是一种强大的启发式方法，当你面对新怀疑时，你可能会发现许多观点可能来自于有缺陷的来源。

一旦某个观点进入了我们的脑海，证据并不总是容易将其根除。考虑一下那些从小就相信《圣经》的人；后来，他们（有意识地）拒绝了《圣经》是由上帝亲自书写的观念；但他们仍然认为《圣经》充满了不可或缺的道德智慧。你看，他们没有清理自己的思维；如果他们开始怀疑《圣经》所说的任何内容，仅仅因为它是《圣经》说的，他们就能做得更好。

与此同时，他们必须坚守一个原则：逆向愚蠢并不是智慧；目标是让思维真正松动，进行独立思考，而不是否定《圣经》，并将其作为算法。

一旦某个观点进入了你的头脑，你会倾向于在任何地方都为它寻找支持——因此，当原始来源突然被怀疑时，确实非常明智地去怀疑所有最初从那个枝条上生长出来的叶子……

如果你能做到！清除心中的偏见并不容易。要真正重新考虑，而不是让自己的思维陷入复述已知论点的模式，需要付出剧烈的努力。“除非事情可能向任意一方倾斜，否则就不是信仰的真正危机。”[Thor Shenkel说过](http://forums.keenspot.com/viewtopic.php?p=1099965#p1099965)。

如果你有许多观点是来自你现在知道不可信的来源，但这些观点看起来最终都正确——比如《圣经》这样的经典例子——你应该极为怀疑。

另一方面……也有一种情况，就是证据足够明确，以至于源头变得不再重要。积累这种明确的证据就是科学的全部内容。凯库勒最早在梦中看到了苯的环状结构，这已经不重要了——即使我们是通过生成随机的计算机图像、从一个被揭穿为骗子的灵媒处得到这个假设，甚至从《圣经》得到这个假设，这也不重要。苯的环状结构已经得到了足够的实验性证据，足以让该建议的来源变得不相关。

如果没有这样的明确证据，那么你确实需要关注观点的原始来源——给专家更多的信任，尤其是当他们的领域赢得了尊重；怀疑那些你最初从可疑来源得到的观点；不信任那些动机不可信的人，如果他们不能提供独立于其权威的论据。

当一个观点的原始来源的合理性已被充分辩护时，遗传谬误便成为谬误。Hal Finney建议我们将正确地提到一个观点来源的做法称为“遗传启发式”。<sup>1</sup>

一些有用的经验法则（适用于人类）：

* 对那些你不喜欢的信念，尤其是当支持者声称超越简单权威的辩护时，要保持怀疑态度。“飞行是宗教思想，因此莱特兄弟必须是骗子”是经典的例子之一。
* 同理，不要认为你可以仅仅通过深刻的心理分析相关人物及其缺陷动机来获取关于技术问题的有价值信息。如果存在技术性论证，它们应当优先考虑。
* 当你的一项基本来源受到新的怀疑时，你真的应该怀疑所有从这个根源上生长出的枝条和叶子。你并不被授权直接否定它们作为结论，因为逆向愚蠢并不是智慧，但……
* 如果你发现自己仍然相信一个你后来拒绝的来源的早期观点，那就要极为怀疑。

---

<sup>1</sup>来源：[http://lesswrong.com/lw/s3/the\_genetic\_fallacy/lls](http://lesswrong.com/lw/s3/the_genetic_fallacy/lls)

---

## The Genetic Fallacy

by Eliezer Yudkowsky

In lists of logical fallacies, you will find included “the genetic fallacy”—the fallacy of attacking a belief based on someone’s causes for believing it.

This is, at first sight, a very strange idea—if the causes of a belief do not determine its systematic reliability, what does? If Deep Blue advises us of a chess move, we trust it based on our understanding of the code that searches the game tree, being unable to evaluate the actual game tree ourselves. What could license any probability assignment as “rational,” except that it was produced by some systematically reliable process?

Articles on the genetic fallacy will tell you that genetic reasoning is not always a fallacy—that the origin of evidence can be relevant to its evaluation, as in the case of a trusted expert. But other times, say the articles, it is a fallacy; the chemist Kekulé first saw the ring structure of benzene in a dream, but this doesn’t mean we can never trust this belief.

So sometimes the genetic fallacy is a fallacy, and sometimes it’s not?

The genetic fallacy is formally a fallacy, because the original cause of a belief is not the same as its current justificational status, the sum of all the support and antisupport currently known.

Yet we change our minds less often than we think. Genetic accusations have a force among humans that they would not have among ideal Bayesians.

Clearing your mind is a powerful heuristic when you’re faced with new suspicion that many of your ideas may have come from a flawed source.

Once an idea gets into our heads, it’s not always easy for evidence to root it out. Consider all the people out there who grew up believing in the Bible; later came to reject (on a deliberate level) the idea that the Bible was written by the hand of God; and who nonetheless think that the Bible is full of indispensable ethical wisdom. They have failed to clear their minds; they could do significantly better by doubting anything the Bible said because the Bible said it.

At the same time, they would have to bear firmly in mind the principle that reversed stupidity is not intelligence; the goal is to genuinely shake your mind loose and do independent thinking, not to negate the Bible and let that be your algorithm.

Once an idea gets into your head, you tend to find support for it everywhere you look—and so when the original source is suddenly cast into suspicion, you would be very wise indeed to suspect all the leaves that originally grew on that branch . . .

If you can! It’s not easy to clear your mind. It takes a convulsive effort to actually reconsider, instead of letting your mind fall into the pattern of rehearsing cached arguments. “It ain’t a true crisis of faith unless things could just as easily go either way,” [said](http://forums.keenspot.com/viewtopic.php?p=1099965#p1099965) Thor Shenkel.

You should be extremely suspicious if you have many ideas suggested by a source that you now know to be untrustworthy, but by golly, it seems that all the ideas still ended up being right—the Bible being the obvious archetypal example.

On the other hand . . . there’s such a thing as sufficiently clear-cut evidence, that it no longer significantly matters where the idea originally came from. Accumulating that kind of clear-cut evidence is what Science is all about. It doesn’t matter any more that Kekulé first saw the ring structure of benzene in a dream—it wouldn’t matter if we’d found the hypothesis to test by generating random computer images, or from a spiritualist revealed as a fraud, or even from the Bible. The ring structure of benzene is pinned down by enough experimental evidence to make the source of the suggestion irrelevant.

In the absence of such clear-cut evidence, then you do need to pay attention to the original sources of ideas—to give experts more credence than layfolk, if their field has earned respect—to suspect ideas you originally got from suspicious sources—to distrust those whose motives are untrustworthy, if they cannot present arguments independent of their own authority.

The genetic fallacy is a fallacy when there exist justifications beyond the genetic fact asserted, but the genetic accusation is presented as if it settled the issue. Hal Finney suggests that we call correctly appealing to a claim’s origins “the genetic heuristic.”<sup>1</sup>

Some good rules of thumb (for humans):

- Be suspicious of genetic accusations against beliefs that you dislike, especially if the proponent claims justifications beyond the simple authority of a speaker. “Flight is a religious idea, so the Wright Brothers must be liars” is one of the classically given examples.
- By the same token, don’t think you can get good information about a technical issue just by sagely psychoanalyzing the personalities involved and their flawed motives. If technical arguments exist, they get priority.
- When new suspicion is cast on one of your fundamental sources, you really should doubt all the branches and leaves that grew from that root. You are not licensed to reject them outright as conclusions, because reversed stupidity is not intelligence, but . . .
- Be extremely suspicious if you find that you still believe the early suggestions of a source you later rejected.

---

<sup>1</sup>Source: http://lesswrong.com/lw/s3/the_genetic_fallacy/lls.