## 正义的天平，理性的笔记本

作者：Eliezer Yudkowsky

正义女神通常被描绘为手持天平。天平有一个特性：一边被拉下，另一边就会上升。这让事情看起来很方便，也容易衡量。但这种比喻往往是对现实的严重扭曲。

在人类的讨论中，存在一种自然倾向：把对话当作一种战斗、一种战争的延伸、一种竞技比赛；而在比赛中，我们只需要记录每个队得了多少分。只有两个阵营，每得一分就意味着对方少得一分。观众们在脑中会默默统计每位辩手打击对方多少次。等到辩论结束，得分较高的自然被认为是“赢家”；于是，赢家说的每一句话就都被当成是真的，而输家说的每一句话就是错的。

一项名为《影响启发式在人们对风险与收益的判断中的作用》的研究，考察了人们是否会将对某项技术（比如核能）的潜在益处与潜在风险混为一谈，从而形成一个笼统的“好”或“坏”的印象。<sup>1</sup>
设想我先告诉你，有一种特定型号的核反应堆比其他型号产生的核废料更少。但接着我又告诉你，这种反应堆比其他型号更不稳定——如果有足够多的系统同时出问题，它发生熔毁的风险更大。

如果某个反应堆更容易熔毁，这听起来像是反对它的“一个扣分项”，或是反对建造它的一种理由。而如果它产生更少的废料，这又似乎是“一个加分项”，或是支持建造它的一种理由。那么，这两个事实是否彼此对立呢？现实中，其实并非如此。它们或许会被辩论双方各自引用，但在逻辑上它们彼此独立；事实本身并不站队。

如果某种反应堆在物理设计上具有被动安全性（即使冷却系统等失效也不会发生超临界事故），这并不意味着它必然会产生更少的废料，或更低的发电成本。所有这些都是好的特性，但它们不是一个东西。反应堆产生的废料量源自它的某些物理属性，而导致反应堆更不稳定的又是另一些属性。即使部分设计因素有所重叠，我们仍必须分别考虑其熔毁概率和年废料产出。这是两个不同的物理问题，拥有两个独立的事实性答案。

然而，像前述研究显示，人们倾向于用一种“总体好坏感”来判断技术及其他许多问题。如果你告诉他们某种反应堆废料更少，他们就会认为它的熔毁风险也更低。这种心理倾向导致人们在面对原本有明确事实答案的物理问题时给出错误答案——因为他们混淆了逻辑上独立的问题，把事实当成了战争中站在不同阵营的士兵，误以为某个阵营的士兵都可以用来打击对方的任何一个士兵。

如果正义女神在判断的是一个纯粹事实性的问题，比如“约翰·史密斯是否杀害了约翰·多伊”，那么一副天平也许并非完全不合适。我们从 E.T. Jaynes 那里学到：所有的贝叶斯证据都表现为不同假设之间的概率流动；并不存在“单独支持”或“单独反驳”某一假设的证据，除非是在比较其他假设表现的基础上。因此，只要正义女神面对的是一个单一、二元结果的问题，一副天平就是一个恰当的工具。但如果她必须面对更复杂的问题，她就应该放下天平，或者放下她的剑。

并非所有争论都可以归结为简单的“支持”或“反对”。理性女神带着一本笔记本，在其中记录下那些**不属于任何一方**的事实。

---

<sup>1</sup>Melissa L. Finucane 等人，《影响启发式在人们对风险与收益的判断中的作用》，《行为决策杂志》13卷，第1期（2000年）：第1–17页。

---

## The Scales of Justice, the Notebook of Rationality

by Eliezer Yudkowsky

Lady Justice is widely depicted as carrying scales. A set of scales has the property that whatever pulls one side down pushes the other side up. This makes things very convenient and easy to track. It’s also usually a gross distortion.

In human discourse there is a natural tendency to treat discussion as a form of combat, an extension of war, a sport; and in sports you only need to keep track of how many points have been scored by each team. There are only two sides, and every point scored against one side is a point in favor of the other. Everyone in the audience keeps a mental running count of how many points each speaker scores against the other. At the end of the debate, the speaker who has scored more points is, obviously, the winner; so everything that speaker says must be true, and everything the loser says must be wrong.

“The Affect Heuristic in Judgments of Risks and Benefits” studied whether subjects mixed up their judgments of the possible benefits of a technology (e.g., nuclear power), and the possible risks of that technology, into a single overall good or bad feeling about the technology.<sup>1</sup> Suppose that I first tell you that a particular kind of nuclear reactor generates less nuclear waste than competing reactor designs. But then I tell you that the reactor is more unstable than competing designs, with a greater danger of melting down if a sufficient number of things go wrong simultaneously.

If the reactor is more likely to melt down, this seems like a “point against” the reactor, or a “point against” someone who argues for building the reactor. And if the reactor produces less waste, this is a “point for” the reactor, or a “point for” building it. So are these two facts opposed to each other? No. In the real world, no. These two facts may be cited by different sides of the same debate, but they are logically distinct; the facts don’t know whose side they’re on.

If it’s a physical fact about a reactor design that it’s passively safe (won’t go supercritical even if the surrounding coolant systems and so on break down), this doesn’t imply that the reactor will necessarily generate less waste, or produce electricity at a lower cost. All these things would be good, but they are not the same good thing. The amount of waste produced by the reactor arises from the properties of that reactor. Other physical properties of the reactor make the nuclear reaction more unstable. Even if some of the same design properties are involved, you have to separately consider the probability of meltdown, and the expected annual waste generated. These are two different physical questions with two different factual answers.

But studies such as the above show that people tend to judge technologies—and many other problems—by an overall good or bad feeling. If you tell people a reactor design produces less waste, they rate its probability of meltdown as lower. This means getting the wrong answer to physical questions with definite factual answers, because you have mixed up logically distinct questions—treated facts like human soldiers on different sides of a war, thinking that any soldier on one side can be used to fight any soldier on the other side.

A set of scales is not wholly inappropriate for Lady Justice if she is investigating a strictly factual question of guilt or innocence. Either John Smith killed John Doe, or not. We are taught (by E. T. Jaynes) that all Bayesian evidence consists of probability flows between hypotheses; there is no such thing as evidence that “supports” or “contradicts” a single hypothesis, except insofar as other hypotheses do worse or better. So long as Lady Justice is investigating a single, strictly factual question with a binary answer space, a set of scales would be an appropriate tool. If Justitia must consider any more complex issue, she should relinquish her scales or relinquish her sword.

Not all arguments reduce to mere up or down. Lady Rationality carries a notebook, wherein she writes down all the facts that aren’t on anyone’s side.

---

<sup>1</sup>Melissa L. Finucane et al., “The Affect Heuristic in Judgments of Risks and Benefits,” Journal of Behavioral Decision Making 13, no. 1 (2000): 1–17.