## 每一个事业都想变成邪教

Cade Metz 在 The Register 上最近声称，维基百科顶级管理员的一个秘密邮件列表已经变得痴迷于封禁所有批评者和潜在批评者。<sup>1</sup> 甚至有管理员仅仅因为某个用户太高产，就怀疑他是 Wikipedia Review 派来的间谍，将其封禁。而维基百科高层则团结一致保护自己人。

追求系统化世界知识的事业，是否有某种深层的道德缺陷，会让追随者走向疯狂？也许只有天生有极权倾向的人才会试图成为世界万事万物的权威——

注意对应偏差！如果关于维基百科的指控属实，那完全可以用普通的人性来解释，而不是非凡的人性。

群体与外群体的二元对立，是人类天性的一部分。幸福死亡螺旋和仇恨螺旋也是如此。一个崇高的事业并不需要什么深层缺陷，追随者就会形成类似邪教的小团体。只要追随者是人类，其他一切都会自然而然地发生，像停电后冰箱里的食物腐坏一样，腐化是默认状态。

就像每一个温差都想被抹平，每一个计算机程序都想变成一堆临时补丁，每一个事业都想变成邪教。这是系统自然趋向的高熵状态，是人类心理中的一个吸引子。这和事业是否真正崇高可能毫无关系。你也许会以为，一个好事业会把它的善良传递给所有相关的人——让追随者更不容易陷入地位游戏、内外群体偏见、情感螺旋、领袖崇拜。但相信一个真理并不会关闭光环效应。崇高的事业不会让追随者变得超越人类。有很多糟糕的想法能造成很多伤害——但这未必就是问题的根源。

任何有特殊目标的人群——无论目标好坏还是荒唐——如果不持续努力抵抗，都会滑向邪教吸引子。你可以让房子比室外凉快，但必须一直开空调，一旦断电——也就是放弃与熵作斗争——一切都会回归“常态”。

有一次，一个团体变得半邪教化，他们的口号是“理性！理智！客观现实！”<sup>2</sup> 把伟大理念贴上“理性”的标签，并不会比在你家门口挂个“冷！”的牌子更能保护你。你还是得开空调——持续消耗能量，才能逆转自然滑向邪教化的趋势。崇拜理性不会让你变得理智，就像崇拜重力不会让你飞起来一样。你不能和热力学对话，也不能向概率论祈祷。你可以用它，但不能把它当作小团体来加入。

邪教化是量变，不是质变。问题不是“是不是邪教”，而是“有多少邪教化，在哪些地方”。即使在科学这个典型的真正崇高事业中，我们也能清楚地看到与邪教熵作战的前线，战线时进时退。比如，期刊是否更容易接受知名作者或知名机构的文章，而不是无名作者的？有多少信念来自权威，有多少来自实验？哪些期刊采用了盲审，盲审效果如何？

我举这个例子，而不是那种“科学家不接受新观点”的老套指责，是因为它展示了一条战线——一个人类心理被主动压制、邪教熵被抽走的地方。（当然，这也需要排放一些废热。）

这篇文章不是一份抵抗邪教化的技术清单。我以前介绍过一些方法，之后还会讲更多。这里只想指出，事业的崇高并不意味着你可以少花力气去抵抗邪教吸引子。如果你能指出当前的战线，这并不意味着你承认自己的崇高事业不够好。你也许会以为，如果问题是“是不是邪教”，你就必须回答“不是”，否则就是背叛了心爱的事业。但这就像认为发动机只能分为“完全高效”和“低效”，而不是去衡量损耗。

反过来说，如果你认为那些愚蠢的其他事业是因为本质不纯才走向邪教，如果你嘲笑“邪教受害者”的愚蠢，如果你觉得邪教都是怪胎领导和怪胎成员，那你就不会花必要的力气去抵抗熵——去抵抗人性。

---

<sup>1</sup>参见“Secret Mailing List Rocks Wikipedia”（http://www.theregister.co.uk/2007/12/04/wikipedia_secret_mailing）和“Wikipedia Black Helicopters Circle Utah’s Traverse Mountain”（http://www.theregister.co.uk/2007/12/06/wikipedia_and_overstock）。

<sup>2</sup>参见“Guardians of the Truth”（http://lesswrong.com/lw/lz/guardians_of_the_truth）和“Guardians of Ayn Rand”（http://lesswrong.com/lw/m1/guardians_of_ayn_rand）。

---

## Every Cause Wants to Be a Cult

Cade Metz at The Register recently alleged that a secret mailing list of Wikipedia’s top administrators has become obsessed with banning all critics and possible critics of Wikipedia.<sup>1</sup> Including banning a productive user when one administrator—solely because of the productivity—became convinced that the user was a spy sent by Wikipedia Review. And that the top people at Wikipedia closed ranks to defend their own.

Is there some deep moral flaw in seeking to systematize the world’s knowledge, of the sort that would lead pursuers of that Cause into madness? Perhaps only people with innately totalitarian tendencies would try to become the world’s authority on everything—

Correspondence bias alert! If the allegations about Wikipedia are true, they’re explained by ordinary human nature, not by extraordinary human nature.

The ingroup-outgroup dichotomy is part of ordinary human nature. So are happy death spirals and spirals of hate. A Noble Cause doesn’t need a deep hidden flaw for its adherents to form a cultish in-group. It is sufficient that the adherents be human. Everything else follows naturally, decay by default, like food spoiling in a refrigerator after the electricity goes off.

In the same sense that every thermal differential wants to equalize itself, and every computer program wants to become a collection of ad-hoc patches, every Cause wants to be a cult. It’s a high-entropy state into which the system trends, an attractor in human psychology. It may have nothing to do with whether the Cause is truly Noble. You might think that a Good Cause would rub off its goodness on every aspect of the people associated with it—that the Cause’s followers would also be less susceptible to status games, ingroup-outgroup bias, affective spirals, leader-gods. But believing one true idea won’t switch off the halo effect. A noble cause won’t make its adherents something other than human. There are plenty of bad ideas that can do plenty of damage—but that’s not necessarily what’s going on.

Every group of people with an unusual goal—good, bad, or silly—will trend toward the cult attractor unless they make a constant effort to resist it. You can keep your house cooler than the outdoors, but you have to run the air conditioner constantly, and as soon as you turn off the electricity—give up the fight against entropy—things will go back to “normal.”

On one notable occasion there was a group that went semicultish whose rallying cry was “Rationality! Reason! Objective reality!”<sup>2</sup> Labeling the Great Idea “rationality” won’t protect you any more than putting up a sign over your house that says “Cold!” You still have to run the air conditioner— expend the required energy per unit time to reverse the natural slide into cultishness. Worshipping rationality won’t make you sane any more than worshipping gravity enables you to fly. You can’t talk to thermodynamics and you can’t pray to probability theory. You can use it, but not join it as an in-group.

Cultishness is quantitative, not qualitative. The question is not, “Cultish, yes or no?” but, “How much cultishness and where?” Even in Science, which is the archetypal Genuinely Truly Noble Cause, we can readily point to the current frontiers of the war against cult-entropy, where the current battle line creeps forward and back. Are journals more likely to accept articles with a well-known authorial byline, or from an unknown author from a well-known institution, compared to an unknown author from an unknown institution? How much belief is due to authority and how much is from the experiment? Which journals are using blinded reviewers, and how effective is blinded reviewing?

I cite this example, rather than the standard vague accusations of “scientists aren’t open to new ideas,” because it shows a battle line—a place where human psychology is being actively driven back, where accumulated cult-entropy is being pumped out. (Of course, this requires emitting some waste heat.)

This essay is not a catalog of techniques for actively pumping against cultishness. I’ve described some such techniques before, and I’ll discuss more later. Here I just want to point out that the worthiness of the Cause does not mean you can spend any less effort in resisting the cult attractor. And that if you can point to current battle lines, it does not mean you confess your Noble Cause unworthy. You might think that if the question were, “Cultish, yes or no?” that you were obliged to answer, “No,” or else betray your beloved Cause. But that is like thinking that you should divide engines into “perfectly efficient” and “inefficient,” instead of measuring waste.

Contrariwise, if you believe that it was the Inherent Impurity of those Foolish Other Causes that made them go wrong, if you laugh at the folly of “cult victims,” if you think that cults are led and populated by mutants, then you will not expend the necessary effort to pump against entropy—to resist being human.

---

<sup>1</sup>See “Secret Mailing List Rocks Wikipedia” (http://www.theregister.co.uk/2007/12/04/wikipedia_secret_mailing) and “Wikipedia Black Helicopters Circle Utah’s Traverse Mountain” (http://www.theregister.co.uk/2007/12/06/wikipedia_and_overstock).

<sup>2</sup>See “Guardians of the Truth” (http://lesswrong.com/lw/lz/guardians_of_the_truth) and “Guardians of Ayn Rand” (http://lesswrong.com/lw/m1/guardians_of_ayn_rand).