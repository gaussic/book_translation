## 黑暗面的认识论

如果你曾经说过一次谎，从此以后真理就是你的敌人。

我曾讨论过谎言具有传染性的观点。如果你从自家车道上捡起一块鹅卵石，然后告诉地质学家你是在海滩上捡到的——你知道地质学家对岩石了解多少吗？我不知道。但我可以猜到，一块被水冲刷过的鹅卵石，和一滴火山喷发后凝固的熔岩石头，外观肯定不同。你知道你车道上的鹅卵石真正来自哪里吗？在这个有规律的宇宙中，万物都带着它们所处位置的印记；在这张大网中，谎言总是格格不入。<sup>1</sup>

对某些人来说，看似随意的事实——似乎可以轻易用一个貌似合理的谎言替换——在更有知识的人眼中却可能被十几条线索牢牢钉死。对一个创世论者来说，“生命是由‘智能设计’而非‘自然选择’塑造的”听起来就像是支持某支球队。但对生物学家来说，要让一个生物看起来像是被智能设计的，你几乎得对这个生物的每一个方面都撒谎。要让“人类”看起来像是被智能设计的，你得对人类视网膜的结构、大脑的架构、由弱范德华力而非强共价键结合的蛋白质……几乎所有细节都撒谎。

或者，你也可以像大多数创世论者那样，直接对进化论本身撒谎。他们不是对网络中的具体节点撒谎，而是对连接这些节点的普遍规律撒谎。

然后，为了掩盖这些谎言，他们又会对科学的规则撒谎——比如“理论”到底是什么意思，或者科学家说自己并非绝对确定时到底意味着什么。

于是，他们从对具体事实撒谎，发展到对普遍规律撒谎，再到对推理规则撒谎。要想否认人类进化，你必须对进化撒谎；然后你还得对科学的规则撒谎——那些约束我们理解进化的规则。

否则还能怎样？就像一个人类在真正由智能设计的生命体社会中会格格不入一样，你必须对进化的规则撒谎，才能让人类看起来不是自然进化的。同理，创世论的信念本身在科学中也是格格不入的——你不会在一个有序的头脑中发现它们，就像你不会在冰川上看到棕榈树一样。所以你必须破坏那些本该禁止它们的屏障。

这就引出了自我欺骗的问题。

你对自己说的一个谎言，或许在你不知道思维规则，甚至不知道有规则存在时，看起来还挺合理；选择似乎就像选冰淇淋口味一样随意，像海滩上一块孤零零的鹅卵石……

……但当有人用他们学到的推理规则质问你的信念时，他们会说：“你的证据呢？”

你会说：“什么？我为什么需要证据？”

于是他们说：“一般来说，信念需要证据。”

很明显，这个论据是“敌方士兵”，你必须击败它。于是你说：“我不同意！不是所有信念都需要证据。比如关于龙的信念就不需要证据。只要是关于龙的，你想信什么都行。所以我相信我的车库里有条龙，不需要证据。”

对方说：“咦？你不能就这样把龙排除在外。信念需要证据是有原因的。要画出城市的正确地图，你得走遍街道，把你看到的东西画在纸上。这不是随意的法律要求——如果你坐在客厅里随便画，地图肯定是错的，概率极高。这对画龙的地图和画其他东西一样适用。”

现在，这个“为什么信念需要证据”的解释也成了敌方士兵。于是你说：“概率极高就错？那还是有可能对吧？只要不是绝对确定，我就不用相信。”

或者你甚至开始怀疑，“信念需要证据”也许是对的。但这威胁到了你珍视的谎言，于是你拒绝内心的曙光，把太阳重新按回地平线下。或者你以前听过“信念需要证据”这句格言，觉得挺有道理，也在公开场合表示过赞同。但直到有人提醒你，这句话其实也适用于你相信车库里有龙的信念，你才意识到这一点。于是你赶紧说：“龙属于另一个领域。”

拥有错误信念并不是好事，但只要你发现错误后能改正，也不至于造成永久伤害。真正危险的是，你有一个错误信念，而且你认为这个信念本身应该被保护——即“信仰中的信仰”，无论你是否真的相信它。

一个“必须被保护的谎言”足以阻止一个人迈向更高阶的理性。这绝不是无害的乐趣。

正如世界本身远比表面看起来更纠缠复杂，推理的规则也比未经训练者想象的要严格得多，对信念的约束也更强。世界紧密相连，由普遍规律支配，理性信念也是如此。

想想要否认进化论或日心说需要付出什么代价——你得否认多少相关的真理和规律。你就能想象，一旦你的头脑开始被这些联系威胁，一个自我欺骗的行为如何能阻断整个追求真理的元层面。它会禁止理性艺术的所有中间和高阶层次。取而代之的，是一整套反规律、反思维的规则，为相信虚假提供通用的辩护。

Steven Kaas 说过：“传播不够准确的信念就是一种破坏行为。除非你也愿意扎破别人的轮胎，否则别这么做。”让别人去保护一个虚假的信念——让他们觉得这个信念本身必须被保护，不能被任何威胁它的想法动摇——你不该这么做，除非你也愿意给他们做额叶切除手术。

一旦你说了谎，真理就是你的敌人；与之相关的每一个真理，以及所有真理的盟友，都是你必须反对的对象，无论你是对别人还是对自己撒谎。

你必须否认信念需要证据，然后你还得否认地图应该反映领地，接着你还得否认真理是好东西……

于是，黑暗面就此诞生。

我担心人们并没有意识到黑暗面的存在，或者没有足够警惕——我们在这个人类世界中游荡时，完全有可能遇到系统性糟糕的认识论。

那些流传的“如何思考”类格言、深奥智慧的陈词滥调——其中有些确实是理性主义者总结出的好建议。但也有一些观念，是为了保护谎言或自我欺骗而发明的：它们来自黑暗面。

“每个人都有权拥有自己的观点。”你想想，这句格言最初是怎么产生的？这是在保护真理时说出来的，还是在保护人们不被真理伤害时说出来的？但人们并不会警觉地说：“啊哈！我感觉到黑暗面的存在！”据我观察，大家并没有普遍意识到黑暗面就在身边。

但还能怎样？无论你是在欺骗别人，还是自欺，那个“必须被保护的谎言”都会递归地传播到经验因果网络、普遍经验规则、推理规则，甚至这些规则背后的理解。如果世界上有好的认识论，同时又有人试图保护谎言或自欺，那么就一定会出现糟糕的认识论来对抗好的认识论。我们很难指望在这个世界上只找到光明面而没有黑暗面；有太阳，也有躲避阳光、制造阴影的东西。

请注意，这些人未必是邪恶的。大多数传播“深奥智慧”的人其实是被骗了，而不是在骗人，他们更多是自欺而非欺人。我认为是这样。

当然，我并不是想给你一个“万能反驳”，让你每次遇到不喜欢的认识论时都说：“哦，这是黑暗面的人编出来的。”光明面的规则之一就是：你必须针对命题本身进行反驳，而不是指责提出者动机不良。

但黑暗面确实存在。恐惧是通向黑暗面的道路，一次背叛就可能让你堕入其中。不是所有穿长袍的人都是绝地武士或骗子；也有西斯尊主、师父和不自知的学徒。请警惕，请小心。

至于列举那些由黑暗面催生的常见格言——不是随便的错误信念，而是糟糕的认识论、失败的通用辩护——亲爱的读者，你愿意试着总结一下吗？

---

<sup>1</sup>实际上，有评论里的地质学家说，大多数车道上的鹅卵石都是从海滩运来的，所以他们分不出车道鹅卵石和海滩鹅卵石，但能分出山里的鹅卵石和车道/海滩鹅卵石（http://lesswrong.com/lw/uy/dark_side_epistemology/4xbv）。这正说明了问题……

---

## Dark Side Epistemology

If you once tell a lie, the truth is ever after your enemy.

I have discussed the notion that lies are contagious. If you pick up a pebble from the driveway, and tell a geologist that you found it on a beach— well, do you know what a geologist knows about rocks? I don’t. But I can suspect that a water-worn pebble wouldn’t look like a droplet of frozen lava from a volcanic eruption. Do you know where the pebble in your driveway really came from? Things bear the marks of their places in a lawful universe; in that web, a lie is out of place.<sup>1</sup>

What sounds like an arbitrary truth to one mind—one that could easily be replaced by a plausible lie—might be nailed down by a dozen linkages to the eyes of greater knowledge. To a creationist, the idea that life was shaped by “intelligent design” instead of “natural selection” might sound like a sports team to cheer for. To a biologist, plausibly arguing that an organism was intelligently designed would require lying about almost every facet of the organism. To plausibly argue that “humans” were intelligently designed, you’d have to lie about the design of the human retina, the architecture of the human brain, the proteins bound together by weak van der Waals forces instead of strong covalent bonds . . .

Or you could just lie about evolutionary theory, which is the path taken by most creationists. Instead of lying about the connected nodes in the network, they lie about the general laws governing the links.

And then to cover that up, they lie about the rules of science—like what it means to call something a “theory,” or what it means for a scientist to say that they are not absolutely certain.

So they pass from lying about specific facts, to lying about general laws, to lying about the rules of reasoning. To lie about whether humans evolved, you must lie about evolution; and then you have to lie about the rules of science that constrain our understanding of evolution.

But how else? Just as a human would be out of place in a community of actually intelligently designed life forms, and you have to lie about the rules of evolution to make it appear otherwise, so too beliefs about creationism are themselves out of place in science—you wouldn’t find them in a wellordered mind any more than you’d find palm trees growing on a glacier. And so you have to disrupt the barriers that would forbid them.

Which brings us to the case of self-deception.

A single lie you tell yourself may seem plausible enough, when you don’t know any of the rules governing thoughts, or even that there are rules; and the choice seems as arbitrary as choosing a flavor of ice cream, as isolated as a pebble on the shore . . .

. . . but then someone calls you on your belief, using the rules of reasoning that they’ve learned. They say, “Where’s your evidence?”

And you say, “What? Why do I need evidence?”

So they say, “In general, beliefs require evidence.”

This argument, clearly, is a soldier fighting on the other side, which you must defeat. So you say: “I disagree! Not all beliefs require evidence. In particular, beliefs about dragons don’t require evidence. When it comes to dragons, you’re allowed to believe anything you like. So I don’t need evidence to believe there’s a dragon in my garage.”

And the one says, “Eh? You can’t just exclude dragons like that. There’s a reason for the rule that beliefs require evidence. To draw a correct map of the city, you have to walk through the streets and make lines on paper that correspond to what you see. That’s not an arbitrary legal requirement—if you sit in your living room and draw lines on the paper at random, the map’s going to be wrong. With extremely high probability. That’s as true of a map of a dragon as it is of anything.”

So now this, the explanation of why beliefs require evidence, is also an opposing soldier. So you say: “Wrong with extremely high probability? Then there’s still a chance, right? I don’t have to believe if it’s not absolutely certain.”

Or maybe you even begin to suspect, yourself, that “beliefs require evidence.” But this threatens a lie you hold precious; so you reject the dawn inside you, push the Sun back under the horizon. Or you’ve previously heard the proverb “beliefs require evidence,” and it sounded wise enough, and you endorsed it in public. But it never quite occurred to you, until someone else brought it to your attention, that this proverb could apply to your belief that there’s a dragon in your garage. So you think fast and say, “The dragon is in a separate magisterium.”

Having false beliefs isn’t a good thing, but it doesn’t have to be permanently crippling—if, when you discover your mistake, you get over it. The dangerous thing is to have a false belief that you believe should be protected as a belief—a belief-in-belief, whether or not accompanied by actual belief.

A single Lie That Must Be Protected can block someone’s progress into advanced rationality. No, it’s not harmless fun.

Just as the world itself is more tangled by far than it appears on the surface, so too there are stricter rules of reasoning, constraining belief more strongly, than the untrained would suspect. The world is woven tightly, governed by general laws, and so are rational beliefs.

Think of what it would take to deny evolution or heliocentrism—all the connected truths and governing laws you wouldn’t be allowed to know. Then you can imagine how a single act of self-deception can block off the whole meta level of truth-seeking, once your mind begins to be threatened by seeing the connections. Forbidding all the intermediate and higher levels of the rationalist’s Art. Creating, in its stead, a vast complex of anti-law, rules of anti-thought, general justifications for believing the untrue.

Steven Kaas said, “Promoting less than maximally accurate beliefs is an act of sabotage. Don’t do it to anyone unless you’d also slash their tires.” Giving someone a false belief to protect—convincing them that the belief itself must be defended from any thought that seems to threaten it—well, you shouldn’t do that to someone unless you’d also give them a frontal lobotomy.

Once you tell a lie, the truth is your enemy; and every truth connected to that truth, and every ally of truth in general; all of these you must oppose, to protect the lie. Whether you’re lying to others, or to yourself.

You have to deny that beliefs require evidence, and then you have to deny that maps should reflect territories, and then you have to deny that truth is a good thing . . .

Thus comes into being the Dark Side.

I worry that people aren’t aware of it, or aren’t sufficiently wary—that as we wander through our human world, we can expect to encounter systematically bad epistemology.

The “how to think” memes floating around, the cached thoughts of Deep Wisdom—some of it will be good advice devised by rationalists. But other notions were invented to protect a lie or self-deception: spawned from the Dark Side.

“Everyone has a right to their own opinion.” When you think about it, where was that proverb generated? Is it something that someone would say in the course of protecting a truth, or in the course of protecting from the truth? But people don’t perk up and say, “Aha! I sense the presence of the Dark Side!” As far as I can tell, it’s not widely realized that the Dark Side is out there.

But how else? Whether you’re deceiving others, or just yourself, the Lie That Must Be Protected will propagate recursively through the network of empirical causality, and the network of general empirical rules, and the rules of reasoning themselves, and the understanding behind those rules. If there is good epistemology in the world, and also lies or self-deceptions that people are trying to protect, then there will come into existence bad epistemology to counter the good. We could hardly expect, in this world, to find the Light Side without the Dark Side; there is the Sun, and that which shrinks away and generates a cloaking Shadow.

Mind you, these are not necessarily evil people. The vast majority who go about repeating the Deep Wisdom are more duped than duplicitous, more self-deceived than deceiving. I think.

And it’s surely not my intent to offer you a Fully General Counterargument, so that whenever someone offers you some epistemology you don’t like, you say: “Oh, someone on the Dark Side made that up.” It’s one of the rules of the Light Side that you have to refute the proposition for itself, not by accusing its inventor of bad intentions.

But the Dark Side is out there. Fear is the path that leads to it, and one betrayal can turn you. Not all who wear robes are either Jedi or fakes; there are also the Sith Lords, masters and unwitting apprentices. Be warned; be wary.

As for listing common memes that were spawned by the Dark Side—not random false beliefs, mind you, but bad epistemology, the Generic Defenses of Fail—well, would you care to take a stab at it, dear readers?

---

<sup>1</sup>Actually, a geologist in the comments says that most pebbles in driveways are taken from beaches, so they couldn’t tell the difference between a driveway pebble and a beach pebble, but they could tell the difference between a mountain pebble and a driveway/beach pebble (http://lesswrong.com/lw/uy/dark_side_epistemology/4xbv). Case in point . . .