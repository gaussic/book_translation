## 合理化

作者：Eliezer Yudkowsky

在《**底线（The Bottom Line）**》一文中，我提出了一个两只箱子的难题：只有一个箱子里有钻石，我们拥有各种迹象和预兆作为证据。我将探究者分为两种：**好奇的探索者**和**聪明的论辩者**。

**好奇的探索者**会把所有的迹象和预兆都记下来，进行推理处理，最后写下：“因此，我估计 B 箱有 85% 的概率含有钻石。”

**聪明的论辩者**则是为出价最高者服务的。他一开始就写下：“因此，B 箱含有钻石。” 然后在前面的部分挑选有利的迹象和预兆来支持这个结论。

第一种做法是**理性**。第二种做法通常被称为\*\*“合理化”\*\*。

“合理化”——多么奇怪的词。我会说，这根本就是一个用错了的词。你不能“合理化”本身不理性的东西。这就好像把“撒谎”叫作“真理化”一样荒唐。

从计算层面上来说，下面这两种做法有本质上的巨大差别：

1. **从证据出发**，计算概率流动，从而得出一个可能的结论。（记录所有的迹象和预兆，然后顺着它们推导出一个依赖于这些信息的结论——即底线概率。）
2. **从结论出发**，计算概率流动，从而寻找表面支持该结论的证据。（先写下结论，即底线，然后逆着流程，挑选可以写在上面的迹象和预兆作为支撑。）

哪个笨蛋发明了“rationality”（理性）和“rationalization”（合理化）这两个容易混淆的词，来描述如此截然不同的心理过程？我更愿意用能揭示算法区别的术语，比如“理性”对“认知黑洞巨兽”。

并不是所有的改变都是改进，但每一次改进必然意味着某种改变。你无法通过争论让一个已知命题变得更“真”；你可以让更多人相信它，但不能让它因此更接近真理。要让我们的信念更接近真理，我们**必须改变**信念本身。理性是一种用来**改变信念以提升其准确性**的操作。而合理化的操作则是**让信念停滞不前**；它更应被称为“反理性”，无论是从其实际效果，还是从其倒置的算法来看。

“理性”是一种**正向流程**：收集证据、权衡、得出结论。
好奇的探索者使用的是正向流程算法：首先收集证据，记录下所有可见的迹象和预兆，然后进行推理处理，得出某个尚未知晓的概率——哪个箱子里更可能有钻石。整个理性过程运行期间，好奇的探索者并不知道最终的结论，这正是他之所以好奇的原因。在贝叶斯之道中，先验概率等于期望的后验概率：如果你已经知道终点，那你早已抵达了。

“合理化”则是从结论反向流动，去选择性地找出支持的证据。你首先写下底线结论，它是已知且固定的；整个推理过程的目的，是找出你该写些什么在前面的部分来支撑它。而这些“理由”才是过程中的未知变量。

我担心，传统理性主义并没有让其信奉者意识到正向流程与反向流程之间的根本差异。在传统理性观中，一个科学家得出心爱假设后，为了“验证”它而去设计实验，并没有被视为错误。传统理性主义者甚至可能对此表示认同，说：“这种执着，是科学进步的引擎。”

确实，它推动了科学的进展。但请注意：要找一对在立场上相反的控辩双方并不难，但要找到一个完全无偏的人类却非常困难。

但事情普遍存在，并不意味着它就是合理的。如果那位科学家在形成假设之后，是出于**好奇心**而去测试这个假设——设计能真正推动自己信念变化的实验——那不是更好吗？

如果你真的不知道自己将会得出什么结论，那你很可能会感到真正的好奇。而**好奇心**，正是第一美德。没有它，你的问题就没有方向，你的技能也没有目标。

感受一下“原力”的流动，确保它不是**反着流的**。

---

## Rationalization

by Eliezer Yudkowsky

In “The Bottom Line,” I presented the dilemma of two boxes, only one of which contains a diamond, with various signs and portents as evidence. I dichotomized the curious inquirer and the clever arguer. The curious inquirer writes down all the signs and portents, and processes them, and finally writes down, “Therefore, I estimate an 85% probability that box B contains the diamond.” The clever arguer works for the highest bidder, and begins by writing, “Therefore, box B contains the diamond,” and then selects favorable signs and portents to list on the lines above.

The first procedure is rationality. The second procedure is generally known as “rationalization.”

“Rationalization.” What a curious term. I would call it a wrong word. You cannot “rationalize” what is not already rational. It is as if “lying” were called “truthization.”

On a purely computational level, there is a rather large difference between:

1. Starting from evidence, and then crunching probability flows, in order to output a probable conclusion. (Writing down all the signs and portents, and then flowing forward to a probability on the bottom line which depends on those signs and portents.) 
2. Starting from a conclusion, and then crunching probability flows, in order to output evidence apparently favoring that conclusion. (Writing down the bottom line, and then flowing backward to select signs and portents for presentation on the lines above.)

What fool devised such confusingly similar words, “rationality” and “rationalization,” to describe such extraordinarily different mental processes? I would prefer terms that made the algorithmic difference obvious, like “rationality” versus “giant sucking cognitive black hole.”

Not every change is an improvement, but every improvement is necessarily a change. You cannot obtain more truth for a fixed proposition by arguing it; you can make more people believe it, but you cannot make it more true. To improve our beliefs, we must necessarily change our beliefs. Rationality is the operation that we use to obtain more accuracy for our beliefs by changing them. Rationalization operates to fix beliefs in place; it would be better named “anti-rationality,” both for its pragmatic results and for its reversed algorithm.

“Rationality” is the forward flow that gathers evidence, weighs it, and outputs a conclusion. The curious inquirer used a forward-flow algorithm: first gathering the evidence, writing down a list of all visible signs and portents, which they then processed forward to obtain a previously unknown probability for the box containing the diamond. During the entire time that the rationality-process was running forward, the curious inquirer did not yet know their destination, which was why they were curious. In the Way of Bayes, the prior probability equals the expected posterior probability: If you know your destination, you are already there.

“Rationalization” is a backward flow from conclusion to selected evidence. First you write down the bottom line, which is known and fixed; the purpose of your processing is to find out which arguments you should write down on the lines above. This, not the bottom line, is the variable unknown to the running process.

I fear that Traditional Rationality does not properly sensitize its users to the difference between forward flow and backward flow. In Traditional Rationality, there is nothing wrong with the scientist who arrives at a pet hypothesis and then sets out to find an experiment that proves it. A Traditional Rationalist would look at this approvingly, and say, “This pride is the engine that drives Science forward.” Well, it is the engine that drives Science forward. It is easier to find a prosecutor and defender biased in opposite directions, than to find a single unbiased human.

But just because everyone does something, doesn’t make it okay. It would be better yet if the scientist, arriving at a pet hypothesis, set out to test that hypothesis for the sake of curiosity—creating experiments that would drive their own beliefs in an unknown direction.

If you genuinely don’t know where you are going, you will probably feel quite curious about it. Curiosity is the first virtue, without which your questioning will be purposeless and your skills without direction.

Feel the flow of the Force, and make sure it isn’t flowing backwards.