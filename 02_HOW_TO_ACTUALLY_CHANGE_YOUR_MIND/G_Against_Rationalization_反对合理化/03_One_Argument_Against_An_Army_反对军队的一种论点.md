## 反对军队的一种论点

作者：Eliezer Yudkowsky

我曾谈到一种推理方式：在这种方式中，一个反对的论点都不被允许存在，结果导致每一个不支持的观察都必须被辩驳掉。在这里，我想指出，人们在遇到反对论据时，往往会通过反复回忆已有的支持性论据，来阻止自己降低信心。

假设“自由尼亚”这个国家正在辩论其邻国“西尔瓦尼亚”是否应对最近一连串陨石袭击城市的事件负责。有几个证据似乎支持这一说法：这些陨石袭击了靠近西尔瓦尼亚边境的城市；袭击发生前，西尔瓦尼亚的股市出现了异常活动；而西尔瓦尼亚的大使特伦蒂诺也曾被听到低声说起“天谴”。

有人找到你说：“我不认为西尔瓦尼亚应对这些陨石袭击负责。他们每年和我们有数十亿第纳尔的贸易往来。”
你回答道：“可是那些陨石袭击了靠近西尔瓦尼亚的城市，他们的股市在事发前出现了异常活动，而且他们的大使还提到‘天谴’。”
因为这三个论点比前者更有力，所以你仍然相信西尔瓦尼亚是始作俑者——你是倾向于相信而非不信的，从定性上讲，证据的天平显然是倾斜向西尔瓦尼亚不利的一方。

随后又有人对你说：“我不认为西尔瓦尼亚应对陨石袭击负责。要操纵一次陨石袭击实在太困难了，西尔瓦尼亚甚至连太空计划都没有。”
你再次回答：“但那些陨石袭击了靠近西尔瓦尼亚的城市，而且他们的投资人显然事先知道了这件事，他们的大使也几乎是当众承认了！”
又一次，这三个论据战胜了一个新的反对论据（3比1），所以你继续坚持原有信念，认为西尔瓦尼亚要负责任。

事实上，你的信念变得更坚定了。你已经在两个独立的场合评估了证据的权重，两次的结果都是3比1地指向西尔瓦尼亚有责。

你不断遇到更多的“亲西尔瓦尼亚”叛徒的论点——一遍又一遍，一百遍又一百遍——但每次新的论据都被你那三条熟悉的论据轻松击败。而在每一次反驳之后，你都觉得自己对西尔瓦尼亚有责的信念变得更强了，你根据“感觉上的证据平衡”调整了自己原先的概率。

问题在于，你通过不断重复原先就知道的论点，实际上是在**重复计算同一份证据**。哪怕你是重复计算了所有的证据，这都是一种严重的错误。（想象一下，一个科学家做了一项有50个受试者的实验，结果没有得到统计学上的显著结果，于是他把全部数据重复计算一遍。）

而**只重复计算部分证据**，那就纯属闹剧了。我小时候看过一幅漫画，反派角色用这样的方法分赃：“一份给你，一份给我。再一份给你，一二份给我。再一份给你，一二三份给我。”

正如我在上一篇文章中强调的：即使你钟爱的信念是正确的，一个理性的人在整合所有证据时，也可能需要**下调**这个信念的概率。是的，证据总体上可能仍然支持你的信念，但你仍然必须下调它的概率——是的，**下调**——相对于你听到反对证据**之前**的状态而言。重复强调你早就知道的支持性论点根本无济于事，因为那些论点已经被你计算在内了。

然而，我确实观察到，当人们面对新的反对论据时，他们往往会寻找理由**不去降低信心**，而当然他们找到的就是自己早已知晓的支持论据。我自己也必须时刻警惕，不去犯这种错误！这种反应就像是本能——就像拿起手边的盾牌去格挡剑击一样自然。

用错误的推理方式，哪怕只有少数几个支持论据，甚至只有一个，也可以挡住一整支由反对证据组成的“军队”。

---

## One Argument Against An Army

by Eliezer Yudkowsky

I talked about a style of reasoning in which not a single contrary argument is allowed, with the result that every non-supporting observation has to be argued away. Here I suggest that when people encounter a contrary argument, they prevent themselves from downshifting their confidence by rehearsing already-known support.

Suppose the country of Freedonia is debating whether its neighbor, Sylvania, is responsible for a recent rash of meteor strikes on its cities. There are several pieces of evidence suggesting this: the meteors struck cities close to the Sylvanian border; there was unusual activity in the Sylvanian stock markets before the strikes; and the Sylvanian ambassador Trentino was heard muttering about “heavenly vengeance.”

Someone comes to you and says: “I don’t think Sylvania is responsible for the meteor strikes. They have trade with us of billions of dinars annually.” “Well,” you reply, “the meteors struck cities close to Sylvania, there was suspicious activity in their stock market, and their ambassador spoke of heavenly vengeance afterward.” Since these three arguments outweigh the first, you keep your belief that Sylvania is responsible—you believe rather than disbelieve, qualitatively. Clearly, the balance of evidence weighs against Sylvania.

Then another comes to you and says: “I don’t think Sylvania is responsible for the meteor strikes. Directing an asteroid strike is really hard. Sylvania doesn’t even have a space program.” You reply, “But the meteors struck cities close to Sylvania, and their investors knew it, and the ambassador came right out and admitted it!” Again, these three arguments outweigh the first (by three arguments against one argument), so you keep your belief that Sylvania is responsible.

Indeed, your convictions are strengthened. On two separate occasions now, you have evaluated the balance of evidence, and both times the balance was tilted against Sylvania by a ratio of 3 to 1.

You encounter further arguments by the pro-Sylvania traitors—again, and again, and a hundred times again—but each time the new argument is handily defeated by 3 to 1. And on every occasion, you feel yourself becoming more confident that Sylvania was indeed responsible, shifting your prior according to the felt balance of evidence.

The problem, of course, is that by rehearsing arguments you already knew, you are double-counting the evidence. This would be a grave sin even if you double-counted all the evidence. (Imagine a scientist who does an experiment with 50 subjects and fails to obtain statistically significant results, so the scientist counts all the data twice.)

But to selectively double-count only some evidence is sheer farce. I remember seeing a cartoon as a child, where a villain was dividing up loot using the following algorithm: “One for you, one for me. One for you, one-two for me. One for you, one-two-three for me.”

As I emphasized in the last essay, even if a cherished belief is true, a rationalist may sometimes need to downshift the probability while integrating all the evidence. Yes, the balance of support may still favor your cherished belief. But you still have to shift the probability down—yes, down—from whatever it was before you heard the contrary evidence. It does no good to rehearse supporting arguments, because you have already taken those into account.

And yet it does appear to me that when people are confronted by a new counterargument, they search for a justification not to downshift their confidence, and of course they find supporting arguments they already know. I have to keep constant vigilance not to do this myself! It feels as natural as parrying a sword-strike with a handy shield.

With the right kind of wrong reasoning, a handful of support—or even a single argument—can stand off an army of contradictions.