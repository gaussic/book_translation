以下是 Eliezer Yudkowsky 的文章《**那真的是你真正的拒绝理由吗？**》的中文翻译：

---

## 那真的是你真正的拒绝理由吗？

**作者：Eliezer Yudkowsky**

有时候，有人听到我关于超人类主义的某些观点（不同于我关于人类理性的观点）——比如超级智能、友善 AI 这些听起来奇怪、异域、甚至怪诞的想法——然后直接拒绝了它们。

当有人要求他解释为什么拒绝时，他常常会说：“我为什么要相信 Yudkowsky 说的话？他又没有博士学位！”

偶尔，也会有其他人听了之后说：“哦，你应该去拿个博士学位，这样大家才会听你的。”甚至，有时候就是那个不相信我的人自己给出这个建议：“等你拿到博士学位再来找我。”

但是，拿博士学位有好理由，也有坏理由。而这，显然是个坏理由。

人们对超人类主义论题可能产生本能反感的原因有很多。大多数时候，这种反感更像是一种**模式识别**，而非语言上的理性思考：这些论点触发了人脑中的某种分类标签，比如“怪异想法”、“科幻”、“世界末日邪教”或者“热血过头的年轻人”。<sup>1</sup>
然后，在感知速度的瞬间，想法就被否定了。

如果之后有人问：“为什么反对？”那么大脑就会启动一个寻找正当理由的过程，但这个寻找并**不一定会找到真正的原因**。
这里的“真正的原因”，指的不是最好的理由，而是**在最初拒绝发生时，实际起决定作用的那些因果因素**。

相反，这个找理由的过程通常会停在一个听起来像是正当理由的点上，比如：“这个人没有博士学位。”
但我在谈人类理性的时候也没有博士学位，为什么那时没人提出同样的反对？

更关键的是，如果我真的有博士学位，人们也不会因此就觉得我说的每句话都值得相信。
他们还是会以同样的原因产生最初的否定反应；只是，在后续为拒绝寻找借口的过程中，会停在另一个“看起来合理”的地方。

他们可能会说：“我为什么要相信你？你不过是一个拿了博士的人！这样的人多了去了。等你在这个领域出名了，还在顶级大学拿到终身教职，再来找我。”

可人们真的会相信哈佛那些说奇怪话的教授吗？当然不会。

如果你讲的东西对新手听起来不对劲——而不是那种听起来就像在讲“N+2维里胶子夸克编织的魔法技术术语”的东西——而听众又是个不认识你的人，也不懂你的专业背景，我怀疑，一般人**真正会因为你有学术头衔而改变初步印象**，大概要到诺贝尔奖得主那个级别。也许还不止。
大概得是那种已经“远远超出平常人”的学术地位才行。

这差不多就是我看到的 Eric Drexler 的遭遇。他提出了自己的纳米技术愿景，然后人们说：“细节在哪？”或者“等你拿了博士再说！”于是 Drexler 花了六年时间写技术细节，并在 Marvin Minsky 指导下拿到了博士学位。他的《纳米系统》是本很棒的书。
但那些说“你拿了博士再来”的人，真的因此改变了他们对分子纳米技术的看法吗？据我所知，没有。

这件事，对年轻企业和新晋顾问来说，可能非常重要。客户告诉你的“拒绝理由”，可能并不是真正的决定性因素；在你投入大量资源去改进它们之前，值得你认真思考。
比如风投说：“如果你们销售增长再快一点就好了！”或者潜在客户说：“看起来不错，但你们缺少某个功能。”
这些可能**并不是他们真正拒绝的原因**。你把这些问题修好了，也**未必**会改变结局。

在意见不合时，这一点也很重要。Robin Hanson 和我都认为，两位理性主义者不应该“同意彼此不同意”：如果存在明确的认知分歧，而且彼此都意识到，那说明一定出了什么问题。<sup>2</sup>

我怀疑，大多数时候，如果两位理性主义者试图解决一个持续的分歧，在初次交流之后仍然存在的那种分歧，那么他们会发现：**真正造成分歧的根源，要么难以表达，要么难以自我揭露**。例如：

* 罕见但确实有支持的数据或数学知识；
* 逻辑链条太长、推理距离太远；
* 难以言表的直觉，可能源于特定的心象画面；
* 某个行业的时代氛围（可能有其合理性）；
* 来自经验的模式识别；
* 思维习惯；
* 对某种结局的情感投入；
* 担心过去的错误会被揭穿；
* 为了自尊或其他私利而深度自欺。

如果这场分歧的真正拒绝理由真的能轻松摆上台面，那么这场分歧大概率根本不会持续到现在——在第一次见面时就已经解决了。

“这真的是我真正的拒绝理由吗？”——这是每一个在分歧中的人都应该自问的问题，好让对方更容易理解你。
不过，从我观察到的情况来看，如果你试图**当面直接**分析对方的心理动机，谈话往往会迅速崩坏。

即便如此，在合理范围内，**“那是你真正的拒绝吗？”** 这个问题还是应该允许被提出的。前提是你能用一种有建设性的方式来探讨这个次话题。
也许我们可以定个规则：你可以诚恳地问对方：“那个听起来很简单的拒绝理由，是你真正的拒绝吗？还是其实源自你某种直觉-X，或者职业文化氛围-Y？”
至于那些更让人尴尬的原因，就留给对方自己去面对吧，那是他们自己的责任。

---

<sup>1</sup>参见《地图与领地》中的“科学作为服饰”。 

<sup>2</sup>参见 Hal Finney，“Agreeing to Agree”，发表于 Overcoming Bias 博客，2006年，[http://www.overcomingbias.com/2006/12/agreeing\_to\_agr.html。](http://www.overcomingbias.com/2006/12/agreeing_to_agr.html。)

---

## Is That Your True Rejection?

by Eliezer Yudkowsky

It happens every now and then that someone encounters some of my transhumanist-side beliefs—as opposed to my ideas having to do with human rationality—strange, exotic-sounding ideas like superintelligence and Friendly AI. And the one rejects them.

If the one is called upon to explain the rejection, not uncommonly the one says, “Why should I believe anything Yudkowsky says? He doesn’t have a PhD!”

And occasionally someone else, hearing, says, “Oh, you should get a PhD, so that people will listen to you.” Or this advice may even be offered by the same one who expressed disbelief, saying, “Come back when you have a PhD.”

Now, there are good and bad reasons to get a PhD. This is one of the bad ones.

There are many reasons why someone might actually have an initial adverse reaction to transhumanist theses. Most are matters of pattern recognition, rather than verbal thought: the thesis calls to mind an associated category like “strange weird idea” or “science fiction” or “end-of-the-world cult” or “overenthusiastic youth.”<sup>1</sup> Immediately, at the speed of perception, the idea is rejected.

If someone afterward says, “Why not?” this launches a search for justification, but the search won’t necessarily hit on the true reason. By “‘true reason,” I don’t mean the best reason that could be offered. Rather, I mean whichever causes were decisive as a matter of historical fact, at the very first moment the rejection occurred.

Instead, the search for justification hits on the justifying-sounding fact, “This speaker does not have a PhD.” But I also don’t have a PhD when I talk about human rationality, so why is the same objection not raised there?

More to the point, if I had a PhD, people would not treat this as a decisive factor indicating that they ought to believe everything I say. Rather, the same initial rejection would occur, for the same reasons; and the search for justification, afterward, would terminate at a different stopping point.

They would say, “Why should I believe you? You’re just some guy with a PhD! There are lots of those. Come back when you’re well-known in your field and tenured at a major university.”

But do people actually believe arbitrary professors at Harvard who say weird things? Of course not.

If you’re saying things that sound wrong to a novice, as opposed to just rattling off magical-sounding technobabble about leptical quark braids in N + 2 dimensions; and if the hearer is a stranger, unfamiliar with you personally and unfamiliar with the subject matter of your field; then I suspect that the point at which the average person will actually start to grant credence overriding their initial impression, purely because of academic credentials, is somewhere around the Nobel Laureate level. If that. Roughly, you need whatever level of academic credential qualifies as “beyond the mundane.”

This is more or less what happened to Eric Drexler, as far as I can tell. He presented his vision of nanotechnology, and people said, “Where are the technical details?” or “Come back when you have a PhD!” And Eric Drexler spent six years writing up technical details and got his PhD under Marvin Minsky for doing it. And Nanosystems is a great book. But did the same people who said, “Come back when you have a PhD,” actually change their minds at all about molecular nanotechnology? Not so far as I ever heard.

This might be an important thing for young businesses and new-minted consultants to keep in mind—that what your failed prospects tell you is the reason for rejection may not make the real difference; and you should ponder that carefully before spending huge efforts. If the venture capitalist says, “If only your sales were growing a little faster!” or if the potential customer says, “It seems good, but you don’t have feature X,” that may not be the true rejection. Fixing it may, or may not, change anything.

And it would also be something to keep in mind during disagreements. Robin Hanson and I share a belief that two rationalists should not agree to disagree: they should not have common knowledge of epistemic disagreement unless something is very wrong.<sup>2</sup>

I suspect that, in general, if two rationalists set out to resolve a disagreement that persisted past the first exchange, they should expect to find that the true sources of the disagreement are either hard to communicate, or hard to expose. E.g.:

- Uncommon, but well-supported, scientific knowledge or math;
- Long inferential distances;
- Hard-to-verbalize intuitions, perhaps stemming from specific visualizations;
- Zeitgeists inherited from a profession (that may have good reason for it);
- Patterns perceptually recognized from experience;
- Sheer habits of thought;
- Emotional commitments to believing in a particular outcome;
- Fear that a past mistake could be disproved;
- Deep self-deception for the sake of pride or other personal benefits.

If the matter were one in which all the true rejections could be easily laid on the table, the disagreement would probably be so straightforward to resolve that it would never have lasted past the first meeting.

“Is this my true rejection?” is something that both disagreers should surely be asking themselves, to make things easier on the other person. However, attempts to directly, publicly psychoanalyze the other may cause the conversation to degenerate very fast, from what I’ve seen.

Still—“Is that your true rejection?” should be fair game for Disagreers to humbly ask, if there’s any productive way to pursue that sub-issue. Maybe the rule could be that you can openly ask, “Is that simple straightforward-sounding reason your true rejection, or does it come from intuition-X or professional-zeitgeist-Y ?” While the more embarrassing possibilities lower on the table are left to the Other’s conscience, as their own responsibility to handle.

---

<sup>1</sup>See “Science as Attire” in Map and Territory.

<sup>2</sup>See Hal Finney, “Agreeing to Agree,” Overcoming Bias (blog), 2006, http://www.overcomingbias.com/2006/12/agreeing_to_agr.html.