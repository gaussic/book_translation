## 合理化

在《结论先行》中，我提出了两个箱子的困境：只有一个箱子里有钻石，各种迹象和征兆作为证据。我把“好奇的探究者”和“聪明的辩手”区分开来。好奇的探究者会把所有迹象和征兆都记下来，进行分析，最后写下：“因此，我估计B箱有85%的概率含有钻石。”而聪明的辩手则为出价最高者服务，一开始就写下“所以，B箱里有钻石”，然后在上面罗列有利的迹象和征兆。

第一种做法是理性。第二种做法通常被称为“合理化”。

“合理化”——多么奇怪的词。我觉得这其实是个错误的词。你无法让本就不理性的东西变得理性。就好像把“撒谎”叫做“真理化”一样。

在纯粹的计算层面上，这两种做法有着极大的区别：

1. 从证据出发，计算概率流，最终得出一个可能的结论。（先把所有迹象和征兆都记下来，然后推导出一个依赖于这些迹象和征兆的结论概率。）
2. 从结论出发，计算概率流，最终挑选出看似支持该结论的证据。（先写下结论，再反向挑选要在上面列出的迹象和征兆。）

是谁发明了“理性”（rationality）和“合理化”（rationalization）这两个容易混淆的词来描述如此截然不同的心理过程？我更希望用能直接体现算法差异的词，比如“理性”对“巨型认知黑洞”。

不是所有改变都是进步，但每一次进步必然意味着改变。你无法通过为一个固定命题辩护来让它变得更真实；你可以让更多人相信它，但无法让它更接近真理。要让我们的信念更接近真理，我们就必须改变信念。理性就是通过改变信念来让信念更准确的操作。而合理化的作用是让信念固定不变；无论从实际结果还是算法流程来看，它都更应该叫“反理性”。

“理性”是一种正向流动，收集证据、权衡证据，最后得出结论。好奇的探究者用的是正向算法：先收集证据，写下所有可见的迹象和征兆，然后正向推导，得到箱子含钻石的概率。在整个理性过程正向运行时，好奇的探究者并不知道最终会得出什么结论，这正是他们好奇的原因。在贝叶斯之道中，先验概率等于期望的后验概率：如果你已经知道终点，那你其实已经在那里了。

“合理化”则是从结论出发，反向挑选证据。你先写下已经确定的结论，整个推理的目的就是找出该在上面写哪些论据。此时，真正的未知量不是结论，而是你要写哪些论据。

我担心传统理性主义并没有让人们真正意识到正向推理和反向推理的区别。在传统理性主义中，科学家先有一个宠爱的假说，然后再去找实验来证明它，这并不被认为有问题。传统理性主义者会赞许地说：“这种自豪感正是推动科学前进的引擎。”没错，这确实是推动科学前进的引擎。找到一个有偏见的控方和一个有偏见的辩方，比找到一个完全无偏见的人要容易得多。

但仅仅因为大家都这么做，并不代表这样就是对的。如果科学家在有了宠爱假说后，是出于好奇心去检验它——设计实验让自己的信念朝未知方向发展——那会更好。

如果你真的不知道自己会得出什么结论，你大概率会对结果感到好奇。好奇心是第一美德，没有它，你的提问就没有目标，你的技能也没有方向。

感受一下“原力”的流动，确保它不是在反向流动。

---

## Rationalization

In “The Bottom Line,” I presented the dilemma of two boxes, only one of which contains a diamond, with various signs and portents as evidence. I dichotomized the curious inquirer and the clever arguer. The curious inquirer writes down all the signs and portents, and processes them, and finally writes down, “Therefore, I estimate an 85% probability that box B contains the diamond.” The clever arguer works for the highest bidder, and begins by writing, “Therefore, box B contains the diamond,” and then selects favorable signs and portents to list on the lines above.

The first procedure is rationality. The second procedure is generally known as “rationalization.”

“Rationalization.” What a curious term. I would call it a wrong word. You cannot “rationalize” what is not already rational. It is as if “lying” were called “truthization.”

On a purely computational level, there is a rather large difference between:

1. Starting from evidence, and then crunching probability flows, in order to output a probable conclusion. (Writing down all the signs and portents, and then flowing forward to a probability on the bottom line which depends on those signs and portents.)
2. Starting from a conclusion, and then crunching probability flows, in order to output evidence apparently favoring that conclusion. (Writing down the bottom line, and then flowing backward to select signs and portents for presentation on the lines above.)

What fool devised such confusingly similar words, “rationality” and “rationalization,” to describe such extraordinarily different mental processes? I would prefer terms that made the algorithmic difference obvious, like “rationality” versus “giant sucking cognitive black hole.”

Not every change is an improvement, but every improvement is necessarily a change. You cannot obtain more truth for a fixed proposition by arguing it; you can make more people believe it, but you cannot make it more true. To improve our beliefs, we must necessarily change our beliefs. Rationality is the operation that we use to obtain more accuracy for our beliefs by changing them. Rationalization operates to fix beliefs in place; it would be better named “anti-rationality,” both for its pragmatic results and for its reversed algorithm.

“Rationality” is the forward flow that gathers evidence, weighs it, and outputs a conclusion. The curious inquirer used a forward-flow algorithm: first gathering the evidence, writing down a list of all visible signs and portents, which they then processed forward to obtain a previously unknown probability for the box containing the diamond. During the entire time that the rationality-process was running forward, the curious inquirer did not yet know their destination, which was why they were curious. In the Way of Bayes, the prior probability equals the expected posterior probability: If you know your destination, you are already there.

“Rationalization” is a backward flow from conclusion to selected evidence. First you write down the bottom line, which is known and fixed; the purpose of your processing is to find out which arguments you should write down on the lines above. This, not the bottom line, is the variable unknown to the running process.

I fear that Traditional Rationality does not properly sensitize its users to the difference between forward flow and backward flow. In Traditional Rationality, there is nothing wrong with the scientist who arrives at a pet hypothesis and then sets out to find an experiment that proves it. A Traditional Rationalist would look at this approvingly, and say, “This pride is the engine that drives Science forward.” Well, it is the engine that drives Science forward. It is easier to find a prosecutor and defender biased in opposite directions, than to find a single unbiased human.

But just because everyone does something, doesn’t make it okay. It would be better yet if the scientist, arriving at a pet hypothesis, set out to test that hypothesis for the sake of curiosity—creating experiments that would drive their own beliefs in an unknown direction.

If you genuinely don’t know where you are going, you will probably feel quite curious about it. Curiosity is the first virtue, without which your questioning will be purposeless and your skills without direction.

Feel the flow of the Force, and make sure it isn’t flowing backwards.