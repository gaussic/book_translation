## 启动效应与污染

假设你让受试者看到一串字母，如果这些字母组成了一个单词就按一个按钮，否则按另一个按钮（比如“banack”和“banner”）。然后你给他们看“water”这个单词。之后，他们会更快地认出“drink”也是一个单词。这就是“认知启动效应”（priming），这种情况具体属于“语义启动”或“概念启动”。

启动效应的奇妙之处在于它发生在极低的认知层级——它能加快你识别字母是否组成单词的速度，而这一步通常发生在你思考单词含义之前。

启动效应还揭示了激活在大脑中的大规模并行传播：如果看到“water”能激活“drink”，那很可能也会激活“river”“cup”“splash”等等……这种激活会沿着概念的语义联系一路扩散，甚至影响到字母串的识别。启动效应是无意识且无法阻止的，是人类神经结构的产物。试图阻止自己被启动效应影响，就像试图阻止自己神经回路的激活扩散一样。

你可以试试做一组卡片，每张卡片上写着像BROWN这样的单词，但颜色是随机分配的——比如用红色写“GREEN”，用蓝色写“YELLOW”，等等。试着大声说出这些字母串的颜色——不是它们的含义，而是颜色本身。

在 Mussweiler 和 Strack 的实验中，受试者被问到一个锚定问题：“德国的年平均气温高于还是低于5°C / 20°C？”<sup>1</sup> 随后，在单词识别任务中，接受5°C锚点的受试者更快认出“cold”和“snow”这样的单词，而高锚点组则更快认出“hot”和“sun”。这说明锚定效应不仅仅是调整机制，还包括启动兼容的想法和记忆。

更一般的结论是，完全无信息、已知为假或完全无关的“信息”也能影响我们的估算和决策。在启发式与偏见领域，这种更普遍的现象被称为“污染效应”。<sup>2</sup>

启发式与偏见的早期研究发现了锚定效应，比如受试者在被问“联合国成员国中非洲国家的比例是否高于或低于10（或65）”后，给出的估算会更低（或更高）。最初的解释是，受试者会以锚点为起点进行调整，直到达到一个看起来合理的值，然后停止调整，因此调整幅度不足，因为他们在置信区间的一端就停下了。<sup>3</sup>

Tversky 和 Kahneman 的早期假设在某些情况下仍然是正确的，尤其是当受试者自己生成初始估算时。但现代研究表明，大多数锚定效应其实是污染效应，而不是滑动调整。<sup>4</sup>

你的超市可能会有“每人限购12件”或“5件10美元”这样的标语。这些标语真的能让顾客买更多吗？你可能觉得自己不会被影响。但一定有人会受影响，因为这些标语确实有效，所以商家才会一直用。<sup>5</sup>

然而，污染效应最可怕的地方在于，它是确认偏误的千面之一。<sup>6</sup> 一旦某个想法进入你的脑海，它就会启动与之兼容的信息，从而保证它的持续存在。别管政治争论中的胜负压力，确认偏误直接写在我们的硬件里，联想网络会自动启动兼容的想法和记忆。这是我们作为神经生物体的一个不幸副作用。

一个短暂的画面就足以启动相关单词的识别。别以为需要更多才能让确认偏误启动。只要有那么一闪念，结论就已经被决定了，而我们改变主意的频率远比自己以为的要低……

---

<sup>1</sup>Mussweiler 和 Strack, “Comparing Is Believing,” 1999.

<sup>2</sup>Chapman 和 Johnson, “Incorporating the Irrelevant,” 2002.

<sup>3</sup>Tversky 和 Kahneman, “Judgment Under Uncertainty,” 1974.

<sup>4</sup>Epley 和 Gilovich, “Putting Adjustment Back in the Anchoring and Adjustment Heuristic,” 2001.

<sup>5</sup>Wansink, Kent, and Hoch, “An Anchoring and Adjustment Model of Purchase Quantity Decisions,” 1998, http://www.jstor.org/stable/3151931.

<sup>6</sup>参见《第三种选择》《了解偏见有时会伤害人》《反对“论据大军”的一个理由》《什么是“被筛选的证据”？》《合理化》以及《地图与领地》中的《事后诸葛亮贬低科学》《伪因果》《正偏误：向黑暗中看去》，还有本书的其他内容。

---

## Priming and Contamination

Suppose you ask subjects to press one button if a string of letters forms a word, and another button if the string does not form a word (e.g., “banack” vs. “banner”). Then you show them the string “water.” Later, they will more quickly identify the string “drink” as a word. This is known as “cognitive priming”; this particular form would be “semantic priming” or “conceptual priming.”

The fascinating thing about priming is that it occurs at such a low level— priming speeds up identifying letters as forming a word, which one would expect to take place before you deliberate on the word’s meaning.

Priming also reveals the massive parallelism of spreading activation: if seeing “water” activates the word “drink,” it probably also activates “river,” or “cup,” or “splash” . . . and this activation spreads, from the semantic linkage of concepts, all the way back to recognizing strings of letters. Priming is subconscious and unstoppable, an artifact of the human neural architecture. Trying to stop yourself from priming is like trying to stop the spreading activation of your own neural circuits.

Try making a set of index cards with words like BROWN written in randomly assigned colors–a red GREEN, a blue YELLOW, and so on. Try to say aloud the color—not the meaning, but the color—of the letter-strings. 

In Mussweiler and Strack’s experiment, subjects were asked an anchoring question: “Is the annual mean temperature in Germany higher or lower than 5 °C / 20 °C?”<sup>1</sup> Afterward, on a word-identification task, subjects presented with the 5 °C anchor were faster on identifying words like “cold” and “snow,” while subjects with the high anchor were faster to identify “hot” and “sun.” This shows a non-adjustment mechanism for anchoring: priming compatible thoughts and memories.

The more general result is that completely uninformative, known false, or totally irrelevant “information” can influence estimates and decisions. In the field of heuristics and biases, this more general phenomenon is known as contamination. <sup>2</sup>

Early research in heuristics and biases discovered anchoring effects, such as subjects giving lower (higher) estimates of the percentage of UN countries found within Africa, depending on whether they were first asked if the percentage was more or less than 10 (65). This effect was originally attributed to subjects adjusting from the anchor as a starting point, stopping as soon as they reached a plausible value, and under-adjusting because they were stopping at one end of a confidence interval.<sup>3</sup>

Tversky and Kahneman’s early hypothesis still appears to be the correct explanation in some circumstances, notably when subjects generate the initial estimate themselves. But modern research seems to show that most anchoring is actually due to contamination, not sliding adjustment.<sup>4</sup>

Your grocery store probably has annoying signs saying “Limit 12 per customer” or “5 for $10.” Are these signs effective at getting customers to buy in larger quantities? You probably think you’re not influenced. But someone must be, because these signs have been shown to work. Which is why stores keep putting them up.<sup>5</sup>

Yet the most fearsome aspect of contamination is that it serves as yet another of the thousand faces of confirmation bias.<sup>6</sup> Once an idea gets into your head, it primes information compatible with it—and thereby ensures its continued existence. Never mind the selection pressures for winning political arguments; confirmation bias is built directly into our hardware, associational networks priming compatible thoughts and memories. An unfortunate side effect of our existence as neural creatures.

A single fleeting image can be enough to prime associated words for recognition. Don’t think it takes anything more to set confirmation bias in motion. All it takes is that one quick flash, and the bottom line is already decided, for we change our minds less often than we think . . .

---

<sup>1</sup>Mussweiler and Strack, “Comparing Is Believing,” 1999.

<sup>2</sup>Chapman and Johnson, “Incorporating the Irrelevant,” 2002.

<sup>3</sup>Tversky and Kahneman, “Judgment Under Uncertainty,” 1974.

<sup>4</sup>Epley and Gilovich, “Putting Adjustment Back in the Anchoring and Adjustment Heuristic,” 2001.

<sup>5</sup>Wansink, Kent, and Hoch, “An Anchoring and Adjustment Model of Purchase Quantity Decisions,” 1998, http://www.jstor.org/stable/3151931.

<sup>6</sup>See “The Third Alternative,” “Knowing About Biases Can Hurt You,” “One Argument Against An Army,” “What Evidence Filtered Evidence?”, and “Rationalization.” And “Hindsight Devalues Science,” “Fake Causality,” and “Positive Bias: Look into the Dark” in Map and Territory. And the rest of this book.