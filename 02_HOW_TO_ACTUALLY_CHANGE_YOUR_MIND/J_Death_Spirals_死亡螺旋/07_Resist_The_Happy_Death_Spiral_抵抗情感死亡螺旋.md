以下是 Eliezer Yudkowsky 的文章《**抵制幸福死亡螺旋**》（*Resist the Happy Death Spiral*）的中文翻译，保留原始引用：

---

## 抵制幸福死亡螺旋

*作者：Eliezer Yudkowsky*

从前，有一个人坚信自己拥有一个伟大的思想。事实上，随着他不断思索这个伟大的思想，他意识到，这不仅仅是个伟大的想法，而是**有史以来最美妙的想法**。这个伟大的思想能够揭示宇宙的奥秘，取代腐败且错误百出的权威机构，赋予实践者几近魔法般的力量，喂饱饥饿的人，治愈病人，让整个世界变得更美好，诸如此类，等等等等。

这个人就是弗朗西斯·培根，他的伟大思想是**科学方法**，他也是历史上唯一一个宣称为人类带来如此巨大福祉、而**结果完全正确**的怪人。<sup>1</sup>

这就带来了一个问题：如果你决定永远不会过度崇拜任何东西，那你也有可能错过那些**确实那么优秀**的东西。虽然到目前为止，还没人实现比培根更大胆的主张——至少，还没有。

但问题来了：我们要如何抵制**对“科学”本身的幸福死亡螺旋**？

所谓的“幸福死亡螺旋”，是指你认为某件事如此美好，以至于“光环效应”让你不断为它找到更多值得称赞的理由，这又让它显得更美好，如此循环螺旋上升，直至深渊。假如科学确实如此有益，以至于我们无法在保持理智的前提下，承认它的真正辉煌呢？听起来好像是一句很赞的话，对吧？哦不，螺旋开始了，快逃啊啊啊……

如果你调用那种预设的深沉智慧来“提醒我们不要过分崇拜科学”，你可能会想到类似“科学发明了空调，但也制造了氢弹”，或者“科学能解释星星和生物学，但它永远无法证明或否定我车库里的龙”这种说法。但最初说这些话的人，并不是为了抵制幸福死亡螺旋。他们并不担心自己对科学的欣赏会失控。他们更可能是因为科学某方面与他们的信仰冲突，于是试图削弱科学的权威。

这些**标准的科学批评**，对那些真正感受到科学振奋之人来说，基本没什么吸引力——因为这压根不是对他们说的。所以我们得寻找其他的方式来说点“负面”的话。

但如果你出于抵制幸福死亡螺旋的目的，**有选择性地去寻找科学的缺点**，你是不是就已经在为自己的信念找借口了？你要是知道自己在“自我操纵”，你还会相信自己的想法吗？

我通常对那些声称“可以用一种偏见抵消另一种偏见”的人持怀疑态度。听起来就像是某个汽车修理工说，你右侧的雨刷电机坏了，但我们不修它，而是把左侧的雨刷也弄坏，这样就平衡了。这种“聪明”往往只会让你自食其果。无论解决方案是什么，它**都应基于对真相的信念**，而不是“相信你自己相信你认为是假的事”。

那我们能不能通过只在“狭窄的领域内”欣赏科学，来防止幸福死亡螺旋？死亡螺旋的部分根源是你在任何地方都看到伟大思想的身影——就像某些人会说“只要给共产主义一个机会，它就能治愈癌症”。几乎可以肯定，最可靠的邪教导师特征，就是他自称对**所有事情**都专家——不仅限于某个领域，甚至不仅是相关领域。他知道你该吃什么、穿什么、从事什么工作、该跟谁上床、该欣赏什么艺术、听什么音乐……

不幸的是，大多数人都无法成功地把科学关进一个“整齐的小盒子”里。常见伎俩如“嘿，科学不能治癌症”，根本站不住脚。“科学对父母对孩子的爱无话可说”——抱歉，这是**假的**。如果你试图把科学从比如“父母的爱”这类问题中剥离开来，那你不仅是在否认认知科学和进化心理学，你也是在否认 Martine Rothblatt 因为想为女儿治肺动脉高压而创立联合治疗公司这一事实。<sup>2</sup> 科学确实与人类生活的方方面面息息相关。

好吧，那么我们举个例子：关于科学的“虚假美好主张”有哪些？

有一个我认为**不实**的说法是：“科学如此伟大，以至于科学家根本无需为自己的研究承担伦理责任——反正最终都会产生正面结果。” 这个观点误解了科学造福人类的机制。科学家是人类，他们和其他人一样有亲社会的关怀，这也是为什么科学总体上利大于弊的原因之一。

但这个观点显然仍有争议。那我们来看看一个更**显而易见的虚假美好主张**：

* “只要发表足够多的论文，癌症病人就能痊愈。”
* 或者：“只要坚持只相信有 p < 0.05 重复实验证据的东西，反社会人格者也能变得完全正常。”

避免相信这种说法的方式，**不是情绪上“限高”，假装科学只是“有点好”**；也不是去寻找“发表论文导致癌症”的理由；也不是说“科学对癌症无话可说”。

相反，如果你足够具体地理解科学是如何运作的，你就会明白：虽然“科学能治癌症”可能为真，但**一个癌症病人写论文，并不会神奇地康复**。这个特定的因果链**根本不成立**。

幸福死亡螺旋的问题，表面是情绪，实质是认知——即“光环效应”：你一旦接受了某个积极主张，就更容易接受更多类似的主张。我们不可能彻底摆脱这种效应，它始终会影响我们，但我们可以**放慢脚步、停止反应、逐条分析新主张的具体内容，而不是沉浸在积极情绪中**。

如果一个美好主张“无法被证伪”，但你发现“正反双方都有道理”，那你就该小心了。因为这往往是人们在排演证据、回避真实弱点时的说法。鉴于幸福死亡螺旋的危险，合理的做法是**避免对那些尚未解决的主张感到“高兴”**——别把它们变成又一层正面情绪来源。

死亡螺旋之所以危险，是因为**正反馈过强**，会让过程“临界爆发”。虽然你可能永远无法完全消除光环效应，但你可以用足够多的批判性思维，来保持这些“光环”**亚临界**，确保共振逐渐消散而不是爆炸。

你甚至可以说，问题的根源在于：人们一旦接受了某个核心前提出发，就不再认真审查每一个“额外负担细节”——不会要求更多证据来补偿复杂度，不寻找漏洞，不引发好奇心。如果没有“合取谬误”（conjunction fallacy），光环效应也许还在，但就不会有“幸福死亡螺旋”。<sup>3</sup>

哪怕是在宇宙中最美好的“美好事物”面前，一个完美的理性主义者若对每一个新主张都**恰如其分地要求证据**，是不会感受到“情绪共鸣”的。你无法成为这样的人，但你可以离它足够近，从而**防止自己的快乐失控**。<sup>4</sup>

Stuart Armstrong 给出了一个密切相关的建议：<sup>5</sup>

> 把你的伟大思想分割成小的、相互独立的观念，并将它们当作独立的来看待。
>
> 比如，一个马克思主义者可以将马克思的伟大思想分为劳动价值理论、阶级之间的政治关系理论、工资理论、人类最终政治状态理论。然后，每一个理论都应该独立评估，某一个理论的真假**不应影响**其他理论的判断。如果我们能做到这一点，我们就能避开螺旋，因为每个理论本身都太狭窄，不足以引发死亡螺旋。

这在比喻意义上，就像是**防止多块未达临界质量的钚块聚在一起**。三个伟大思想远比一个伟大思想更不容易让你发疯。Armstrong 的建议还有助于促进**具体化**：一旦有人说“只要发表足够多的论文就能治愈癌症”，你就应该追问：

> “这是实验方法的成果吗？如果是的话，在实验过程的哪一阶段癌症被治愈了？
> 还是说，这是科学作为一种社会过程的成果？如果是，那它是否依赖于个体科学家希望治愈癌症的动机？还是说即便他们出于私利，系统也能起效？”

希望这样的思考能让你从单纯的好或坏的情绪反应中**抽离出来**，开始**意识到其中的混乱和缺乏支持证据**。

---

### 总结起来，避免陷入“幸福死亡螺旋”的方法包括：

* **把伟大思想拆分成独立部分**；
* **把每一个新增的细节都当作一个“负担”来评估**；
* **专注于因果链的具体细节，而不是依赖情绪**；
* **避免排演式地重复已有证据**；
* **不要因为某个主张“无法被反驳”就感到高兴**。

而不应通过以下方式：

* **拒绝高度欣赏任何事物**；
* **带有偏见地寻找反面理由，只是为了让自己不那么高兴**；
* **强行把一个思想塞进“安全盒子”里，不让它越界**。

---

<sup>1</sup>当然，培根不是单枪匹马发明了科学方法，但他确实作出了贡献，而且可能是第一个真正意识到科学方法威力的人。

<sup>2</sup>而且她确实成功了。

<sup>3</sup>更多背景见前一本《地图与领地》中的〈负担性细节〉、〈需要多少证据？〉和〈奥卡姆剃刀〉。

<sup>4</sup>最危险的情况是：任何对伟大思想中某个积极主张的批评都令人不悦，或在社会上变得不可接受。因为“论点就是士兵”，每个正面主张都是“我方士兵”，批评它就是“背叛”。这时候，链式反应就会变得**超临界**。我们之后会详细谈这个问题。

<sup>5</sup>引用自：[http://lesswrong.com/lw/lm/affective\_death\_spirals/gp5](http://lesswrong.com/lw/lm/affective_death_spirals/gp5)

---

## Resist the Happy Death Spiral

by Eliezer Yudkowsky

Once upon a time, there was a man who was convinced that he possessed a Great Idea. Indeed, as the man thought upon the Great Idea more and more, he realized that it was not just a great idea, but the most wonderful idea ever. The Great Idea would unravel the mysteries of the universe, supersede the authority of the corrupt and error-ridden Establishment, confer nigh-magical powers upon its wielders, feed the hungry, heal the sick, make the whole world a better place, etc., etc., etc.

The man was Francis Bacon, his Great Idea was the scientific method, and he was the only crackpot in all history to claim that level of benefit to humanity and turn out to be completely right.<sup>1</sup>

That’s the problem with deciding that you’ll never admire anything that much: Some ideas really are that good. Though no one has fulfilled claims more audacious than Bacon’s; at least, not yet.

But then how can we resist the happy death spiral with respect to Science itself? The happy death spiral starts when you believe something is so wonderful that the halo effect leads you to find more and more nice things to say about it, making you see it as even more wonderful, and so on, spiraling up into the abyss. What if Science is in fact so beneficial that we cannot acknowledge its true glory and retain our sanity? Sounds like a nice thing to say, doesn’t it? Oh no it’s starting ruuunnnnn . . .

If you retrieve the standard cached deep wisdom for don’t go overboard on admiring science, you will find thoughts like “Science gave us air conditioning, but it also made the hydrogen bomb” or “Science can tell us about stars and biology, but it can never prove or disprove the dragon in my garage.” But the people who originated such thoughts were not trying to resist a happy death spiral. They weren’t worrying about their own admiration of science spinning out of control. Probably they didn’t like something science had to say about their pet beliefs, and sought ways to undermine its authority.

The standard negative things to say about science aren’t likely to appeal to someone who genuinely feels the exultation of science—that’s not the intended audience. So we’ll have to search for other negative things to say instead.

But if you look selectively for something negative to say about science—even in an attempt to resist a happy death spiral—do you not automatically convict yourself of rationalization? Why would you pay attention to your own thoughts, if you knew you were trying to manipulate yourself?

I am generally skeptical of people who claim that one bias can be used to counteract another. It sounds to me like an automobile mechanic who says that the motor is broken on your right windshield wiper, but instead of fixing it, they’ll just break your left windshield wiper to balance things out. This is the sort of cleverness that leads to shooting yourself in the foot. Whatever the solution, it ought to involve believing true things, rather than believing you believe things that you believe are false.

Can you prevent the happy death spiral by restricting your admiration of Science to a narrow domain? Part of the happy death spiral is seeing the Great Idea everywhere—thinking about how Communism could cure cancer if it were only given a chance. Probably the single most reliable sign of a cult guru is that the guru claims expertise, not in one area, not even in a cluster of related areas, but in everything. The guru knows what cult members should eat, wear, do for a living; who they should have sex with; which art they should look at; which music they should listen to . . .

Unfortunately for this plan, most people fail miserably when they try to describe the neat little box that science has to stay inside. The usual trick, “Hey, science won’t cure cancer,” isn’t going to fly. “Science has nothing to say about a parent’s love for their child”—sorry, that’s simply false. If you try to sever science from e.g. parental love, you aren’t just denying cognitive science and evolutionary psychology. You’re also denying Martine Rothblatt’s founding of United Therapeutics to seek a cure for her daughter’s pulmonary hypertension.<sup>2</sup> Science is legitimately related, one way or another, to just about every important facet of human existence.

All right, so what’s an example of a false nice claim you could make about science?

One false claim, in my humble opinion, is that science is so wonderful that scientists shouldn’t even try to take ethical responsibility for their work—it will turn out well in the end regardless. It appears to me that this misunderstands the process whereby science benefits humanity. Scientists are human; they have prosocial concerns just like most other other people, and this is at least part of why science ends up doing more good than evil.

But that point is, evidently, not beyond dispute. So here’s a simpler false nice claim: “A cancer patient can be cured just through the publishing of enough journal papers.” Or: “Sociopaths could become fully normal, if they just committed themselves to never believing anything without replicated experimental evidence with p < 0.05.”

The way to avoid believing such statements isn’t an affective cap, deciding that science is only slightly nice. Nor searching for reasons to believe that publishing journal articles causes cancer. Nor believing that science has nothing to say about cancer one way or the other.

Rather, if you know with enough specificity how science works, then you know that while it may be possible for “science to cure cancer,” a cancer patient writing journal papers isn’t going to experience a miraculous remission. That specific proposed chain of cause and effect is not going to work out.

The happy death spiral is only an emotional problem because of a perceptual problem, the halo effect, that makes us more likely to accept future positive claims once we’ve accepted an initial positive claim. We can’t get rid of this effect just by wishing; it will probably always influence us a little. But we can manage to slow down, stop, consider each additional nice claim as an additional burdensome detail, and focus on the specific points of the claim apart from its positiveness.

What if a specific nice claim “can’t be disproven” but there are arguments “both for and against” it? Actually these are words to be wary of in general, because often this is what people say when they’re rehearsing the evidence or avoiding the real weak points. Given the danger of the happy death spiral, it makes sense to try to avoid being happy about unsettled claims—to avoid making them into a source of yet more positive affect about something you liked already.

The happy death spiral is only a big emotional problem because of the overly positive feedback, the ability for the process to go critical. You may not be able to eliminate the halo effect entirely, but you can apply enough critical reasoning to keep the halos subcritical—make sure that the resonance dies out rather than exploding.

You might even say that the whole problem starts with people not bothering to critically examine every additional burdensome detail—demanding sufficient evidence to compensate for complexity, searching for flaws as well as support, invoking curiosity—once they’ve accepted some core premise. Without the conjunction fallacy, there might still be a halo effect, but there wouldn’t be a happy death spiral.<sup>3</sup>

Even on the nicest Nice Thingies in the known universe, a perfect rationalist who demanded exactly the necessary evidence for every additional (positive) claim would experience no affective resonance. You can’t do this, but you can stay close enough to rational to keep your happiness from spiraling out of control.<sup>4</sup>

Stuart Armstrong gives closely related advice:<sup>5</sup>

> Cut up your Great Thingy into smaller independent ideas, and treat them as independent.
> 
> For instance a marxist would cut up Marx’s Great Thingy into a theory of value of labour, a theory of the political relations between classes, a theory of wages, a theory on the ultimate political state of mankind. Then each of them should be assessed independently, and the truth or falsity of one should not halo on the others. If we can do that, we should be safe from the spiral, as each theory is too narrow to start a spiral on its own.

This, metaphorically, is like keeping subcritical masses of plutonium from coming together. Three Great Ideas are far less likely to drive you mad than one Great Idea. Armstrong’s advice also helps promote specificity: As soon as someone says, “Publishing enough papers can cure your cancer,” you ask, “Is that a benefit of the experimental method, and if so, at which stage of the experimental process is the cancer cured? Or is it a benefit of science as a social process, and if so, does it rely on individual scientists wanting to cure cancer, or can they be self-interested?” Hopefully this leads you away from the good or bad feeling, and toward noticing the confusion and lack of support.

To summarize, you do avoid a Happy Death Spiral by:

- Splitting the Great Idea into parts;
- Treating every additional detail as burdensome;
- Thinking about the specifics of the causal chain instead of the good or bad feelings;
- Not rehearsing evidence; and
- Not adding happiness from claims that “you can’t prove are wrong”;

but not by:

- Refusing to admire anything too much;
- Conducting a biased search for negative points until you feel unhappy again; or
- Forcibly shoving an idea into a safe box.

---

<sup>1</sup>Bacon didn’t singlehandedly invent science, of course, but he did contribute, and may have been the first to realize the power.

<sup>2</sup>Successfully, I might add.

<sup>3</sup>For more background, see “Burdensome Details,” “How Much Evidence Does it Take?”, and “Occam’s Razor” in the previous volume, Map and Territory.

<sup>4</sup>The really dangerous cases are the ones where any criticism of any positive claim about the Great Thingy feels bad or is socially unacceptable. Arguments are soldiers; any positive claim is a soldier on our side; stabbing your soldiers in the back is treason. Then the chain reaction goes supercritical. More on this later.

<sup>5</sup>Source: http://lesswrong.com/lw/lm/affective_death_spirals/gp5.